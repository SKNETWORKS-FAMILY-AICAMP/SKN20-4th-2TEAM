{
  "context": "TurkColBERT evaluates dense encoders and late-interaction models for Turkish information retrieval, demonstrating parameter efficiency and superior performance of late-interaction models with faster indexing. Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish.Dense bi-encoderscurrently dominate Turkish IR, yetlate-interaction models-- which retaintoken-level representationsforfine-grained matching-- have not been systematically evaluated. We introduceTurkColBERT, the first comprehensive benchmark comparing dense encoders andlate-interaction modelsfor Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders onTurkish NLI/STS tasks, then converts them intoColBERT-style retrieversusingPyLatetrained onMS MARCO-TR. We evaluate 10 models across fiveTurkish BEIR datasetscovering scientific, financial, and argumentative domains. Results show strongparameter efficiency: the 1.0M-parametercolbert-hash-nano-tris 600times smaller than the 600Mturkish-e5-largedense encoder while preserving over 71\\% of itsaverage mAP.Late-interaction modelsthat are 3--5times smaller than dense encoders significantly outperform them;ColmmBERT-base-TRyields up to +13.8\\% mAP on domain-specific tasks. For production-readiness, we compareindexing algorithms:MUVERA+Rerankis 3.33times faster thanPLAIDand offers +1.7\\% relative mAP gain. This enables low-latency retrieval, withColmmBERT-base-TRachieving 0.54 msquery timesunderMUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets (leq50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scaleMUVERAevaluations remain necessary. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547043",
    "title": "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval",
    "authors": [
      "Özay Ezerceli",
      "Mahmoud El Hussieni",
      "Selva Taş",
      "Reyhan Bayraktar",
      "Fatma Betül Terzioğlu",
      "Yusuf Çelebi",
      "Yağız Asker"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/ozayezerceli/TurkColBERT",
    "huggingface_url": "https://huggingface.co/papers/2511.16528",
    "upvote": 22
  }
}