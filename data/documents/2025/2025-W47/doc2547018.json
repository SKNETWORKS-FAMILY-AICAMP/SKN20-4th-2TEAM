{
  "context": "Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED. The GroupRank paper presents a very elegant solution to a fundamental dilemma in reranking for RAG systems. It cleverly bridges the gap between Pointwise and Listwise methods with a new 'Groupwise' paradigm. By evaluating documents in small, manageable groups, it gains the comparative context that Pointwise methods lack, while avoiding the rigidity and scalability issues of traditional Listwise approaches. The use of reinforcement learning with a unique reward function, combined with their innovative data synthesis pipeline, makes this a powerful and practical contribution, especially for complex, reasoning-based retrieval tasks. good job！ When will the code be updated? We are conducting a final review of the code and models and will release them this week. groupwise, sounds interesting This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547018",
    "title": "GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning",
    "authors": [
      "Dan Yang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/AQ-MedAI/Diver",
    "huggingface_url": "https://huggingface.co/papers/2511.11653",
    "upvote": 55
  }
}