{
  "context": "V-ReasonBench evaluates generative video models across structured problem-solving, spatial cognition, pattern-based inference, and physical dynamics using a diverse set of tasks. Recent progress ingenerative video models, such asVeo-3, has shown surprisingzero-shot reasoningabilities, creating a growing need for systematic and reliable evaluation. We introduce V-ReasonBench, abenchmarkdesigned to assess video reasoning across four key dimensions:structured problem-solving,spatial cognition,pattern-based inference, andphysical dynamics. Thebenchmarkis built from both synthetic andreal-world image sequencesand provides a diverse set ofanswer-verifiable tasksthat arereproducible,scalable, andunambiguous. Evaluations of six state-of-the-art video models reveal clear dimension-wise differences, with strong variation in structured, spatial, pattern-based, and physical reasoning. We further compare video models with strong image models, analyze common hallucination behaviors, and study how video duration affectsChain-of-Frames reasoning. Overall, V-ReasonBench offers a unified andreproducibleframework for measuring video reasoning and aims to support the development of models with more reliable,human-aligned reasoning skills. Recent progress in generative video models, such as Veo-3, has shown surprising zero-shot reasoning abilities, creating a growing need for systematic and reliable evaluation. We introduce V-ReasonBench, a benchmark designed to assess video reasoning across four key dimensions: structured problem-solving, spatial cognition, pattern-based inference, and physical dynamics. The benchmark is built from both synthetic and real-world image sequences and provides a diverse set of answer-verifiable tasks that are reproducible, scalable, and unambiguous. Evaluations of six state-of-the-art video models reveal clear dimension-wise differences, with strong variation in structured, spatial, pattern-based, and physical reasoning. We further compare video models with strong image models, analyze common hallucination behaviors, and study how video duration affects Chain-of-Frames reasoning. Overall, V-ReasonBench offers a unified and reproducible framework for measuring video reasoning and aims to support the development of models with more reliable, human-aligned reasoning skills. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547019",
    "title": "V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models",
    "authors": [
      "Lingting Zhu",
      "Shengju Qian"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/yangluo7/V-ReasonBench",
    "huggingface_url": "https://huggingface.co/papers/2511.16668",
    "upvote": 54
  }
}