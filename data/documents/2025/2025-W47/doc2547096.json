{
  "context": "Multi-Granular Language Learning (MGLL) enhances visual understanding by improving multi-label and cross-granularity alignment in image-text pretraining, outperforming existing methods in complex domains like medical imaging. Recent advances in image-text pretraining have significantly enhanced visual understanding by aligning visual and textual representations.Contrastive Language-Image Pretraining (CLIP)has played a pivotal role in multimodal learning. However, its focus on single-label, single-granularity alignment limits its effectiveness in complex domains such as medical imaging, where images often correspond to multiple high-level labels (e.g., disease categories) across different annotation granularities (e.g., diagnostic description, clinical explanation). To address this, we propose Multi-Granular Language Learning (MGLL), a contrastive learning framework designed to improve both multi-label and cross-granularity alignment. MGLL leveragesstructured multi-label supervision, integrates textual descriptions across granularities, and introducessoft-label supervisionwith point-wise constraints to enhance alignment. MGLL employssmooth Kullback-Leibler (KL) divergenceto ensure cross-granularity consistency while maintaining computational efficiency as a plug-and-play module forvision-language models. Pretrained on our constructed large-scale multi-granular datasets and evaluated across multiple datasets, MGLL outperforms other state-of-the-art methods in downstream tasks. The code is available at https://github.com/HUANGLIZI/MGLL{https://github.com/HUANGLIZI/MGLL}. MGLL leverages structured multi-label supervision, integrates textual descriptions across granularities, and introduces soft-label supervision with point-wise constraints to enhance alignment. MGLL employs smooth Kullback-Leibler (KL) divergence to ensure cross-granularity consistency while maintaining computational efficiency as a plug-and-play module for vision-language models. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547096",
    "title": "Boosting Medical Visual Understanding From Multi-Granular Language Learning",
    "authors": [
      "Zihan Li"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/HUANGLIZI/MGLL",
    "huggingface_url": "https://huggingface.co/papers/2511.15943",
    "upvote": 1
  }
}