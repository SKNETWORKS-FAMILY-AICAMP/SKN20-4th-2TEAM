{
  "context": "A proactive hearing assistant system identifies and separates conversation partners in real-time using a dual-model architecture on binaural audio, adapting to conversational dynamics without explicit prompts. We introduce proactive hearing assistants that automatically identify and separate the wearer's conversation partners, without requiring explicit prompts. Our system operates onegocentric binaural audioand uses the wearer'sself-speechas an anchor, leveragingturn-taking behavioranddialogue dynamicsto inferconversational partnersand suppress others. To enablereal-time,on-device operation, we propose adual-model architecture: alightweight streaming modelruns every 12.5 ms for low-latency extraction of the conversation partners, while a slower model runs less frequently to capture longer-range conversational dynamics. Results on real-world 2- and 3-speaker conversation test sets, collected with binaural egocentric hardware from 11 participants totaling 6.8 hours, showgeneralizationin identifying and isolatingconversational partnersinmulti-conversation settings. Our work marks a step toward hearing assistants that adapt proactively to conversational dynamics and engagement. More information can be found on our website: https://proactivehearing.cs.washington.edu/ In this work, we introduce the first proactive hearing assistant that automatically identifies and isolates the speakers who are in the same conversation as the user, without requiring any user input or manual selection. Operating directly on egocentric binaural audio, the system uses the wearerâ€™s own speech and natural turn-taking patterns to track who they are talking to and suppress interfering speakers in other conversations. A dual-model architecture enables real-time, on-device performance: a lightweight streaming model ensures low-latency, while a slower model captures longer conversational dynamics. Across real-world 2- and 3-speaker conversations (6.8 hours, 11 participants), our method shows generalization in identifying and isolating conversational partners in multi-conversation settings. Our work marks a step toward hearing assistants that adapt proactively to conversational dynamics and engagement. Chat is this real ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547074",
    "title": "Proactive Hearing Assistants that Isolate Egocentric Conversations",
    "authors": [
      "Guilin Hu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/guilinhu/proactive_hearing_assistant",
    "huggingface_url": "https://huggingface.co/papers/2511.11473",
    "upvote": 6
  }
}