{
  "context": "Medal S is a medical segmentation foundation model that integrates spatial and textual prompts for efficient, high-accuracy multi-class segmentation across various imaging modalities. We introduce Medal S, amedical segmentation foundation modelthat supports native-resolution spatial andtextual promptswithin anend-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieveschannel-wise alignmentbetweenvolumetric promptsandtext embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiplenative-resolution masksin parallel, enhancingmulti-class segmentationperformance. A lightweight3D convolutional moduleenables precisevoxel-space refinementguided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: atext-only mode, where model predictions serve asspatial promptsforself-refinementwithout human input, and ahybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We proposedynamic resamplingto address target-patch ratio imbalance, extendingSATandnnU-Netfordata augmentation. Furthermore, we develop optimizedtext preprocessing, atwo-stage inferencestrategy, andpost-processing techniquesto improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperformsSATwith aDSCof 75.44 (vs. 69.83),NSDof 77.34 (vs. 71.06),F1of 38.24 (vs. 24.88), andDSC TPof 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy inmulti-class medical segmentationtasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S. We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available athttps://github.com/yinghemedical/Medal-S. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547097",
    "title": "Medal S: Spatio-Textual Prompt Model for Medical Segmentation",
    "authors": [
      "Pengcheng Shi"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/yinghemedical/Medal-S",
    "huggingface_url": "https://huggingface.co/papers/2511.13001",
    "upvote": 1
  }
}