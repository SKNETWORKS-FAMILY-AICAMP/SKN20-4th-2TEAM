{
  "context": "The Draft and Refine (DnR) agent framework uses a question-conditioned utilization metric to improve visual grounding in large vision-language models, reducing hallucinations and increasing accuracy. While recentLarge Vision-Language Models (LVLMs)exhibit strongmultimodal reasoningabilities, they often produce ungrounded or hallucinated responses because they rely too heavily onlinguistic priorsinstead ofvisual evidence. This limitation highlights the absence of a quantitative measure of how much these models actually use visual information during reasoning. We propose Draft and Refine (DnR), an agent framework driven by aquestion-conditioned utilization metric. The metric quantifies the model's reliance onvisual evidenceby first constructing a query-conditionedrelevance mapto localize question-specific cues and then measuring dependence through relevance-guidedprobabilistic masking. Guided by this metric, the DnR agent refines its initial draft using targeted feedback from externalvisual experts. Each expert's output (such as boxes or masks) is rendered asvisual cueson the image, and the model is re-queried to select the response that yields the largest improvement in utilization. This process strengthensvisual groundingwithout retraining or architectural changes. Experiments acrossVQAandcaptioning benchmarksshow consistent accuracy gains and reduced hallucination, demonstrating that measuring visual utilization provides a principled path toward moreinterpretableandevidence-driven multimodal agent systems. This paper introduces Draft-and-Refine (DnR), a framework that measures question-conditioned visual utilization in LVLMs and refines answers using external visual experts. The pipeline mitigates hallucination without retraining and strengthens visual grounding through relevance-driven feedback. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547094",
    "title": "Draft and Refine with Visual Experts",
    "authors": [
      "Sungheon Jeong"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/EavnJeong/Draft-and-Refine-with-Visual-Experts",
    "huggingface_url": "https://huggingface.co/papers/2511.11005",
    "upvote": 2
  }
}