{
  "context": "Normalized contextual calibration addresses label length bias in large language models, improving performance and reliability across various tasks. Large language models(LLMs) are powerful zero- andfew-shot learners. However, when predicting over a set of candidate options, LLMs suffer fromlabel biases, and existingcalibration methodsoverlook biases arising frommulti-token class labels. We tackle an issue we calllabel length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we proposenormalized contextual calibration(NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10%F1. Moreover, NCC extends bias mitigation to broader tasks such asmultiple-choice question answering. Our analysis shows that, when combined within-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples forcompetitive performance, and produces more reliableconfidence estimates. These findings highlight the importance of mitigating full-label biasesto improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens. Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547068",
    "title": "Mitigating Label Length Bias in Large Language Models",
    "authors": [
      "Mario Sanz-Guerrero"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.14385",
    "upvote": 7
  }
}