{
  "context": "A parallel multimodal diffusion framework, MMaDA-Parallel, enhances cross-modal alignment and semantic consistency in thinking-aware image synthesis by addressing error propagation issues in sequential approaches. Whilethinking-aware generationaims to improve performance on complex tasks, we identify a critical failure mode where existingsequential,autoregressiveapproaches can paradoxically degrade performance due to error propagation. To systematically analyze this issue, we proposeParaBench, a new benchmark designed to evaluate both text and image output modalities. Our analysis usingParaBenchreveals that this performance degradation is strongly correlated with poor alignment between the generated reasoning and the final image. To resolve this, we propose aparallel multimodal diffusionframework,MMaDA-Parallel, that enablescontinuous,bidirectional interactionbetween text and images throughout the entire denoising trajectory.MMaDA-Parallelis trained withsupervised finetuningand then further optimized byParallel Reinforcement Learning(ParaRL), a novel strategy that appliessemantic rewardsalong the trajectory to enforce cross-modal consistency. Experiments validate that our model significantly improvescross-modal alignmentandsemantic consistency, achieving a 6.9\\% improvement inOutput AlignmentonParaBenchcompared to the state-of-the-art model,Bagel, establishing a more robust paradigm for thinking-aware image synthesis. Our code is open-sourced at https://github.com/tyfeld/MMaDA-Parallel Our code is open-sourced at:https://github.com/tyfeld/MMaDA-Parallel arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/mmada-parallel-multimodal-large-diffusion-language-models-for-thinking-aware-editing-and-generation This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547014",
    "title": "MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation",
    "authors": [
      "Ye Tian",
      "Ling Yang",
      "Jiongfan Yang",
      "Xiangtai Li"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/tyfeld/MMaDA-Parallel",
    "huggingface_url": "https://huggingface.co/papers/2511.09611",
    "upvote": 69
  }
}