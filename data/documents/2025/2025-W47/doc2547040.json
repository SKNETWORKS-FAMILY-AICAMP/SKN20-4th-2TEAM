{
  "context": "MVI-Bench evaluates the robustness of Large Vision-Language Models against misleading visual inputs using a hierarchical taxonomy and a novel sensitivity metric, revealing significant vulnerabilities. Evaluating therobustnessofLarge Vision-Language Models(LVLMs) is essential for their continued development and responsible deployment in real-world applications. However, existingrobustnessbenchmarks typically focus onhallucinationor misleading textual inputs, while largely overlooking the equally critical challenge posed bymisleading visual inputsin assessing visual understanding. To fill this important gap, we introduceMVI-Bench, the first comprehensive benchmark specially designed for evaluating howMisleading Visual Inputsundermine therobustnessofLVLMs. Grounded in fundamentalvisual primitives, the design ofMVI-Benchcenters on three hierarchical levels ofmisleading visual inputs:Visual Concept,Visual Attribute, andVisual Relationship. Using this taxonomy, we curate six representative categories and compile 1,248 expertly annotatedVQAinstances. To facilitate fine-grainedrobustnessevaluation, we further introduceMVI-Sensitivity, a novel metric that characterizes LVLMrobustnessat a granular level. Empirical results across 18 state-of-the-artLVLMsuncover pronounced vulnerabilities tomisleading visual inputs, and our in-depth analyses onMVI-Benchprovide actionable insights that can guide the development of more reliable and robustLVLMs. The benchmark and codebase can be accessed at https://github.com/chenyil6/MVI-Bench. Evaluating the robustness of Large Vision-Language Models (LVLMs) is essential for their continued development and responsible deployment in real-world applications. However, existing robustness benchmarks typically focus on hallucination or misleading textual inputs, while largely overlooking the equally critical challenge posed by misleading visual inputs in assessing visual understanding. To fill this important gap, we introduce MVI-Bench, the first comprehensive benchmark specially designed for evaluating how Misleading Visual Inputs undermine the robustness of LVLMs. Grounded in fundamental visual primitives, the design of MVI-Bench centers on three hierarchical levels of misleading visual inputs: Visual Concept, Visual Attribute, and Visual Relationship. Using this taxonomy, we curate six representative categories and compile 1,248 expertly annotated VQA instances. To facilitate fine-grained robustness evaluation, we further introduce MVI-Sensitivity, a novel metric that characterizes LVLM robustness at a granular level. Empirical results across 18 state-of-the-art LVLMs uncover pronounced vulnerabilities to misleading visual inputs, and our in-depth analyses on MVI-Bench provide actionable insights that can guide the development of more reliable and robust LVLMs.  This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547040",
    "title": "MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs",
    "authors": [
      "Dehai Min"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/chenyil6/MVI-Bench",
    "huggingface_url": "https://huggingface.co/papers/2511.14159",
    "upvote": 24
  }
}