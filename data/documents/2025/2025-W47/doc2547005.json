{
  "context": "VideoP2R, a process-aware reinforcement fine-tuning framework, improves video reasoning and understanding by modeling perception and reasoning separately, achieving state-of-the-art results on multiple benchmarks. Reinforcement fine-tuning(RFT), a two-stage framework consisting ofsupervised fine-tuning(SFT) andreinforcement learning(RL) has shown promising results on improvingreasoningability oflarge language models(LLMs). Yet extending RFT tolarge video language models(LVLMs) remains challenging. We proposeVideoP2R, a novel process-aware video RFT framework that enhances videoreasoningby modelingperceptionandreasoningas distinct processes. In the SFT stage, we develop a three-step pipeline to generateVideoP2R-CoT-162K, a high-quality, process-awarechain-of-thought(CoT) dataset forperceptionandreasoning. In the RL stage, we introduce a novelprocess-aware group relative policy optimization(PA-GRPO) algorithm that supplies separate rewards forperceptionandreasoning. Extensive experiments show thatVideoP2Rachieves state-of-the-art (SotA) performance on six out of seven videoreasoningand understanding benchmarks. Ablation studies further confirm the effectiveness of our process-aware modeling andPA-GRPOand demonstrate that model'sperceptionoutput is information-sufficient for downstreamreasoning. Arxiv linkhttps://arxiv.org/abs/2511.11113v1 Reinforcement fine-tuning (RFT), a two-stage framework consisting of supervised fine-tuning (SFT) and reinforcement learning (RL) has shown promising results on improving reasoning ability of large language models (LLMs). Yet extending RFT to large video language models (LVLMs) remains challenging. We propose VideoP2R, a novel process-aware video RFT framework that enhances video reasoning by modeling perception and reasoning as distinct processes. In the SFT stage, we develop a three-step pipeline to generate VideoP2R-CoT-162K, a high-quality, process-aware chain-of-thought (CoT) dataset for perception and reasoning. In the RL stage, we introduce a novel process-aware group relative policy optimization (PA-GRPO) algorithm that supplies separate rewards for perception and reasoning. Extensive experiments show that VideoP2R achieves state-of-the-art (SotA) performance on six out of seven video reasoning and understanding benchmarks. Ablation studies further confirm the effectiveness of our process-aware modeling and PA-GRPO and demonstrate that model's perception output is information-sufficient for downstream reasoning. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend awesome! Thanks for the great insightful work! arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/videop2r-video-understanding-from-perception-to-reasoning-3032-cb765041 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547005",
    "title": "VIDEOP2R: Video Understanding from Perception to Reasoning",
    "authors": [
      "Yifan Jiang"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.11113",
    "upvote": 112
  }
}