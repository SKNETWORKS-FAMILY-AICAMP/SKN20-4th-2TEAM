{
  "context": "MoS, a novel multimodal diffusion model fusion paradigm, achieves state-of-the-art results in text-to-image generation and editing with minimal parameters and computational overhead by using a learnable, token-wise router for modality interaction. We introduceMoS(Mixture of States), a novel fusion paradigm formultimodal diffusion modelsthat merges modalities using flexible, state-based interactions. The core ofMoSis a learnable,token-wise routerthat createsdenoising timestep- andinput-dependent interactionsbetween modalities'hidden states, precisely aligning token-level features with thediffusion trajectory. This router sparsely selects thetop-k hidden statesand is trained with anε-greedy strategy, efficiently selectingcontextual featureswith minimal learnable parameters and negligible computational overhead. We validate our design with text-to-image generation (MoS-Image) and editing (MoS-Editing), which achieve state-of-the-art results. With only 3B to 5B parameters, our models match or surpass counterparts up to 4times larger. These findings establishMoSas a flexible andcompute-efficient paradigmfor scalingmultimodal diffusion models. Scaling text-to-image generation isn't just about stacking layers—it's about smarter moves. The MoS team brings fresh tricks to the transformer table. Prior approaches predominantly rely on cross-attention, self-attention, or unified architectures such as Mixture-of-Transformers (MoT) to align textual and visual representations, enabling the model to follow text guidance effectively. In contrast, our design adopts an orthogonal perspective, guided by the following key principles: Adaptive Layer Selection. We find that using a single fixed layer—typically the final-layer feature—or enforcing rigid one-to-one layer alignment is suboptimal. This indicates that diffusion models do not consume language features in a strictly sequential or layer-aligned manner, making a flexible selection mechanism essential. Input-Dependent Conditional Signals. Modern text-to-image systems often encode the text once and keep it static throughout denoising. We find that this creates an information mismatch with the evolving nature of the diffusion trajectory. Conditional signals should adapt to the noise level and denoising step rather than remain fixed. Token-Specific Conditioning. Our findings indicate that it is more effective to allow each token to source its representation adaptively from different layers, rather than using a single, shared layer embedding to represent all tokens uniformly. This supports a {\\it more granular, token-level view} of context conditioning. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547063",
    "title": "Mixture of States: Routing Token-Level Dynamics for Multimodal Generation",
    "authors": [
      "Zijian Zhou"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.12207",
    "upvote": 9
  }
}