{
  "context": "Step-Audio-R1, using the Modality-Grounded Reasoning Distillation framework, achieves strong reasoning capabilities in audio, outperforming previous models and demonstrating the transferability of reasoning across modalities. Recent advances inreasoning modelshave demonstrated remarkable success in text and vision domains through extendedchain-of-thought deliberation. However, a perplexing phenomenon persists inaudio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduceStep-Audio-R1, the firstaudio reasoningmodel that successfully unlocks reasoning capabilities in the audio domain. Through our proposedModality-Grounded Reasoning Distillation(MGRD) framework,Step-Audio-R1learns to generate audio-relevant reasoning chains that genuinely ground themselves inacoustic featuresrather than hallucinating disconnected deliberations. Our model exhibits strongaudio reasoningcapabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensiveaudio understandingandreasoning benchmarksspanningspeech,environmental sounds, andmusic. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successfulaudio reasoningmodel,Step-Audio-R1opens new pathways toward building trulymultimodal reasoning systemsthat think deeply across all sensory modalities. Step-Audio-R1 Congrats ðŸ”¥ Is this model going to be open source? yes, we will open source This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2547020",
    "title": "Step-Audio-R1 Technical Report",
    "authors": [
      "Xiangyu Tony Zhang",
      "Gang Yu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/stepfun-ai/Step-Audio-R1",
    "huggingface_url": "https://huggingface.co/papers/2511.15848",
    "upvote": 53
  }
}