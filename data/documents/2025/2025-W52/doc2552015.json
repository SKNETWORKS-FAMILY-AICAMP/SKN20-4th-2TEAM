{
  "context": "DSR Suite enhances vision-language models with dynamic spatial reasoning through automated data generation and a geometry selection module that integrates geometric priors. Vision-language models(VLM) excel at general understanding yet remain weak atdynamic spatial reasoning(DSR), i.e., reasoning about the evolvement of object geometry and relationship in 3D space over time, largely due to the scarcity of scalable4D-aware trainingresources. To bridge this gap across aspects of dataset, benchmark and model, we introduce DSR Suite. First, we propose anautomated pipelinethat generatesmultiple-choice question-answer pairsfrom in-the-wild videos for DSR. By leveraging modernvision foundation models, the pipeline extracts rich geometric and motion information, includingcamera poses,local point clouds,object masks,orientations, and3D trajectories. These geometric cues enable the construction ofDSR-Trainfor learning and further human-refinedDSR-Benchfor evaluation. Compared with previous works, our data emphasize (i) in-the-wild video sources, (ii) object- and scene-level 3D requirements, (iii) viewpoint transformations, (iv) multi-object interactions, and (v) fine-grained, procedural answers. Beyond data, we propose a lightweightGeometry Selection Module(GSM) to seamlessly integrate geometric priors into VLMs, which condenses question semantics and extracts question-relevant knowledge from pretrained 4D reconstruction priors into a compact set ofgeometry tokens. This targeted extraction avoids overwhelming the model with irrelevant knowledge. Experiments show that integratingDSR-Trainand GSM intoQwen2.5-VL-7Bsignificantly enhances itsdynamic spatial reasoningcapability, while maintaining accuracy on generalvideo understanding benchmarks. DSR Suite delivers scalable 4D training/evaluation from real-world videos and a lightweight GSM module that injects targeted geometric priors into VLMs, markedly boosting dynamic spatial reasoning while preserving general video understanding. Key Findings: Code:https://github.com/TencentARC/DSR_SuiteData & Model:https://huggingface.co/collections/TencentARC/dsr-suite arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/learning-to-reason-in-4d-dynamic-spatial-understanding-for-vision-language-models-7275-8c033a96 arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/learning-to-reason-in-4d-dynamic-spatial-understanding-for-vision-language-models Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2552015",
    "title": "Learning to Reason in 4D: Dynamic Spatial Understanding for Vision Language Models",
    "authors": [
      "Shengchao Zhou",
      "Yuxin Chen",
      "Wei Huang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/TencentARC/DSR_Suite",
    "huggingface_url": "https://huggingface.co/papers/2512.20557",
    "upvote": 49
  }
}