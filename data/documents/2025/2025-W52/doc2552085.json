{
  "context": "MineTheGap is a method using a genetic algorithm and a bias score to identify prompts that cause Text-to-Image models to generate biased outputs, aiming to reduce redundancy and improve diversity. Text-to-Image (TTI) modelsgenerate images based on text prompts, which often leave certain aspects of the desired image ambiguous. When faced with these ambiguities, TTI models have been shown to exhibit biases in their interpretations. These biases can have societal impacts, e.g., when showing only a certain race for a stated occupation. They can also affect user experience when creating redundancy within a set of generated images instead of spanning diverse possibilities. Here, we introduce MineTheGap - a method for automatically mining prompts that cause a TTI model to generate biased outputs. Our method goes beyond merely detecting bias for a given prompt. Rather, it leverages agenetic algorithmto iteratively refine a pool of prompts, seeking for those that expose biases. This optimization process is driven by a novelbias score, which ranks biases according to their severity, as we validate on a dataset with known biases. For a given prompt, this score is obtained by comparing the distribution of generated images to the distribution ofLLM-generated textsthat constitute variations on the prompt. Code and examples are available on the project's webpage. Text-to-Image (TTI) models generate images based on text prompts, which often leave certain aspects of the desired image ambiguous. When faced with these ambiguities, TTI models have been shown to exhibit biases in their interpretations. These biases can have societal impacts, e.g., when showing only a certain race for a stated occupation. They can also affect user experience when creating redundancy within a set of generated images instead of spanning diverse possibilities. Here, we introduce MineTheGap - a method for automatically mining prompts that cause a TTI model to generate biased outputs. Our method goes beyond merely detecting bias for a given prompt. Rather, it leverages a genetic algorithm to iteratively refine a pool of prompts, seeking for those that expose biases. This optimization process is driven by a novel bias score, which ranks biases according to their severity, as we validate on a dataset with known biases. For a given prompt, this score is obtained by comparing the distribution of generated images to the distribution of LLM-generated texts that constitute variations on the prompt. arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/minethegap-automatic-mining-of-biases-in-text-to-image-models-3350-21e278d8 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2552085",
    "title": "MineTheGap: Automatic Mining of Biases in Text-to-Image Models",
    "authors": [
      "Noa Cohen"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.13427",
    "upvote": 2
  }
}