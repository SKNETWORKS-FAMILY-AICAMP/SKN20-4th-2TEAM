{
  "context": "Text-to-Audio-Video (T2AV) generation aims to synthesize temporally coherent video and semantically synchronized audio from natural language, yet its evaluation remains fragmented, often relying on unimodal metrics or narrowly scoped benchmarks that fail to capture cross-modal alignment, instruction following, and perceptual realism under complex prompts. To address this limitation, we present T2AV-Compass, a unified benchmark for comprehensive evaluation of T2AV systems, consisting of 500 diverse and complex prompts constructed via a taxonomy-driven pipeline to ensure semantic richness and physical plausibility. Besides, T2AV-Compass introduces a dual-level evaluation framework that integrates objective signal-level metrics for video quality, audio quality, and cross-modal alignment with a subjective MLLM-as-a-Judge protocol for instruction following and realism assessment. Extensive evaluation of 11 representative T2AVsystems reveals that even the strongest models fall substantially short of human-level realism and cross-modal consistency, with persistent failures in audio realism, fine-grained synchronization, instruction following, etc. These results indicate significant improvement room for future models and highlight the value of T2AV-Compass as a challenging and diagnostic testbed for advancing text-to-audio-video generation. Text-to-Audio-Video (T2AV) generation aims to synthesize temporally coherent video and semantically synchronized audio from natural language, yet its evaluation remains fragmented, oftenrelying on unimodal metrics or narrowly scoped benchmarks that fail to capture cross-modalalignment, instruction following, and perceptual realism under complex prompts. To address thislimitation, we present T2AV-Compass, a unified benchmark for comprehensive evaluation ofT2AV systems, consisting of 500 diverse and complex prompts constructed via a taxonomy-drivenpipeline to ensure semantic richness and physical plausibility. Besides, T2AV-Compass introducesa dual-level evaluation framework that integrates objective signal-level metrics for video quality, audio quality, and cross-modal alignment with a subjective MLLM-as-a-Judge protocol forinstruction following and realism assessment. arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/t2av-compass-towards-unified-evaluation-for-text-to-audio-video-generation-1896-ec0e575c Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2552033",
    "title": "T2AV-Compass: Towards Unified Evaluation for Text-to-Audio-Video Generation",
    "authors": [
      "Zhe Cao",
      "Jiaming Wang",
      "Jiahao Wang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/NJU-LINK/T2AV-Compass/",
    "huggingface_url": "https://huggingface.co/papers/2512.21094",
    "upvote": 24
  }
}