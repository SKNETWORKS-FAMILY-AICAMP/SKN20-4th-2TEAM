{
  "context": "Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate-scale lens and introduce ThinkARM (Anatomy of Reasoning in Models), a scalable framework that explicitly abstracts reasoning traces into functional reasoning steps such as Analysis, Explore, Implement, Verify, etc. When applied to mathematical problem solving by diverse models, this abstraction reveals reproducible thinking dynamics and structural differences between reasoning and non-reasoning models, which are not apparent from token-level views. We further present two diagnostic case studies showing that exploration functions as a critical branching step associated with correctness, and that efficiency-oriented methods selectively suppress evaluative feedback steps rather than uniformly shortening responses. Together, our results demonstrate that episode-level representations make reasoning steps explicit, enabling systematic analysis of how reasoning is structured, stabilized, and altered in modern language models. We extend a cognitive science-inspired episode annotation framework to an automatic, scalable, sentence-level representation that supports large-scale analysis of reasoning traces and conduct a systematic study of reasoning dynamics across a diverse set of LLMs. Moreover, we demonstrate the practical utility of episode-level representations through downstream case studies on correctness and efficiency, illustrating how reasoning dynamics can be analyzed beyond outcome-based metrics. Key Findings: When reasoning traces are analyzed at the episode level,a functional progression from abstract reasoning to concrete execution, and finally to evaluative control, consistently emerges.Episodes associated with analysis and exploration use more abstract, conceptual language anddecreasesteadily as reasoning progresses, while execution-oriented episodesdominatethe middle of the trace through sustained concrete operations. In contrast, verification-related episodes are characterized by evaluative and meta-level language andincreasetoward the end of the reasoning process. Comparing reasoning and non-reasoning models, the difference is not merely how many tokens they generate, but how reasoning is structured.Non-reasoning models allocate most of their response trace to execution, with episode transitions largely following a feed-forward pattern toward implementation. In contrast,reasoning models distribute effort across analysis, exploration, execution, and verification, and exhibit frequent iterative Explore-Monitor/Verify loops. Through our correctness-oriented case study, we find thatexploration reflects uncertainty and serves as a critical branching point: correct solutions more often route exploration into monitoring or re-analysis, whereas incorrect solutions tend to continue execution or terminate prematurely after exploration. Through our efficiency-oriented case study, we find thatdifferent efficient reasoning methods selectively suppress evaluation-oriented episodes and feedback loops, leading to varying degrees of divergencefrom the reasoning patterns of the base model. Episode-level analysis thus reveals which episodes can be removed to gain efficiency, beyond token-level pruning. We open-sourced the annotated data athttps://github.com/MingLiiii/ThinkARM: arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/schoenfeld-s-anatomy-of-mathematical-reasoning-by-language-models-6489-cd118a42 arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/schoenfelds-anatomy-of-mathematical-reasoning-by-language-models This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2552050",
    "title": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
    "authors": [
      "Yize Cheng",
      "Tianyi Zhou"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/MingLiiii/ThinkARM",
    "huggingface_url": "https://huggingface.co/papers/2512.19995",
    "upvote": 14
  }
}