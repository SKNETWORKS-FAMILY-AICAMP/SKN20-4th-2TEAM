{
  "context": "4D-RGPT, a specialized multimodal LLM, enhances 4D perception in video inputs through Perceptual 4D Distillation and is evaluated on R4D-Bench, a new benchmark for depth-aware dynamic scenes. Despite advances inMultimodal LLMs(MLLMs), their ability to reason over 3D structures and temporal dynamics remains limited, constrained by weak 4D perception and temporal understanding. Existing 3D and4D Video Question Answering(VQA) benchmarks also emphasize static scenes and lackregion-level prompting. We tackle these issues by introducing: (a)4D-RGPT, a specialized MLLM designed to capture4D representationsfrom video inputs with enhanced temporal perception; (b)Perceptual 4D Distillation(P4D), a training framework that transfers4D representationsfrom a frozen expert model into4D-RGPTfor comprehensive 4D perception; and (c)R4D-Bench, a benchmark fordepth-awaredynamic sceneswithregion-level prompting, built via a hybrid automated and human-verified pipeline. Our4D-RGPTachieves notable improvements on both existing 4D VQA benchmarks and the proposedR4D-Benchbenchmark. Project page:https://www.ca-joe-yang.com/resource/projects/4D_RGPT arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/4d-rgpt-toward-region-level-4d-understanding-via-perceptual-distillation-1806-b2c771e8 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2552018",
    "title": "4D-RGPT: Toward Region-level 4D Understanding via Perceptual Distillation",
    "authors": [
      "Min-Hung Chen"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.17012",
    "upvote": 42
  }
}