{
  "context": "Step-DeepResearch, an end-to-end agent enhanced with a data synthesis strategy and progressive training, achieves expert-level capabilities in deep research scenarios, outperforming established models. As LLMs shift toward autonomous agents,Deep Researchhas emerged as a pivotal metric. However, existing academic benchmarks likeBrowseCompoften fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduceStep-DeepResearch, a cost-effective, end-to-end agent. We propose aData Synthesis StrategyBased onAtomic Capabilitiesto reinforce planning and report writing, combined with a progressive training path fromagentic mid-trainingtoSFTandRL. Enhanced by aChecklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establishADR-Benchfor realisticdeep researchscenarios. Experimental results show thatStep-DeepResearch(32B) scores 61.4% onScale AI Research Rubrics. OnADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models likeOpenAIandGemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency. As LLMs shift toward autonomous agents, Deep Research has emerged as a pivotal metric. However, existing academic benchmarks like BrowseComp often fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduce Step-DeepResearch, a cost-effective, end-to-end agent. We propose a Data Synthesis Strategy Based on Atomic Capabilities to reinforce planning and report writing, combined with a progressive training path from agentic mid-training to SFT and RL. Enhanced by a Checklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establish ADR-Bench for realistic deep research scenarios. Experimental results show that Step-DeepResearch (32B) scores 61.4% on Scale AI Research Rubrics. On ADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models like OpenAI and Gemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency. Many thanks for@taesiri's contributions. It appears the latest version has been updated on arXiv. Could you please help update the corresponding paper version on Hugging Face?\" arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/step-deepresearch-technical-report-1855-b4852a8e Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2552005",
    "title": "Step-DeepResearch Technical Report",
    "authors": [
      "Xiaoyun Zhang",
      "Xikai Liu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/stepfun-ai/StepDeepResearch",
    "huggingface_url": "https://huggingface.co/papers/2512.20491",
    "upvote": 79
  }
}