{
  "context": "Memory-T1, a framework using reinforcement learning, enhances temporal reasoning in long dialogues by selecting relevant sessions and ensuring temporal consistency, achieving state-of-the-art performance on the Time-Dialog benchmark. Temporal reasoningover long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context models struggle to accurately identify temporally pertinent information, significantly impairing reasoning performance. To address this, we introduce Memory-T1, a framework that learns atime-aware memoryselection policy usingreinforcement learning(RL). It employs acoarse-to-fine strategy, first pruning thedialogue historyinto a candidate set using temporal and relevance filters, followed by anRLagent that selects the precise evidence sessions. TheRLtraining is guided by a multi-levelreward functionoptimizing (i) answer accuracy, (ii)evidence grounding, and (iii)temporal consistency. In particular, thetemporal consistencyreward provides a dense signal by evaluating alignment with the query time scope at both thesession-level(chronological proximity) and theutterance-level(chronological fidelity), enabling the agent to resolve subtle chronological ambiguities. On theTime-Dialog benchmark, Memory-T1 boosts a 7B model to an overall score of 67.0\\%, establishing a new state-of-the-art performance for open-source models and outperforming a 14B baseline by 10.2\\%. Ablation studies showtemporal consistencyandevidence groundingrewards jointly contribute to a 15.0\\%performance gain. Moreover, Memory-T1 maintainsrobustnessup to 128k tokens, where baseline models collapse, proving effectiveness against noise in extensive dialogue histories. The code and datasets are publicly available at https://github.com/Elvin-Yiming-Du/Memory-T1/ Temporal reasoning over long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context models struggle to accurately identify temporally pertinent information, significantly impairing reasoning performance. To address this, we introduce Memory-T1, a framework that learns a time-aware memory selection policy using reinforcement learning (RL). It employs a coarse-to-fine strategy, first pruning the dialogue history into a candidate set using temporal and relevance filters, followed by an RL agent that selects the precise evidence sessions. The RL training is guided by a multi-level reward function optimizing (i) answer accuracy, (ii) evidence grounding, and (iii) temporal consistency. In particular, the temporal consistency reward provides a dense signal by evaluating alignment with the query time scope at both the session-level (chronological proximity) and the utterance-level (chronological fidelity), enabling the agent to resolve subtle chronological ambiguities. On the Time-Dialog benchmark, Memory-T1 boosts a 7B model to an overall score of 67.0%, establishing a new state-of-the-art performance for open-source models and outperforming a 14B baseline by 10.2%. Ablation studies show temporal consistency and evidence grounding rewards jointly contribute to a 15.0% performance gain. Moreover, Memory-T1 maintains robustness up to 128k tokens, where baseline models collapse, proving effectiveness against noise in extensive dialogue histories. The code and datasets are publicly available athttps://github.com/Elvin-Yiming-Du/Memory-T1/ arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/memory-t1-reinforcement-learning-for-temporal-reasoning-in-multi-session-agents-8019-8635e8d6 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2552072",
    "title": "Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents",
    "authors": [
      "Yiming Du",
      "Zhaowei Wang",
      "Yuxin Jiang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Elvin-Yiming-Du/Memory-T1",
    "huggingface_url": "https://huggingface.co/papers/2512.20092",
    "upvote": 8
  }
}