{
  "context": "HyperVL, an efficient multimodal large language model for on-device inference, uses image tiling, Visual Resolution Compressor, and Dual Consistency Learning to reduce memory usage, latency, and power consumption while maintaining performance. Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standardVision Transformer (ViT)encoders remain a critical bottleneck, suffering from excessivelatencyand memory consumption when processing high-resolution inputs.To address these challenges, we introduce HyperVL, an efficient multimodal large language model tailored foron-device inference. HyperVL adopts animage-tiling strategyto cap peak memory usage and incorporates two novel techniques: (1) aVisual Resolution Compressor(VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2)Dual Consistency Learning(DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiplebenchmarks. Furthermore, it significantly significantly reduceslatencyandpower consumptionon real mobile devices, demonstrating its practicality for on-device multimodal inference. üöÄ[New Paper] HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices Current multimodal large language models (MLLMs) possess strong perceptual and reasoning capabilities, but their high computational and memory requirements make them difficult to deploy directly on edge devices. HyperVL aims to tackle this challenge by introducing an efficient multimodal large language model tailored for on-device inference. ‚ú®The Core Intuition: HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: 1Ô∏è‚É£Visual Resolution Compressor (VRC):Adaptively predicts optimal encoding resolutions to eliminate redundant computation. 2Ô∏è‚É£Dual Consistency Learning (DCL):Aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. üìàHighlights: arXiv lens breakdown of this paper üëâhttps://arxivlens.com/PaperView/Details/hypervl-an-efficient-and-dynamic-multimodal-large-language-model-for-edge-devices-846-98deea02 ¬∑Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551023",
    "title": "HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices",
    "authors": [
      "Chen Song"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.14052",
    "upvote": 40
  }
}