{
  "context": "Skyra, a specialized multimodal large language model, detects and explains visual artifacts in AI-generated videos using a novel dataset and two-stage training strategy, outperforming existing methods. The misuse of AI-driven video generation technologies has raised serious social concerns, highlighting the urgent need for reliableAI-generated video detectors. However, most existing methods are limited to binary classification and lack the necessary explanations for human interpretation. In this paper, we present Skyra, a specializedmultimodal large language model(MLLM) that identifies human-perceivablevisual artifactsin AI-generated videos and leverages them as grounded evidence for both detection and explanation. To support this objective, we constructViF-CoT-4KforSupervised Fine-Tuning(SFT), which represents the first large-scale AI-generated video artifact dataset with fine-grained human annotations. We then develop a two-stage training strategy that systematically enhances our model'sspatio-temporal artifact perception,explanation capability, anddetection accuracy. To comprehensively evaluate Skyra, we introduceViF-Bench, a benchmark comprising 3K high-quality samples generated by over ten state-of-the-art video generators. Extensive experiments demonstrate that Skyra surpasses existing methods across multiple benchmarks, while our evaluation yields valuable insights for advancingexplainable AI-generated video detection. Skyra: AI-Generated Video Detection via Grounded Artifact Reasoninghttps://huggingface.co/papers/2512.15693 Explainable AI-generated video detection with a specialized multimodal LLM. Given an input video, Skyra explicitly identifies human-perceivable spatio-temporal artifacts (e.g., texture/structure inconsistencies, motion irregularities) and uses them as grounded evidence to produce both a real/fake decision and a human-interpretable explanation with localized cues. To train this capability, we introduce ViF-CoT-4K, the first large-scale AI-generated video artifact dataset with fine-grained human annotations, enabling supervised fine-tuning (Skyra-SFT). We further apply a second-stage reinforcement learning procedure to encourage the model to actively mine discriminative artifacts, improving both detection and explanation quality (Skyra-RL). For rigorous evaluation, we release ViF-Bench (3K high-quality samples from 10+ state-of-the-art video generators) with aligned real/fake semantics and formats to reduce shortcut signals, and demonstrate consistent gains over prior binary detectors and MLLM-based baselines.Learn more athttps://joeleelyf.github.io/Skyraandhttps://github.com/JoeLeelyf/Skyra.  arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/skyra-ai-generated-video-detection-via-grounded-artifact-reasoning-3336-22fb155d Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551055",
    "title": "Skyra: AI-Generated Video Detection via Grounded Artifact Reasoning",
    "authors": [
      "Yifei Li",
      "Yanran Zhang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/JoeLeelyf/Skyra",
    "huggingface_url": "https://huggingface.co/papers/2512.15693",
    "upvote": 17
  }
}