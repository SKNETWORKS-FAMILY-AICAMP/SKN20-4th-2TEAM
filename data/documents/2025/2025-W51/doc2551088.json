{
  "context": "Pixel-space self-supervised learning using an enhanced masked autoencoder achieves competitive performance across diverse downstream tasks while maintaining simplicity and efficiency. At the most basic level, pixels are the source of the visual information through which we perceive the world. Pixels contain information at all levels, ranging from low-level attributes to high-level concepts.Autoencodersrepresent a classical and long-standing paradigm for learning representations from pixels or other raw inputs. In this work, we demonstrate that autoencoder-basedself-supervised learningremains competitive today and can produce strong representations fordownstream tasks, while remaining simple, stable, and efficient. Our model, codenamed \"Pixio\", is an enhancedmasked autoencoder(MAE) with more challenging pre-training tasks and more capable architectures. The model is trained on 2B web-crawled images with a self-curation strategy with minimal human curation. Pixio performs competitively across a wide range ofdownstream tasksin the wild, including monocular depth estimation (e.g.,Depth Anything), feed-forward 3D reconstruction (i.e.,MapAnything),semantic segmentation, androbot learning, outperforming or matchingDINOv3trained at similar scales. Our results suggest that pixel-spaceself-supervised learningcan serve as a promising alternative and a complement to latent-space approaches. arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/in-pursuit-of-pixel-supervision-for-visual-pre-training-8810-5e30657e Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551088",
    "title": "In Pursuit of Pixel Supervision for Visual Pre-training",
    "authors": [
      "Shang-Wen Li"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/facebookresearch/pixio",
    "huggingface_url": "https://huggingface.co/papers/2512.15715",
    "upvote": 8
  }
}