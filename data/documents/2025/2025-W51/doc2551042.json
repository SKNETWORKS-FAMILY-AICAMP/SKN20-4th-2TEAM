{
  "context": "REGLUE, a unified latent diffusion framework, enhances image synthesis by jointly modeling VAE latents, patch-level VFM semantics, and global tokens, improving semantic supervision and convergence. Latent diffusion models(LDMs) achieve state-of-the-art image synthesis, yet their reconstruction-style denoising objective provides only indirect semantic supervision: high-level semantics emerge slowly, requiring longer training and limiting sample quality. Recent works inject semantics fromVision Foundation Models(VFMs) either externally viarepresentation alignmentor internally by jointly modeling only a narrow slice of VFM features inside the diffusion process, under-utilizing the rich, nonlinear, multi-layer spatial semantics available. We introduce REGLUE (Representation Entanglement with Global-Local Unified Encoding), a unified latent diffusion framework that jointly models (i)VAEimage latents, (ii) compact local (patch-level) VFM semantics, and (iii) a global (image-level) [CLS] token within a singleSiT backbone. A lightweightconvolutional semantic compressornonlinearly aggregatesmulti-layer VFM featuresinto a low-dimensional, spatially structured representation, which is entangled with theVAElatents in the diffusion process. Anexternal alignment lossfurther regularizes internal representations toward frozen VFM targets. On ImageNet 256x256, REGLUE consistently improvesFIDand accelerates convergence over SiT-B/2 and SiT-XL/2 baselines, as well as over REPA, ReDi, and REG. Extensive experiments show that (a) spatial VFM semantics are crucial, (b) non-linear compression is key to unlocking their full benefit, and (c) global tokens and external alignment act as complementary, lightweight enhancements within our global-local-latent joint modeling framework. The code is available at https://github.com/giorgospets/reglue .  Latent diffusion models (LDMs) achieve state-of-the-art image synthesis, yet their reconstruction-style denoising objective provides only indirect semantic supervision: high-level semantics emerge slowly, requiring longer training and limiting sample quality. Recent works inject semantics from Vision Foundation Models (VFMs) either externally via representation alignment or internally by jointly modeling only a narrow slice of VFM features inside the diffusion process, under-utilizing the rich, nonlinear, multi-layer spatial semantics available. We introduce REGLUE (Representation Entanglement with Global-Local Unified Encoding), a unified latent diffusion framework that jointly models (i) VAE image latents, (ii) compact local (patch-level) VFM semantics, and (iii) a global (image-level) [CLS] token within a single SiT backbone. A lightweight convolutional semantic compressor nonlinearly aggregates multi-layer VFM features into a low-dimensional, spatially structured representation, which is entangled with the VAE latents in the diffusion process. An external alignment loss further regularizes internal representations toward frozen VFM targets. On ImageNet 256x256, REGLUE consistently improves FID and accelerates convergence over SiT-B/2 and SiT-XL/2 baselines, as well as over REPA, ReDi, and REG. Extensive experiments show that (a) spatial VFM semantics are crucial, (b) non-linear compression is key to unlocking their full benefit, and (c) global tokens and external alignment act as complementary, lightweight enhancements within our global-local-latent joint modeling framework. arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/reglue-your-latents-with-global-and-local-semantics-for-entangled-diffusion-9971-3531857a Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551042",
    "title": "REGLUE Your Latents with Global and Local Semantics for Entangled Diffusion",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/giorgospets/reglue",
    "huggingface_url": "https://huggingface.co/papers/2512.16636",
    "upvote": 25
  }
}