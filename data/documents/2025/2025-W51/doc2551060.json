{
  "context": "RecGPT-V2 enhances recommender systems by integrating a Hierarchical Multi-Agent System, Hybrid Representation Inference, Meta-Prompting, constrained reinforcement learning, and an Agent-as-a-Judge framework to improve efficiency, explanation diversity, generalization, and human preference alignment. Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicitintent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and itemtag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficientexplanation diversityin fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.\n  To address these challenges, we present RecGPT-V2 with four key innovations. First, aHierarchical Multi-Agent Systemrestructuresintent reasoningthrough coordinated collaboration, eliminatingcognitive duplicationwhile enabling diverse intent coverage. Combined withHybrid Representation Inferencethat compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, aMeta-Promptingframework dynamically generates contextually adaptive prompts, improvingexplanation diversityby +7.3%. Third,constrained reinforcement learningmitigates multi-reward conflicts, achieving +24.1% improvement intag predictionand +13.0% inexplanation acceptance. Fourth, anAgent-as-a-Judgeframework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98%CTR, +3.71%IPV, +2.19%TV, and +11.46%NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-poweredintent reasoningat scale, bridging the gap between cognitive exploration and industrial utility. ðŸŒŸ RecGPT-V2: A Major Leap in LLM-Powered Recommendation (RecGPT-V1â€™s Power Upgrade!) ðŸŒŸ Thrilled to unveil RecGPT-V2â€”the highly anticipated successor to RecGPT-V1! This agentic framework addresses V1â€™s core limitations, fusing cognitive reasoning with industrial scalability for next-gen intent-centric recommendations. ðŸ”¥ Core Innovations:Hierarchical Multi-Agent + Hybrid Representation: 60% less GPU usage, 9.39%â†’10.99% exclusive recall, and 32Kâ†’11K token compression (context intact).Meta-Prompting: +7.3% explanation diversity with adaptive, non-generic prompts.Constrained RL: Resolves multi-reward conflictsâ€”+24.1% better tag prediction and +13.0% higher explanation acceptance vs. V1.Agent-as-a-Judge: Human-like multi-step evaluation, closer alignment with real-world standards. ðŸš€ Taobao A/B Test Results:+2.98% CTR | +3.71% IPV | +2.19% TV | +11.46% NER (Novelty Exposure Rate) Validated for large-scale deploymentâ€”bridging cognitive AI and practical utility, with room to evolve. ðŸŽ¯ Why It Matters:Fixes V1â€™s pain points (computational bloat, rigid explanations, weak generalization, oversimplified evaluation) to deliver a scalable, efficient, human-aligned paradigm. Perfect for researchers and engineersâ€”this is just a key milestone in refining intent-driven AI! ðŸ‘‰ Dive into the full technical report to unlock scalable intent-driven recommendations. Letâ€™s shape personalized AI4Recâ€™s future! Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551060",
    "title": "RecGPT-V2 Technical Report",
    "authors": [
      "Gaoyang Guo",
      "Jiakai Tang",
      "Zhujin Gao"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.14503",
    "upvote": 16
  }
}