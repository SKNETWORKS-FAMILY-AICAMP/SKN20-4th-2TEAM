{
  "context": "This survey provides an updated overview of agent memory research, distinguishing its forms, functions, and dynamics, and highlights emerging research directions. Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research onagent memoryrapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella ofagent memoryoften differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporaryagent memorysystems. This work aims to provide an up-to-date landscape of currentagent memoryresearch. We begin by clearly delineating the scope ofagent memoryand distinguishing it from related concepts such asLLM memory,retrieval augmented generation (RAG), andcontext engineering. We then examineagent memorythrough the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations ofagent memory, namely token-level, parametric, andlatent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, andworking memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary ofmemory benchmarksandopen-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, includingmemory automation,reinforcement learning integration,multimodal memory,multi-agent memory, andtrustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence. Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend This survey does something the field badly needed: it treats memory as a first-class primitive rather than a bolt-on hack. The forms/functions/dynamics framing is especially useful â€” token, parametric, and latent memory map cleanly to factual, experiential, and working memory in cognition. The real insight here is that agent failures arenâ€™t about model size, but about missing memory dynamics: formation, decay, consolidation, and retrieval. If agents are going to move from reactive tools to adaptive systems, this is the conceptual reset point. arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/memory-in-the-age-of-ai-agents-5321-21a1a74a arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/memory-in-the-age-of-ai-agents Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551002",
    "title": "Memory in the Age of AI Agents",
    "authors": [
      "Yuyang Hu",
      "Shichun Liu",
      "Guibin Zhang",
      "Honglin Guo",
      "Jiejun Tan",
      "Zhongxiang Sun"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Shichun-Liu/Agent-Memory-Paper-List",
    "huggingface_url": "https://huggingface.co/papers/2512.13564",
    "upvote": 129
  }
}