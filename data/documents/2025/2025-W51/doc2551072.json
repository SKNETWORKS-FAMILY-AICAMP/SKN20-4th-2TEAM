{
  "context": "Multimodal RewardBench 2 (MMRB2) is a benchmark for reward models on multimodal understanding and generation tasks, featuring expert-annotated preferences and state-of-the-art model evaluations. Reward models(RMs) are essential for traininglarge language models(LLMs), but remain underexplored foromni modelsthat handle interleaved image and text sequences. We introduceMultimodal RewardBench 2(MMRB2), the first comprehensive benchmark forreward modelson multimodal understanding and (interleaved) generation.MMRB2spans four tasks:text-to-image,image editing,interleaved generation, andmultimodal reasoning(\"thinking-with-images\"), providing 1,000 expert-annotated preference pairs per task from 23 models and agents across 21 source tasks.MMRB2is designed with: (1) practical but challenging prompts; (2) responses from state-of-the-art models and agents; and (3) preference pairs with strong human-expert consensus, curated via an ensemble filtering strategy. UsingMMRB2, we study existing judges for each subtask, includingmultimodal LLM-as-a-judgeand models trained with human preferences. The latest Gemini 3 Pro attains 75-80% accuracy. GPT-5 and Gemini 2.5 Pro reach 66-75% accuracy, compared to >90% for humans, yet surpass the widely used GPT-4o (59%). The best performing open-source model Qwen3-VL-32B achieves similar accuracies as Gemini 2.5 Flash (64%). We also show thatMMRB2performance strongly correlates with downstream task success usingBest-of-N samplingand conduct an in-depth analysis that shows key areas to improve thereward modelsgoing forward. Reward models are the most critical part of post-training for Omni models like nano banana, but it is barely studied in the open-source world. To build the foundation for future research on better post-training and RL for Omni models, FAIR at Meta Superintelligence Labs released their reward benchmark. arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/multimodal-rewardbench-2-evaluating-omni-reward-models-for-interleaved-text-and-image-4504-324ab751 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551072",
    "title": "Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/facebookresearch/MMRB2/tree/main",
    "huggingface_url": "https://huggingface.co/papers/2512.16899",
    "upvote": 12
  }
}