{
  "context": "A panoramic metric depth foundation model using DINOv3-Large and a three-stage pseudo-label pipeline achieves robust performance across diverse real-world scenes. In this work, we present a panoramic metric depth foundation model that generalizes across diverse scene distances. We explore a data-in-the-loop paradigm from the view of both data construction and framework design. We collect a large-scale dataset by combining public datasets, high-quality synthetic data from our UE5 simulator and text-to-image models, and real panoramic images from the web. To reduce domain gaps between indoor/outdoor and synthetic/real data, we introduce a three-stagepseudo-label curation pipelineto generate reliable ground truth for unlabeled images. For the model, we adoptDINOv3-Largeas the backbone for its strong pre-trained generalization, and introduce a plug-and-playrange mask head,sharpness-centric optimization, andgeometry-centric optimizationto improve robustness to varying distances and enforce geometric consistency across views. Experiments on multiple benchmarks (e.g.,Stanford2D3D,Matterport3D, andDeep360) demonstrate strong performance and zero-shot generalization, with particularly robust and stable metric predictions in diverse real-world scenes. The project page can be found at: https://insta360-research-team.github.io/DAP_website/ {https://insta360-research-team.github.io/DAP\\_website/} In this work, we present a panoramic metric depth foundation model that generalizes across diverse scene distances. We explore a data-in-the-loop paradigm from the view of both data construction and framework design. We collect a large-scale dataset by combining public datasets, high-quality synthetic data from our UE5 simulator and text-to-image models, and real panoramic images from the web. To reduce domain gaps between indoor/outdoor and synthetic/real data, we introduce a three-stage pseudo-label curation pipeline to generate reliable ground truth for unlabeled images. For the model, we adopt DINOv3-Large as the backbone for its strong pre-trained generalization, and introduce a plug-and-play range mask head, sharpness-centric optimization, and geometry-centric optimization to improve robustness to varying distances and enforce geometric consistency across views. Experiments on multiple benchmarks (e.g., Stanford2D3D, Matterport3D, and Deep360) demonstrate strong performance and zero-shot generalization, with particularly robust and stable metric predictions in diverse real-world scenes. The project page can be found at:https://insta360-research-team.github.io/DAPwebsite/ arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/depth-any-panoramas-a-foundation-model-for-panoramic-depth-estimation-1693-666834dd Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2551034",
    "title": "Depth Any Panoramas: A Foundation Model for Panoramic Depth Estimation",
    "authors": [
      "Haodong Li"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Insta360-Research-Team/DAP",
    "huggingface_url": "https://huggingface.co/papers/2512.16913",
    "upvote": 33
  }
}