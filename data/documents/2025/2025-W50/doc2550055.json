{
  "context": "Arbitrage is a dynamic routing framework for speculative decoding that improves efficiency in large language model inference by predicting when the target model will provide a better step, outperforming traditional step-level methods. Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques,Speculative Decodingaccelerates inference by employing a fast but inaccuratedraft modelto autoregressively propose tokens, which are then verified in parallel by a more capabletarget model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditionaltoken-level Speculative Decodingstruggles in reasoning tasks. Although recent works have shifted tostep-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we proposeArbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft andtarget models. Instead of applying a fixed acceptance threshold,Arbitrageuses a lightweightroutertrained to predict when thetarget modelis likely to produce a meaningfully better step. This routing approximates an idealArbitrage Oraclethat always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks,Arbitrageconsistently surpasses prior step-levelSpeculative Decodingbaselines, reducinginference latencyby up to sim2times at matched accuracy. Modern large language models achieve impressive reasoning capabilities with long chains of thought, but they incur substantial computational cost at inference time. Speculative decoding improves efficiency by using a fast, less accurate draft model to propose tokens that are then verified in parallel by a stronger target model. However, on reasoning tasks, traditional token-level speculative decoding often rejects many semantically valid steps due to superficial token mismatches. Recent step-level semantic verification methods mitigate this by accepting or rejecting entire reasoning steps, but they still waste target compute by regenerating many rejected steps that yield little quality gain. We proposeARBITRAGE, a step-level speculative generation framework that dynamically routes generation based on the relative advantage of the target model over the draft model. Instead of relying on a fixed acceptance threshold, ARBITRAGE uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal “arbitrage oracle” that always selects the higher-quality step, achieving near-optimal efficiency–accuracy trade-offs. Across multiple mathematical reasoning benchmarks, ARBITRAGE consistently outperforms prior step-level speculative decoding baselines,reducing inference latency by up to approximately 2×at matched accuracy. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550055",
    "title": "Arbitrage: Efficient Reasoning via Advantage-Aware Speculation",
    "authors": [
      "Monishwaran Maheswaran",
      "Yuezhou Hu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/SqueezeAILab/Arbitrage",
    "huggingface_url": "https://huggingface.co/papers/2512.05033",
    "upvote": 15
  }
}