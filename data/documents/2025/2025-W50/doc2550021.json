{
  "context": "DeepCode, a fully autonomous framework, addresses the challenges of document-to-codebase synthesis by optimizing information flow through source compression, structured indexing, knowledge injection, and error correction, achieving state-of-the-art performance and surpassing human experts. Recent advances inlarge language models(LLMs) have given rise to powerfulcoding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face significant challenges in achieving high-fidelitydocument-to-codebase synthesis--such as scientific papers to code--primarily due to a fundamental conflict betweeninformation overloadand thecontext bottlenecksof LLMs. In this work, we introduceDeepCode, a fully autonomous framework that fundamentally addresses this challenge through principled information-flow management. By treating repository synthesis as achannel optimizationproblem,DeepCodeseamlessly orchestrates four information operations to maximize task-relevant signals under finite context budgets: source compression viablueprint distillation, structured indexing usingstateful code memory, conditional knowledge injection viaretrieval-augmented generation, andclosed-loop error correction. Extensive evaluations on thePaperBenchbenchmark demonstrate thatDeepCodeachieves state-of-the-art performance, decisively outperforming leading commercial agents such as Cursor and Claude Code, and crucially, surpassing PhD-level human experts from top institutes on key reproduction metrics. By systematically transforming paper specifications into production-grade implementations comparable to human expert quality, this work establishes new foundations forautonomous scientific reproductionthat can accelerate research evaluation and discovery. Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face significant challenges in achieving high-fidelity document-to-codebase synthesis--such as scientific papers to code--primarily due to a fundamental conflict between information overload and the context bottlenecks of LLMs. In this work, we introduce DeepCode, a fully autonomous framework that fundamentally addresses this challenge through principled information-flow management. By treating repository synthesis as a channel optimization problem, DeepCode seamlessly orchestrates four information operations to maximize task-relevant signals under finite context budgets: source compression via blueprint distillation, structured indexing using stateful code memory, conditional knowledge injection via retrieval-augmented generation, and closed-loop error correction. Extensive evaluations on the PaperBench benchmark demonstrate that DeepCode achieves state-of-the-art performance, decisively outperforming leading commercial agents such as Cursor and Claude Code, and crucially, surpassing PhD-level human experts from top institutes on key reproduction metrics. By systematically transforming paper specifications into production-grade implementations comparable to human expert quality, this work establishes new foundations for autonomous scientific reproduction that can accelerate research evaluation and discovery. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550021",
    "title": "DeepCode: Open Agentic Coding",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/HKUDS/DeepCode",
    "huggingface_url": "https://huggingface.co/papers/2512.07921",
    "upvote": 31
  }
}