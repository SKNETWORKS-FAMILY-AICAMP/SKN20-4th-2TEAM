{
  "context": "Efficient video reasoning can be achieved using concise chains of thought and reduced visual tokens without manual annotations or supervised fine-tuning. Chain-of-thought(CoT) reasoning has been highly successful in solving complex tasks in natural language processing, and recentmultimodal large language models(MLLMs) have extended this paradigm tovideo reasoning. However, these models typically build on lengthy reasoning chains and large numbers of inputvisual tokens. Motivated by empirical observations from our benchmark study, we hypothesize that concise reasoning combined with a reduced set ofvisual tokenscan be sufficient for effectivevideo reasoning. To evaluate this hypothesis, we design and validate an efficientpost-trainingandinference frameworkthat enhances a video MLLM's reasoning capability. Our framework enables models to operate on compressedvisual tokensand generate briefreasoning tracesprior to answering. The resulting models achieve substantially improvedinference efficiency, deliver competitive performance across diversebenchmarks, and avoid reliance on manual CoT annotations or supervised fine-tuning. Collectively, our results suggest that long,human-like CoT reasoningmay not be necessary for generalvideo reasoning, and that concise reasoning can be both effective and efficient. Our code will be released at https://github.com/LaVi-Lab/Rethink_CoT_Video. Rethinking Chain-of-Thought Reasoning for Videos This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Nice work! Our work also tackles a similar problem where we achieve efficient video reasoning without any training.https://huggingface.co/papers/2510.17045We introduce a training-free method for enhancing video reasoning via value cache optimization during inference that narrows the gap to RL-trained models with fewer output tokens. We plan to discuss your paper in our work as a concurrent method. We would greatly appreciate if you could discuss our paper in a similar vein. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550047",
    "title": "Rethinking Chain-of-Thought Reasoning for Videos",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/LaVi-Lab/Rethink_CoT_Video",
    "huggingface_url": "https://huggingface.co/papers/2512.09616",
    "upvote": 17
  }
}