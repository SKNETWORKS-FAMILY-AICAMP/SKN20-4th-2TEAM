{
  "context": "LongCat-Image is a bilingual open-source foundation model for image generation that addresses multilingual text rendering, photorealism, and deployment efficiency through rigorous data curation, compact design, and comprehensive open-source support. We introduce LongCat-Image, a pioneering open-source and bilingual (Chinese-English)foundation modelforimage generation, designed to address core challenges inmultilingual text rendering,photorealism,deployment efficiency, and developer accessibility prevalent in current leading models. 1) We achieve this through rigorousdata curationstrategies across the pre-training, mid-training, and SFT stages, complemented by the coordinated use of curatedreward modelsduring the RL phase. This strategy establishes the model as a new state-of-the-art (SOTA), delivering superior text-rendering capabilities and remarkablephotorealism, and significantly enhancing aesthetic quality. 2) Notably, it sets a new industry standard for Chinese character rendering. By supporting even complex and rare characters, it outperforms both major open-source and commercial solutions in coverage, while also achieving superior accuracy. 3) The model achieves remarkable efficiency through its compact design. With a corediffusion modelof only 6Bparameters, it is significantly smaller than the nearly 20B or largerMixture-of-Experts(MoE) architectures common in the field. This ensures minimalVRAM usageand rapidinference, significantly reducing deployment costs. Beyond generation, LongCat-Image also excels inimage editing, achieving SOTA results on standard benchmarks with superior editing consistency compared to other open-source works. 4) To fully empower the community, we have established the most comprehensiveopen-source ecosystemto date. We are releasing not only multiple model versions fortext-to-imageandimage editing, including checkpoints after mid-training and post-training stages, but also the entire toolchain oftraining procedure. We believe that the openness of LongCat-Image will provide robust support for developers and researchers, pushing the frontiers of visual content creation. We introduce LongCat-Image, a pioneering open-source and bilingual (Chinese-English) foundation model for image generation, designed to address core challenges in multilingual text rendering, photorealism, deployment efficiency, and developer accessibility prevalent in current leading models. 1) We achieve this through rigorous data curation strategies across the pre-training, mid-training, and SFT stages, complemented by the coordinated use of curated reward models during the RL phase. This strategy establishes the model as a new state-of-the-art (SOTA), delivering superior text-rendering capabilities and remarkable photorealism, and significantly enhancing aesthetic quality. 2) Notably, it sets a new industry standard for Chinese character rendering. By supporting even complex and rare characters, it outperforms both major open-source and commercial solutions in coverage, while also achieving superior accuracy. 3) The model achieves remarkable efficiency through its compact design. With a core diffusion model of only 6B parameters, it is significantly smaller than the nearly 20B or larger Mixture-of-Experts (MoE) architectures common in the field. This ensures minimal VRAM usage and rapid inference, significantly reducing deployment costs. Beyond generation, LongCat-Image also excels in image editing, achieving SOTA results on standard benchmarks with superior editing consistency compared to other open-source works. 4) To fully empower the community, we have established the most comprehensive open-source ecosystem to date. We are releasing not only multiple model versions for text-to-image and image editing, including checkpoints after mid-training and post-training stages, but also the entire toolchain of training procedure. We believe that the openness of LongCat-Image will provide robust support for developers and researchers, pushing the frontiers of visual content creation. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550045",
    "title": "LongCat-Image Technical Report",
    "authors": [
      "Haoxian Tan",
      "Junqiang Wu",
      "Lishuai Gao",
      "Jie Hu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/meituan-longcat/LongCat-Image",
    "huggingface_url": "https://huggingface.co/papers/2512.07584",
    "upvote": 18
  }
}