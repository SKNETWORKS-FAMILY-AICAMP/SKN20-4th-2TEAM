{
  "context": "M3DR is a multilingual multimodal document retrieval framework using contrastive training to achieve robust cross-lingual and cross-modal alignment across diverse languages and document types. Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we presentM3DR(Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts.M3DRleveragessynthetic multilingual document dataand generalizes across differentvision-language architecturesand model sizes, enabling robust cross-lingual and cross-modal alignment. Usingcontrastive training, our models learnunified representationsfor text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings.M3DRgeneralizes across both single dense vector andColBERT-style token-level multi-vectorretrieval paradigms. Our models,NetraEmbedandColNetraEmbedachieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval. Can we build universal document retrievers that maintain strong results across typologically diverse languages without losing English performance. This question led us to design synthetic training data and multilingual benchmarks to teach a model to match documents across scripts and formats. We are excited to launchNetraEmbedour SoTA model for multimodal multilingual document retrieval along with theM3DR: Towards Universal Multilingual Multimodal Document Retrievalpaper. The release includes theNetraEmbed modelwhich produces a single dense embedding with matryoshka support at 768,1536 and 2560 dimensions and theColNetraEmbed modelwhich produces patch level multivector embeddings. Both models are finetuned on Gemma3-4B-it and gained ~150% improvement over baselines. To measure progress we also built theNayanaIR Benchmarkwith 22 multilingual and 1 cross lingual dataset and documented the full framework in theM3DR paper. LinksBlog:https://www.cognitivelab.in/blog/introducing-netraembed This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550079",
    "title": "M3DR: Towards Universal Multilingual Multimodal Document Retrieval",
    "authors": [
      "Adithya S Kolavi",
      "Vyoman Jain"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/adithya-s-k/colpali",
    "huggingface_url": "https://huggingface.co/papers/2512.03514",
    "upvote": 7
  }
}