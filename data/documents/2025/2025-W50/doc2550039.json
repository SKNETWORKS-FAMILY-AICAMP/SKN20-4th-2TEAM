{
  "context": "ThreadWeaver, a framework for adaptive parallel reasoning, achieves accuracy comparable to sequential models while reducing inference latency through parallel trajectory generation, trie-based training-inference co-design, and parallelization-aware reinforcement learning. Scaling inference-time computation has enabledLarge Language Models(LLMs) to achieve strong reasoning performance, but inherentlysequential decodingleads to substantial latency, especially on complex tasks. Recent work onadaptive parallel reasoningaims to improve inference efficiency by decomposing the problem-solving process into concurrent reasoning threads when beneficial. However, existing methods on realistic tasks are either limited to supervised behavior cloning or exhibit significant accuracy drops compared to widely-used sequentiallong chain-of-thought(CoT) baselines. Moreover, many require customized inference engines, complicating deployment. We introduceThreadWeaver, a framework foradaptive parallel reasoningthat achieves accuracy on par with popular sequential reasoning models of comparable size while significantly reducing inference latency.ThreadWeaver's performance stems from three key innovations: 1) a two-stageparallel trajectory generatorthat produces large-scale, high-qualityCoTdata with parallel annotations for supervised fine-tuning; 2) atrie-based training-inference co-designthat enables parallel reasoning on any off-the-shelf autoregressive inference engine without modifying position embeddings or KV caches; and 3) aparallelization-aware reinforcement learningframework that teaches the model to balance accuracy with effective parallelization. Across six challenging mathematical reasoning benchmarks,ThreadWeavertrained atopQwen3-8Bachieves accuracy comparable to cutting-edge sequential reasoning models (71.9% on average and 79.9% onAIME24) while delivering up to 1.53x average speedup in token latency, establishing a new Pareto frontier between accuracy and efficiency.  Thank you AK for sharing our new research from Meta, UC Berkeley, and UCSF! Within the realm of parallel reasoning that is getting more and more popular, ThreadWeaver üßµ‚ö°Ô∏è is the first adaptive reasoning approach to:üß† Match strong sequential reasoning LLM accuracy on real competition math problems,‚ö° Run in parallel with no engine modifications, andüìà Perform parallel GRPO on an off-the-shelf long CoT reasoning model to further improve performance and efficiency Project Page:https://threadweaver-parallel.github.io/Post on X for a one-minute preview:https://x.com/LongTonyLian/status/1995561005557186963?s=20    This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ¬∑Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550039",
    "title": "ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models",
    "authors": [
      "Long Lian",
      "Felix Juefei-Xu",
      "Xi Victoria Lin"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.07843",
    "upvote": 21
  }
}