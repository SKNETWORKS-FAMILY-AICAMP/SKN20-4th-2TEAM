{
  "context": "TwinFlow is a 1-step generative model framework that enhances inference efficiency without requiring fixed pretrained teacher models or standard adversarial networks, achieving high performance on text-to-image tasks and scaling efficiently. Recent advances in large multi-modal generative models have demonstrated impressive capabilities in multi-modal generation, including image and video generation. These models are typically built upon multi-step frameworks likediffusionandflow matching, which inherently limits theirinference efficiency(requiring 40-100Number of Function Evaluations(NFEs)). While variousfew-step methodsaim to accelerate the inference, existing solutions have clear limitations. Prominent distillation-based methods, such as progressive andconsistency distillation, either require an iterative distillation procedure or show significant degradation at very few steps (< 4-NFE). Meanwhile, integratingadversarial traininginto distillation (e.g.,DMD/DMD2andSANA-Sprint) to enhance performance introduces training instability, added complexity, and high GPU memory overhead due to the auxiliary trained models. To this end, we proposeTwinFlow, a simple yet effective framework for training 1-step generative models that bypasses the need of fixed pretrained teacher models and avoids standard adversarial networks during training, making it ideal for building large-scale, efficient models. On text-to-image tasks, our method achieves aGenEvalscore of 0.83 in 1-NFE, outperforming strong baselines likeSANA-Sprint(a GAN loss-based framework) andRCGM(a consistency-based framework). Notably, we demonstrate the scalability ofTwinFlowby full-parameter training onQwen-Image-20Band transform it into an efficient few-step generator. With just 1-NFE, our approach matches the performance of the original 100-NFE model on both theGenEvalandDPG-Benchbenchmarks, reducing computational cost by 100times with minor quality degradation. Project page is available at https://zhenglin-cheng.com/twinflow. Taming 20B full-parameter few-step training with self-adversarial flows! ðŸ‘ðŸ» Checkout our2-NFE imagesgenerated by ourTwinFlow-Qwen-Image!ðŸ‘‡  We are also working onZ-Image-Turbo, stay tuned! very nice paper! ðŸŽ‰ðŸ‘ Hope it there will be one for **OnomaAIResearch/Illustrious-xl-early-release-v0 ** gonna save us from 24/29 sampling steps for every GEN ðŸ‘€ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend the github / huggingface link of the project are not found? the github / huggingface link of the project are not found? sorry for delay, we are releasing them soon. arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/twinflow-realizing-one-step-generation-on-large-models-with-self-adversarial-flows-2286-ddb0218b Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550005",
    "title": "TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows",
    "authors": [
      "Zhenglin Cheng",
      "Jianguo Li"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/inclusionAI/TwinFlow",
    "huggingface_url": "https://huggingface.co/papers/2512.05150",
    "upvote": 74
  }
}