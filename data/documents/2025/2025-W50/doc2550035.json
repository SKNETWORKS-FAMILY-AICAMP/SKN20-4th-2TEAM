{
  "context": "PaCo-RL combines reinforcement learning with a specialized consistency reward model and an efficient optimization strategy to improve consistent image generation. Consistent image generation requires faithfully preserving identities, styles, and logical coherence across multiple images, which is essential for applications such as storytelling and character design. Supervised training approaches struggle with this task due to the lack of large-scale datasets capturing visual consistency and the complexity of modeling human perceptual preferences. In this paper, we argue thatreinforcement learning(RL) offers a promising alternative by enabling models to learn complex and subjective visual criteria in a data-free manner. To achieve this, we introducePaCo-RL, a comprehensive framework that combines a specialized consistency reward model with an efficient RL algorithm. The first component,PaCo-Reward, is apairwise consistency evaluatortrained on a large-scale dataset constructed via automated sub-figure pairing. It evaluates consistency through a generative,autoregressive scoring mechanismenhanced bytask-aware instructionsandCoT reasons. The second component,PaCo-GRPO, leverages a novelresolution-decoupled optimizationstrategy to substantially reduce RL cost, alongside alog-tamed multi-reward aggregationmechanism that ensures balanced and stable reward optimization. Extensive experiments across the two representative subtasks show thatPaCo-Rewardsignificantly improves alignment with human perceptions of visual consistency, andPaCo-GRPOachieves state-of-the-artconsistency performancewith improvedtraining efficiencyandstability. Together, these results highlight the promise ofPaCo-RLas a practical and scalable solution for consistent image generation. The project page is available at https://x-gengroup.github.io/HomePage_PaCo-RL/. Consistent image generation requires faithfully preserving identities, styles, and logical coherence across multiple images, which is essential for applications such as storytelling and character design. Supervised training approaches struggle with this task due to the lack of large-scale datasets capturing visual consistency and the complexity of modeling human perceptual preferences. In this paper, we argue that reinforcement learning (RL) offers a promising alternative by enabling models to learn complex and subjective visual criteria in a data-free manner. To achieve this, we introduce PaCo-RL, a comprehensive framework that combines a specialized consistency reward model with an efficient RL algorithm. The first component, PaCo-Reward, is a pairwise consistency evaluator trained on a large-scale dataset constructed via automated sub-figure pairing. It evaluates consistency through a generative, autoregressive scoring mechanism enhanced by task-aware instructions and CoT reasons. The second component, PaCo-GRPO, leverages a novel resolution-decoupled optimization strategy to substantially reduce RL cost, alongside a log-tamed multi-reward aggregation mechanism that ensures balanced and stable reward optimization. Extensive experiments across the two representative subtasks show that PaCo-Reward significantly improves alignment with human perceptions of visual consistency, and PaCo-GRPO achieves state-of-the-art consistency performance with improved training efficiency and stability. Together, these results highlight the promise of PaCo-RL as a practical and scalable solution for consistent image generation. The project page is available athttps://x-gengroup.github.io/HomePage_PaCo-RL This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550035",
    "title": "PaCo-RL: Advancing Reinforcement Learning for Consistent Image Generation with Pairwise Reward Modeling",
    "authors": [
      "Chengyou Jia"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/X-GenGroup/PaCo-RL",
    "huggingface_url": "https://huggingface.co/papers/2512.04784",
    "upvote": 24
  }
}