{
  "context": "A deliberative editing framework with a reasoning engine improves instruction-following in image editing through iterative critique and refinement, significantly enhancing performance. Instruction-basedimage editinghas emerged as a prominent research area, which, benefiting from imagegenerationfoundation models, have achieved high aesthetic quality, makinginstruction-following capabilitythe primary challenge. Existing approaches improve instruction adherence via supervised orreinforcement learning, yet single-turn success rates remain limited due to inherent stochasticity and a lack of deliberation. In this work, we propose a deliberative editing framework to 'think' while they edit, which simulates the human cognitive loop by iteratively executing aThink-while-Edit cycle:Critiquingresults andRefining instructions, followed by Repeating thegenerationuntil satisfactory. Specifically, we train a singleMLLM,EditThinker, to act as the reasoning engine of this framework, which jointly produce the critique score, reasoning process, and refined instructions. We employreinforcement learningto align theEditThinker's thinking with its editing, thereby generating more targeted instruction improvements. Extensive experiments on four benchmarks demonstrate that our approach significantly improves theinstruction-following capabilityof anyimage editingmodel by a large margin. We will release ourdata construction framework, datasets, and models to benefit the community. Instruction-based image editing has emerged as a prominent research area. Benefiting from image generation foundation models, it has achieved high aesthetic quality, making instruction-following capability the primary challenge. Existing approaches improve instruction adherence via supervised or reinforcement learning, yet single-turn success rates remain limited due to inherent stochasticity and a lack of deliberation. In this work, we propose a deliberative editing framework to \"think\" while they edit, which simulates the human cognitive loop by iteratively executing a Think-while-Edit cycle: Critiquing results and Refining instructions, followed by Repeating the generation until satisfactory. Specifically, we train a single MLLM, EditThinker, to act as the reasoning engine of this framework, which jointly produces the critique score, reasoning process, and refined instructions. We employ reinforcement learning to align the EditThinker's thinking with its editing, thereby generating more targeted instruction improvements. Extensive experiments on four benchmarks demonstrate that our approach significantly improves the instruction-following capability of any image editing model by a large margin. code:https://github.com/appletea233/EditThinker This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2550016",
    "title": "EditThinker: Unlocking Iterative Reasoning for Any Image Editor",
    "authors": [
      "Hongyu Li",
      "Dian Zheng",
      "Hao Yu",
      "Yexin Liu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/appletea233/EditThinker",
    "huggingface_url": "https://huggingface.co/papers/2512.05965",
    "upvote": 38
  }
}