{
  "context": "HoloCine generates coherent multi-shot narratives using a Window Cross-Attention mechanism and Sparse Inter-Shot Self-Attention, enabling end-to-end cinematic creation. State-of-the-arttext-to-video modelsexcel at generating isolated clips but\nfall short of creating the coherent, multi-shot narratives, which are the\nessence of storytelling. We bridge this \"narrative gap\" with HoloCine, a model\nthat generates entire scenes holistically to ensure global consistency from the\nfirst shot to the last. Our architecture achieves precise directorial control\nthrough aWindow Cross-Attentionmechanism that localizes text prompts to\nspecific shots, while aSparse Inter-Shot Self-Attentionpattern (dense within\nshots but sparse between them) ensures the efficiency required for minute-scale\ngeneration. Beyond setting a new state-of-the-art innarrative coherence,\nHoloCine develops remarkable emergent abilities: a persistent memory for\ncharacters and scenes, and an intuitive grasp of cinematic techniques. Our work\nmarks a pivotal shift from clip synthesis towardsautomated filmmaking, making\nend-to-end cinematic creation a tangible future. Our code is available at:\nhttps://holo-cine.github.io/. HoloCineis a text-to-video framework that holistically generates coherent, cinematic multi-shot video narratives from a single prompt, combiningWindow Cross-Attentionfor per-shot control andSparse Inter-Shot Self-Attentionfor efficient, consistent long-scene generation. Thanks a lot@taesirifor helping us submit our paper to the daily papers! üôèCould we please use the following video as the cover to better showcase our results?üé•https://holo-cine.github.io/holocine.mp4 Congrats on the amazing work! Unfortunately, it seems the media tag cannot be updated after an initial submission has been made. I think I messed that up, super sorry about that. code:https://github.com/yihao-meng/HoloCine This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend moving in space make her realstic adult model Giant horse made of colorful balloons placed slightly farther back on a bright green football field, leaving clear empty space in the foreground for text. The balloon colors are smooth and vibrant (yellow, teal, pink, green, purple). Sunlight and soft shadows. Clean, playful, high-definition look. Cinematic, bright sky background, no people, no text, ultra sharp 9:16 ¬∑Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543029",
    "title": "HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video\n  Narratives",
    "authors": [
      "Yue Yu",
      "Qiuyu Wang",
      "Wen Wang",
      "Yanhong Zeng"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/yihao-meng/HoloCine",
    "huggingface_url": "https://huggingface.co/papers/2510.20822",
    "upvote": 40
  }
}