{
  "context": "UltraGen, a novel video generation framework, enables efficient high-resolution video synthesis using a hierarchical dual-branch attention architecture and spatially compressed global modeling. Recent advances invideo generationhave made it possible to produce visually\ncompelling videos, with wide-ranging applications in content creation,\nentertainment, and virtual reality. However, most existing diffusion\ntransformer basedvideo generationmodels are limited tolow-resolutionoutputs\n(<=720P) due to the quadraticcomputational complexityof the attention\nmechanism with respect to the output width and height. This computational\nbottleneck makes nativehigh-resolutionvideo generation(1080P/2K/4K)\nimpractical for both training and inference. To address this challenge, we\npresent UltraGen, a novelvideo generationframework that enables i) efficient\nand ii) end-to-end nativehigh-resolutionvideo synthesis. Specifically,\nUltraGen features a hierarchical dual-branch attention architecture based onglobal-local attention decomposition, which decouples full attention into alocal attentionbranch for high-fidelity regional content and a global\nattention branch for overall semantic consistency. We further propose aspatially compressed global modelingstrategy to efficiently learn global\ndependencies, and ahierarchical cross-window local attentionmechanism to\nreduce computational costs while enhancing information flow across different\nlocal windows. Extensive experiments demonstrate that UltraGen can effectively\nscale pre-trainedlow-resolutionvideo models to 1080P and even 4K resolution\nfor the first time, outperforming existing state-of-the-art methods andsuper-resolutionbasedtwo-stage pipelinesin both qualitative and quantitative\nevaluations. Recent advances in video generation have made it possible to produce visually compelling videos, with wide-ranging applications in content creation, entertainment, and virtual reality. However, most existing diffusion transformer based video generation models are limited to low-resolution outputs (≤720P) due to the quadratic computational complexity of the attention mechanism with respect to the output width and height. This computational bottleneck makes native high-resolution video generation (1080P/2K/4K) impractical for both training and inference. To address this challenge, we present UltraGen, a novel video generation framework that enables i) efficient and ii) end-to-end native high-resolution video synthesis. Specifically, UltraGen features a hierarchical dual-branch attention architecture based on global-local attention decomposition, which decouples full attention into a local attention branch for high-fidelity regional content and a global attention branch for overall semantic consistency. We further propose a spatially compressed global modeling strategy to efficiently learn global dependencies, and a hierarchical cross-window local attention mechanism to reduce computational costs while enhancing information flow across different local windows. Extensive experiments demonstrate that UltraGen can effectively scale pre-trained low-resolution video models to 1080P and even 4K resolution for the first time, outperforming existing state-of-the-art methods and super-resolution based two-stage pipelines in both qualitative and quantitative evaluations. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543063",
    "title": "UltraGen: High-Resolution Video Generation with Hierarchical Attention",
    "authors": [
      "Teng Hu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/sjtuplayer/UltraGen",
    "huggingface_url": "https://huggingface.co/papers/2510.18775",
    "upvote": 17
  }
}