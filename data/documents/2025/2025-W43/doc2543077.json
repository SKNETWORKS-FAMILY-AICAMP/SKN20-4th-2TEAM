{
  "context": "OmniNWM is a unified world model for autonomous driving that generates panoramic videos, encodes actions using Plucker ray-maps, and defines dense rewards based on 3D occupancy, achieving top performance in video generation, control, and stability. Autonomous driving world models are expected to work effectively across three\ncore dimensions: state, action, and reward. Existing models, however, are\ntypically restricted to limited state modalities, short video sequences,\nimprecise action control, and a lack of reward awareness. In this paper, we\nintroduceOmniNWM, an omniscientpanoramic navigation world modelthat\naddresses all three dimensions within a unified framework. For state,OmniNWMjointly generatespanoramic videosofRGB,semantics,metric depth, and 3D\noccupancy. A flexible forcing strategy enables high-quality long-horizonauto-regressive generation. For action, we introduce a normalized panoramic\nPlucker ray-map representation that encodes input trajectories into pixel-level\nsignals, enabling highly precise and generalizable control over panoramic video\ngeneration. Regarding reward, we move beyond learning reward functions with\nexternal image-based models: instead, we leverage the generated3D occupancyto\ndirectly definerule-based dense rewardsfordriving complianceandsafety.\nExtensive experiments demonstrate thatOmniNWMachieves state-of-the-art\nperformance in video generation, control accuracy, and long-horizon stability,\nwhile providing a reliable closed-loop evaluation framework throughoccupancy-grounded rewards. Project page is available at\nhttps://github.com/Arlo0o/OmniNWM. OmniNWM addresses three core dimensions of autonomous driving world models: üìä State: Joint generation of panoramic RGB, semantic, metric depth, and 3D occupancy videosüéÆ Action: Precise panoramic camera control via normalized Pl√ºcker ray-mapsüèÜ Reward: Integrated occupancy-based dense rewards for driving compliance and safety https://arlo0o.github.io/OmniNWM/ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ¬∑Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543077",
    "title": "OmniNWM: Omniscient Driving Navigation World Models",
    "authors": [
      "Zhuang Ma"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Ma-Zhuang/OmniNWM",
    "huggingface_url": "https://huggingface.co/papers/2510.18313",
    "upvote": 12
  }
}