{
  "context": "Nano3D is a training-free framework that integrates FlowEdit and TRELLIS for precise 3D object editing, using front-view renderings and region-aware merging strategies to maintain structural fidelity and visual quality. 3D object editing is essential for interactive content creation in gaming,\nanimation, and robotics, yet current approaches remain inefficient,\ninconsistent, and often fail to preserve unedited regions. Most methods rely on\nediting multi-view renderings followed by reconstruction, which introduces\nartifacts and limits practicality. To address these challenges, we propose\nNano3D, a training-free framework for precise and coherent 3D object editing\nwithout masks. Nano3D integratesFlowEditintoTRELLISto perform localized\nedits guided byfront-view renderings, and further introduces region-aware\nmerging strategies,Voxel/Slat-Merge, which adaptively preserve structural\nfidelity by ensuring consistency between edited and unedited areas. Experiments\ndemonstrate that Nano3D achieves superior3D consistencyand visual quality\ncompared with existing methods. Based on this framework, we construct the first\nlarge-scale3D editing datasetsNano3D-Edit-100k, which contains over 100,000\nhigh-quality 3D editing pairs. This work addresses long-standing challenges in\nboth algorithm design and data availability, significantly improving the\ngenerality and reliability of 3D editing, and laying the groundwork for the\ndevelopment offeed-forward 3D editing models. Project\nPage:https://jamesyjl.github.io/Nano3D 3D object editing is essential for interactive content creation in gaming, animation, and robotics, yet current approaches remain inefficient, inconsistent, and often fail to preserve unedited regions. Most methods rely on editing multi-view renderings followed by reconstruction, which introduces artifacts and limits practicality. To address these challenges, we propose Nano3D, a training-free framework for precise and coherent 3D object editing without masks. Nano3D integrates FlowEdit into TRELLIS to perform localized edits guided by front-view renderings, and further introduces region-aware merging strategies, Voxel/Slat-Merge, which adaptively preserve structural fidelity by ensuring consistency between edited and unedited areas. Experiments demonstrate that Nano3D achieves superior 3D consistency and visual quality compared with existing methods. Based on this framework, we construct the first large-scale 3D editing datasets Nano3D-Edit-100k, which contains over 100,000 high-quality 3D editing pairs. This work addresses long-standing challenges in both algorithm design and data availability, significantly improving the generality and reliability of 3D editing, and laying the groundwork for the development of feed-forward 3D editing models. Project Page:https://jamesyjl.github.io/Nano3D/ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543016",
    "title": "NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks",
    "authors": [
      "Junliang Ye"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/JAMESYJL/Nano3D/tree/main",
    "huggingface_url": "https://huggingface.co/papers/2510.15019",
    "upvote": 63
  }
}