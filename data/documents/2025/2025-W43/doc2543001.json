{
  "context": "A theoretical framework for sampling-based test-time scaling in large language models reveals limitations in self-consistency and perplexity, and introduces RPC to improve reasoning performance and reduce sampling costs. Test-time scaling seeks to improve the reasoning performance of large\nlanguage models (LLMs) by adding computational resources. A prevalent approach\nwithin the field issampling-based test-time scalingmethods, which enhance\nreasoning by generating multiple reasoning paths for a given input during\ninference. However, despite its practical success, the theoretical foundations\nremain underexplored. In this paper, we provide the first theoretical framework\nfor analyzingsampling-based test-time scalingmethods, grounded in the\nperspective ofconfidence estimation. Based on the framework, we analyze two\ndominant paradigms:self-consistencyandperplexity, and reveal key\nlimitations:self-consistencysuffers from high estimation error whileperplexityexhibits substantial modeling error and possible degradation of the\nestimation error convergence. To address these limitations, we introduce RPC, a\nhybrid method that leverages our theoretical insights through two key\ncomponents:Perplexity ConsistencyandReasoning Pruning.PerplexityConsistency combines the strengths ofself-consistencyandperplexity, boosting\nthe convergence rate of estimation error from linear to exponential while\npreserving model error.Reasoning Pruningprevents degradation by eliminating\nlow-probability reasoning paths. Both theoretical analysis and empirical\nresults across sevenbenchmark datasetsdemonstrate that RPC has a strong\npotential for reducingreasoning error. Notably, RPC achieves reasoning\nperformance comparable toself-consistencywhile not only enhancing confidence\nreliability but also reducing sampling costs by 50%. The code and resources are\navailable at https://wnjxyk.github.io/RPC. We introduce thefirst theoretical frameworkfor analyzing LLM reasoning errors, and bridge two typical sampling-based test-time scaling methods to achieveboth low error and fast convergence. @librarian-botrecommend This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/a-theoretical-study-on-bridging-internal-probability-and-self-consistency-for-llm-reasoning Thanks! arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/a-theoretical-study-on-bridging-internal-probability-and-self-consistency-for-llm-reasoning-6122-e8e5c02d Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543001",
    "title": "A Theoretical Study on Bridging Internal Probability and\n  Self-Consistency for LLM Reasoning",
    "authors": [
      "Zhi Zhou"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/WNJXYK/RPC",
    "huggingface_url": "https://huggingface.co/papers/2510.15444",
    "upvote": 147
  }
}