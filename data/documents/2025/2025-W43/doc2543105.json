{
  "context": "CiteGuard, a retrieval-aware agent framework, enhances citation accuracy in LLM-generated text by aligning citations with human choices, achieving near-human performance. Large Language Models(LLMs) have emerged as promising assistants for\nscientific writing. However, there have been concerns regarding the quality and\nreliability of the generated text, one of which is the citation accuracy and\nfaithfulness. While most recent work relies on methods such asLLM-as-a-Judge,\nthe reliability ofLLM-as-a-Judgealone is also in doubt. In this work, we\nreframecitation evaluationas a problem ofcitation attribution alignment,\nwhich is assessing whether LLM-generated citations match those a human author\nwould include for the same text. We proposeCiteGuard, aretrieval-aware agentframework designed to provide more faithful grounding for citation validation.CiteGuardimproves the prior baseline by 12.3%, and achieves up to 65.4%\naccuracy on theCiteME benchmark, on par with human-level performance (69.7%).\nIt also enables the identification of alternative but valid citations. Large Language Models (LLMs) have emerged as promising assistants for scientific writing. However, there have been concerns regarding the quality and reliability of the generated text, one of which is the citation accuracy and faithfulness. While most recent work relies on methods such as LLM-as-a-Judge, the reliability of LLM-as-a-Judge alone is also in doubt. In this work, we reframe citation evaluation as a problem of citation attribution alignment, which is assessing whether LLM-generated citations match those a human author would include for the same text. We propose CiteGuard, a retrieval-aware agent framework designed to provide more faithful grounding for citation validation. CiteGuard improves the prior baseline by 12.3%, and achieves up to 65.4% accuracy on the CiteME benchmark, on par with human-level performance (69.7%). It also enables the identification of alternative but valid citations.https://kathcym.github.io/CiteGuard_Page/ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543105",
    "title": "CiteGuard: Faithful Citation Attribution for LLMs via\n  Retrieval-Augmented Validation",
    "authors": [
      "Yee Man Choi",
      "Qingyun Wang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/KathCYM/CiteGuard",
    "huggingface_url": "https://huggingface.co/papers/2510.17853",
    "upvote": 7
  }
}