{
  "context": "STEAM, a back-translation-based detection method, enhances multilingual watermarking robustness across various languages by addressing semantic clustering failures. Multilingual watermarkingaims to makelarge language model(LLM) outputs\ntraceable across languages, yet current methods still fall short. Despite\nclaims of cross-lingual robustness, they are evaluated only on high-resource\nlanguages. We show that existingmultilingual watermarkingmethods are not\ntruly multilingual: they fail to remain robust undertranslation attacksin\nmedium- andlow-resource languages. We trace this failure to semantic\nclustering, which fails when thetokenizer vocabularycontains too fewfull-word tokensfor a given language. To address this, we introduce STEAM, aback-translation-based detection method that restores watermark strength lost\nthrough translation. STEAM is compatible with any watermarking method, robust\nacross different tokenizers and languages, non-invasive, and easily extendable\nto new languages. With average gains of +0.19AUCand +40%pTPR@1%on 17\nlanguages, STEAM provides a simple and robust path toward fairer watermarking\nacross diverse languages. Some watermarking methods for large language models (LLMs) claim to be multilingual, yet they are almost always tested on high-resource languages like English, French, and German. This paper reveals that such claims do not hold up under scrutiny: multilingual watermarks collapse under translation attacks in medium- and low-resource languages.  This paper traces the issue tosemantic clustering, the main technique behind multilingual watermarking, which groups semantically similar tokens across languages. When tokenisers have few full-word tokens, as is common in less-resourced languages, the clustering fails, weakening watermark detection. To fix this, the paper introducesSTEAM (Simple Translation-Enhanced Approach for Multilingual watermarking), a lightweight, detection-time method that restores watermark signals lost during translation. STEAM usesback-translation, translating a suspect text back into multiple supported languages, and then identifies the strongest watermark signal across these variants. Crucially, STEAM is model-agnostic, tokenizer-independent, and works with any existing watermarking method without modifying model outputs.  ðŸ“ˆResults ðŸ’¡Key Insight:Watermark robustness depends on language tokenisation coverage. By recovering lost watermark signals through back-translation,STEAMensures fairer, more reliable detection across linguistic diversity. In short,STEAM redefines multilingual watermarking as genuinely multilingual, offering a simple yet powerful step toward equitable content provenance for all languages. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543064",
    "title": "Is Multilingual LLM Watermarking Truly Multilingual? A Simple\n  Back-Translation Solution",
    "authors": [
      "Asim Mohamed",
      "Martin Gubri"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/asimzz/steam",
    "huggingface_url": "https://huggingface.co/papers/2510.18019",
    "upvote": 17
  }
}