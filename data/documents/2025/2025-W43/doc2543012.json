{
  "context": "Transformer language models are proven to be injective, allowing exact input reconstruction from hidden activations, which has implications for transparency and safety. Transformer componentssuch asnon-linear activationsandnormalizationare\ninherently non-injective, suggesting that different inputs could map to the\nsame output and prevent exact recovery of the input from a model's\nrepresentations. In this paper, we challenge this view. First, we prove\nmathematically that transformerlanguage modelsmapping discrete input\nsequences to their corresponding sequence ofcontinuous representationsareinjectiveand therefore lossless, a property established at initialization and\npreserved during training. Second, we confirm this result empirically through\nbillions ofcollision testson six state-of-the-artlanguage models, and\nobserve no collisions. Third, we operationalize injectivity: we introduceSipIt, the first algorithm that provably and efficiently reconstructs the exact\ninput text from hidden activations, establishinglinear-time guaranteesand\ndemonstratingexact invertibilityin practice. Overall, our work establishes\ninjectivity as a fundamental and exploitable property oflanguage models, with\ndirect implications for transparency, interpretability, and safe deployment. Transformer components such as non-linear activations and normalization are inherently non-injective, suggesting that different inputs could map to the same output and prevent exact recovery of the input from a model’s representations. In this paper, we challenge this view. First, we prove mathematically that transformer language models mapping discrete input sequences to their corresponding sequence of continuous representations are injective and therefore lossless, a property established at initialization and preserved during training. Second, we confirm this result empirically through billions of collision tests on six state-of-the-art language models, and observe no collisions. Third, we operationalize injectivity: we introduce SipIt, the first algorithm that provably and efficiently reconstructs the exact input text from hidden activations, establishing linear-time guarantees and demonstrating exact invertibility in practice. Overall, our work establishes injectivity as a fundamental and exploitable property of language models, with direct implications for transparency, interpretability, and safe deployment. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend *Equal contribution; author order settled via Mario Kart. ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543012",
    "title": "Language Models are Injective and Hence Invertible",
    "authors": [
      "Giorgos Nikolaou",
      "Tommaso Mencattini",
      "Andrea Santilli"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2510.15511",
    "upvote": 69
  }
}