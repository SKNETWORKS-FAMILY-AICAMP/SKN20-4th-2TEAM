{
  "context": "BLIP3o-NEXT, a unified text-to-image generation and image editing model, uses an Autoregressive + Diffusion architecture to achieve superior performance and realism. We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3\nseries that advances the next frontier of native image generation. BLIP3o-NEXT\nunifiestext-to-image generationandimage editingwithin a single\narchitecture, demonstrating strong image generation andimage editingcapabilities. In developing the state-of-the-art native image generation model,\nwe identify four key insights: (1) Most architectural choices yield comparable\nperformance; an architecture can be deemed effective provided it scales\nefficiently and supports fast inference; (2) The successful application of\nreinforcement learning can further push the frontier of native image\ngeneration; (3)Image editingstill remains a challenging task, yet instruction\nfollowing and the consistency between generated and reference images can be\nsignificantly enhanced through post-training and data engine; (4) Data quality\nand scale continue to be decisive factors that determine the upper bound of\nmodel performance. Building upon these insights, BLIP3o-NEXT leverages anAutoregressive+Diffusionarchitecture in which anautoregressivemodel first\ngeneratesdiscrete image tokensconditioned onmultimodal inputs, whose hidden\nstates are then used as conditioning signals for adiffusionmodel to generatehigh-fidelity images. This architecture integrates the reasoning strength and\ninstruction following ofautoregressivemodels with the fine-detail rendering\nability ofdiffusionmodels, achieving a new level ofcoherenceandrealism.\nExtensive evaluations of various text-to-image and image-editing benchmarks\nshow that BLIP3o-NEXT achieves superior performance over existing models. We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3 series that advances the next frontier of native image generation. BLIP3o-NEXT unifies text-to-image generation and image editing within a single architecture, demonstrating strong image generation and image editing capabilities. In developing the state-of-the-art native image generation model, we identify four key insights: (1) Most architectural choices yield comparable performance; an architecture can be deemed effective provided it scales efficiently and supports fast inference; (2) The successful application of reinforcement learning can further push the frontier of native image generation; (3) Image editing still remains a challenging task, yet instruction following and the consistency between generated and reference images can be significantly enhanced through post-training and data engine; (4) Data quality and scale continue to be decisive factors that determine the upper bound of model performance. Building upon these insights, BLIP3o-NEXT leverages an Autoregressive + Diffusion architecture in which an autoregressive model first generates discrete image tokens conditioned on multimodal inputs, whose hidden states are then used as conditioning signals for a diffusion model to generate high-fidelity images. This architecture integrates the reasoning strength and instruction following of autoregressive models with the fine-detail rendering ability of diffusion models, achieving a new level of coherence and realism. Extensive evaluations of various text-to-image and image-editing benchmarks show that BLIP3o-NEXT achieves superior performance over existing models. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2543046",
    "title": "BLIP3o-NEXT: Next Frontier of Native Image Generation",
    "authors": [
      "Tianyi Zhou"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2510.15857",
    "upvote": 24
  }
}