{
  "context": "An iterative sampling algorithm enhances reasoning capabilities in base models without additional training, matching or outperforming reinforcement learning on single-shot tasks. Frontier reasoning models have exhibited incredible capabilities across a\nwide array of disciplines, driven byposttraining large language models(LLMs)\nwithreinforcement learning(RL). However, despite the widespread success of\nthis paradigm, much of the literature has been devoted to disentangling truly\nnovel behaviors that emerge during RL but are not present in the base models.\nIn our work, we approach this question from a different angle, instead asking\nwhether comparable reasoning capabilites can be elicited from base models at\ninference time by pure sampling, without any additional training. Inspired byMarkov chain Monte Carlo(MCMC) techniques for sampling from sharpened\ndistributions, we propose a simpleiterative sampling algorithmleveraging the\nbase models' ownlikelihoods. Over different base models, we show that our\nalgorithm offers substantial boosts in reasoning that nearly match and even\noutperform those from RL on a wide variety of single-shot tasks, includingMATH500,HumanEval, andGPQA. Moreover, our sampler avoids the collapse in\ndiversity over multiple samples that is characteristic of RL-posttraining.\nCrucially, our method does not require training, curated datasets, or a\nverifier, suggesting broad applicability beyond easily verifiable domains. This paper explores a sampling-based method for LLM reasoning to improve reasoning performance, surpassing the results of RL training using GPRO with a very low cost. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ðŸ¥º Please also see ourNeurIPS 2025 paper \"A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning\", which introduces a theoretical framework for sampling-based test-time scaling methods. Interesting work!It seems that the base model can achieve higher performance even without extra training process, i have a question, have you tried this method on other VLM tasks, such as Grounding or Video understanding? Actually, A decent reasoning mcp server with COT, reflection, recall and such can give a boost to existing models that don't even support reasoning. Wow, this is a highly reasonable proposal. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2544018",
    "title": "Reasoning with Sampling: Your Base Model is Smarter Than You Think",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/aakaran/reasoning-with-sampling",
    "huggingface_url": "https://huggingface.co/papers/2510.14901",
    "upvote": 47
  }
}