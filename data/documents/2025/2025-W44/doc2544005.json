{
  "context": "AutoDeco, a novel architecture, enables end-to-end generation by dynamically predicting decoding parameters, outperforming default strategies and achieving performance close to an oracle-tuned baseline. The \"end-to-end\" label forLLMsis a misnomer. In practice, they depend on a\nnon-differentiabledecoding processthat requires laborious, hand-tuning ofhyperparametersliketemperatureandtop-p. This paper introducesAutoDeco, a\nnovel architecture that enables truly \"end-to-end\" generation by learning to\ncontrol its own decoding strategy. We augment the standardtransformerwithlightweight headsthat, at each step, dynamically predict context-specifictemperatureandtop-pvalues alongside thenext-token logits. This approach\ntransforms decoding into aparametric,token-level process, allowing the model\nto self-regulate itssampling strategywithin a single forward pass.\n  Through extensive experiments on eight benchmarks, we demonstrate thatAutoDeconot only significantly outperforms default decoding strategies but\nalso achieves performance comparable to an oracle-tuned baseline derived from\n\"hacking the test set\"-a practical upper bound for any static method.\nCrucially, we uncover an emergent capability for instruction-based decoding\ncontrol: the model learns to interpretnatural language commands(e.g.,\n\"generate with low randomness\") and adjusts its predictedtemperatureandtop-pon a token-by-token basis, opening a new paradigm for steerable and interactive\nLLM decoding. AutoDeco is a framework that adds token-level adaptive decoding parameter prediction capabilities to Large Language Models (LLMs). By adding lightweight prediction heads on top of pre-trained models, AutoDeco can dynamically predict optimal temperature and top-p parameters for each token during decoding. Github:https://github.com/Zacks917/AutoDecoHuggingface Models:https://huggingface.co/collections/Jadeislaw/autodeco This work should cite:https://arxiv.org/abs/2411.09661: Adaptive Decoding via Latent Preference Optimization During language model decoding, it is known that using higher temperature sampling gives more creative responses, while lower temperatures are more factually accurate. However, such models are commonly applied to general instruction following, which involves both creative and fact seeking tasks, using a single fixed temperature across all examples and tokens. In this work, we introduce Adaptive Decoding, a layer added to the model to select the sampling temperature dynamically at inference time, at either the token or example level, in order to optimize performance. To learn its parameters we introduce Latent Preference Optimization (LPO) a general approach to train discrete latent variables such as choices of temperature. Our method outperforms all fixed decoding temperatures across a range of tasks that require different temperatures, including UltraFeedback, Creative Story Writing, and GSM8K. Hi Jason, Thanks for the comment. Jack, kindly reached out to us via email yesterday, and we've already been in touch with him. We appreciate you both bringing this highly relevant work to our attention—it was an oversight on our part during the literature survey. As we conveyed to him, we are preparing an updated version of our paper, expected on arXiv within two weeks. In this revision, we will be sure to include a discussion that analyzes the connections and differences between our two approaches. Thanks again for making sure we were aware. ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2544005",
    "title": "The End of Manual Decoding: Towards Truly End-to-End Language Models",
    "authors": [
      "Zhichao Wang",
      "Dongyang Ma",
      "Xinting Huang",
      "Tian Lan",
      "Xiaoying Tang",
      "Yan Wang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Zacks917/AutoDeco",
    "huggingface_url": "https://huggingface.co/papers/2510.26697",
    "upvote": 116
  }
}