{
  "context": "AgentFold, a novel proactive context management paradigm, enhances long-horizon task performance through dynamic context folding, achieving superior results on benchmarks compared to larger models and proprietary agents. LLM-based web agents show immense promise for information seeking, yet their\neffectiveness on long-horizon tasks is hindered by a fundamental trade-off incontext management. PrevailingReAct-based agentssuffer from context\nsaturation as they accumulate noisy, raw histories, while methods that fixedly\nsummarize the full history at each step risk the irreversible loss of critical\ndetails. Addressing these, we introduce AgentFold, a novel agent paradigm\ncentered on proactivecontext management, inspired by the human cognitive\nprocess of retrospective consolidation. AgentFold treats its context as a\ndynamiccognitive workspaceto be actively sculpted, rather than a passive log\nto be filled. At each step, it learns to execute a `folding' operation, which\nmanages its historical trajectory at multiple scales: it can perform granular\ncondensations to preserve vital, fine-grained details, ordeep consolidationsto abstract away entire multi-step sub-tasks. The results on prominent\nbenchmarks are striking: with simple supervised fine-tuning (without continual\npre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% onBrowseCompand 47.3% onBrowseComp-ZH. Notably, this performance not only surpasses or\nmatches open-source models of a dramatically larger scale, such as theDeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents likeOpenAI's o4-mini. LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini. Check our projects athttps://github.com/Alibaba-NLP/DeepResearch Thank you for sharing this great and interesting paper!Our recent work is on a similar line, while we take a different approach by using an external compressor rather than having the LLM agent generate compression itself. Our focus is onhow to optimize the context compressionfor long-horizon LLM agents. Hope you are interested in our work ðŸ˜€Title: ACON: Optimizing Context Compression for Long-horizon LLM AgentsLink:https://huggingface.co/papers/2510.00615 Thanks, very interesting Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2544012",
    "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
    "authors": [
      "Yida Zhao",
      "Liangcai Su",
      "Xinyu Wang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Alibaba-NLP/DeepResearch",
    "huggingface_url": "https://huggingface.co/papers/2510.24699",
    "upvote": 69
  }
}