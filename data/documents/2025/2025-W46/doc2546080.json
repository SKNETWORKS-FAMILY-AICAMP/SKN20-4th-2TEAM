{
  "context": "Natural language critiques improve confidence calibration in LLMs, with CritiCal training method outperforming other approaches and enhancing reliability. Accurateconfidence calibrationinLarge Language Models(LLMs) iscriticalfor safe use in high-stakes domains, where clear verbalized confidence enhances\nuser trust. Traditional methods that mimic reference confidence expressions\noften fail to capture the reasoning needed for accurateconfidence assessment.\nWe proposenatural language critiquesas a solution, ideally suited forconfidence calibration, as precise gold confidence labels are hard to obtain\nand often require multiple generations. This paper studies how natural language\ncritiques can enhance verbalized confidence, addressing: (1) What to critique:uncertainty(question-focused) or confidence (answer-specific)? Analysis shows\nconfidence suitsmultiple-choice tasks, whileuncertaintyexcels in open-ended\nscenarios. (2) How to critique:self-critiqueor critique calibration training?\nWe proposeSelf-Critique, enabling LLMs to critique and optimize their\nconfidence beyond mere accuracy, andCritiCal, a novel Critique Calibration\ntraining method that leveragesnatural language critiquesto improve confidence\ncalibration, moving beyond direct numerical optimization. Experiments show thatCritiCalsignificantly outperformsSelf-Critiqueand other competitive\nbaselines, even surpassing its teacher model, GPT-4o, in complex reasoning\ntasks.CritiCalalso shows robust generalization in out-of-distribution\nsettings, advancing LLM's reliability. Accurate confidence calibration in Large Language Models (LLMs) is critical for safe use in high-stakes domains, where clear verbalized confidence enhances user trust. Traditional methods that mimic reference confidence expressions often fail to capture the reasoning needed for accurate confidence assessment. We propose natural language critiques as a solution, ideally suited for confidence calibration, as precise gold confidence labels are hard to obtain and often require multiple generations. This paper studies how natural language critiques can enhance verbalized confidence, addressing: (1) What to critique: uncertainty (question-focused) or confidence (answer-specific)? Analysis shows confidence suits multiple-choice tasks, while uncertainty excels in open-ended scenarios. (2) How to critique: self-critique or critique calibration training? We propose Self-Critique, enabling LLMs to critique and optimize their confidence beyond mere accuracy, and CritiCal, a novel Critique Calibration training method that leverages natural language critiques to improve confidence calibration, moving beyond direct numerical optimization. Experiments show that CritiCal significantly outperforms Self-Critique and other competitive baselines, even surpassing its teacher model, GPT-4o, in complex reasoning tasks. CritiCal also shows robust generalization in out-of-distribution settings, advancing LLM's reliability. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546080",
    "title": "CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?",
    "authors": [
      "Jiayu Liu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/HKUST-KnowComp/CritiCal",
    "huggingface_url": "https://huggingface.co/papers/2510.24505",
    "upvote": 3
  }
}