{
  "context": "A text-to-image model trained on long structured captions with DimFusion fusion mechanism and TaBR evaluation protocol achieves state-of-the-art prompt alignment and improved controllability. Text-to-image modelshave rapidly evolved from casual creative tools to\nprofessional-grade systems, achieving unprecedented levels of image quality and\nrealism. Yet, most models are trained to map short prompts into detailed\nimages, creating a gap between sparse textual input and rich visual outputs.\nThis mismatch reduces controllability, as models often fill in missing details\narbitrarily, biasing toward average user preferences and limiting precision for\nprofessional use. We address this limitation by training the first open-source\ntext-to-image model onlong structured captions, where every training sample is\nannotated with the same set offine-grained attributes. This design maximizes\nexpressive coverage and enablesdisentangled controlover visual factors. To\nprocess long captions efficiently, we proposeDimFusion, afusion mechanismthat integrates intermediate tokens from alightweight LLMwithout increasing\ntoken length. We also introduce theText-as-a-Bottleneck Reconstruction(TaBR)\nevaluation protocol. By assessing how well real images can be reconstructed\nthrough a captioning-generation loop, TaBR directly measures controllability\nand expressiveness, even for very long captions where existing evaluation\nmethods fail. Finally, we demonstrate our contributions by training the\nlarge-scale modelFIBO, achieving state-of-the-artprompt alignmentamong\nopen-source models. Model weights are publicly available at\nhttps://huggingface.co/briaai/FIBO Generating an image from 1,000 words. Very excited to release Fibo ðŸ˜ƒ, the first ever open-source model trained exclusively on long, structured captions. Fibo sets a new standard for controllability and disentanglement in image generation This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Very nice work! It's great to see that we're thinking along the same lines! We had a very similar idea, also utilizing structural knowledge for controllable missing modality handling. You can check out our paper: 'Knowledge Bridger: Towards Training-Free Missing Modality Completion' (CVPR 2025). Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546028",
    "title": "Generating an Image From 1,000 Words: Enhancing Text-to-Image With\n  Structured Captions",
    "authors": [
      "Hezi Zisman",
      "Kfir Goldberg",
      "Ron Mokady"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Bria-AI/FIBO",
    "huggingface_url": "https://huggingface.co/papers/2511.06876",
    "upvote": 27
  }
}