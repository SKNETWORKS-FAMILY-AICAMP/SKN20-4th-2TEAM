{
  "context": "TiDAR combines diffusion and autoregressive models to achieve high throughput and quality in language generation. Diffusion language modelshold the promise of fast parallel generation, while autoregressive (AR) models typically excel in quality due to theircausal structurealigning naturally with language modeling. This raises a fundamental question: can we achieve a synergy with high throughput, higher GPU utilization, and AR level quality? Existing methods fail to effectively balance these two aspects, either prioritizing AR using a weaker model for sequential drafting (speculative decoding), leading to lower drafting efficiency, or using some form of left-to-right (AR-like) decoding logic for diffusion, which still suffers from quality degradation and forfeits its potential parallelizability. We introduce TiDAR, asequence-level hybrid architecturethat drafts tokens (Thinking) in Diffusion and samples final outputs (Talking) AutoRegressively - all within a single forward pass using specially designedstructured attention masks. This design exploits the freeGPU compute density, achieving a strong balance between drafting and verification capacity. Moreover, TiDAR is designed to beserving-friendly(low overhead) as a standalone model. We extensively evaluate TiDAR against AR models,speculative decoding, and diffusion variants across generative and likelihood tasks at 1.5B and 8B scales. Thanks to the parallel drafting and sampling as well as exactKV cache support, TiDAR outperformsspeculative decodingin measured throughput and surpasses diffusion models likeDreamandLladain both efficiency and quality. Most notably, TiDAR is the first architecture to close the quality gap with AR models while delivering 4.71x to 5.91x more tokens per second. TiDAR hybridizes diffusion drafting with autoregressive sampling in a single forward pass using structured attention, delivering AR-quality results with diffusion-style parallelism and high throughput. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/tidar-think-in-diffusion-talk-in-autoregression Interesting work! I would like to run some experiments using your approach.Do you have an estimated timeline for releasing the model weights? Demotime ! :) arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/tidar-think-in-diffusion-talk-in-autoregression-8138-9e3ac383 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546004",
    "title": "TiDAR: Think in Diffusion, Talk in Autoregression",
    "authors": [
      "Jingyu Liu",
      "Zhifan Ye",
      "Rishabh Mehta"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.08923",
    "upvote": 119
  }
}