{
  "context": "IterResearch, an iterative deep-research paradigm, improves long-horizon reasoning by reformulating it as a Markov Decision Process with strategic workspace reconstruction and Efficiency-Aware Policy Optimization, achieving better performance and interaction scaling compared to existing agents. Recent advances indeep-research agentshave shown promise for autonomous\nknowledge construction throughdynamic reasoningover external sources.\nHowever, existing approaches rely on amono-contextual paradigmthat\naccumulates all information in a single, expanding context window, leading tocontext suffocationandnoise contaminationthat limit their effectiveness onlong-horizon tasks. We introduceIterResearch, a novel iterative deep-research\nparadigm that reformulates long-horizon research as aMarkov Decision Processwithstrategic workspace reconstruction. By maintaining anevolving reportas\nmemory and periodically synthesizing insights, our approach preserves\nconsistent reasoning capacity across arbitrary exploration depths. We further\ndevelopEfficiency-Aware Policy Optimization(EAPO), areinforcement learningframework that incentivizes efficient exploration through geometric reward\ndiscounting and enables stable distributed training viaadaptive downsampling.\nExtensive experiments demonstrate thatIterResearchachieves substantial\nimprovements over existing open-source agents with average +14.5pp across six\nbenchmarks and narrows the gap with frontier proprietary systems. Remarkably,\nour paradigm exhibits unprecedented interaction scaling, extending to 2048\ninteractions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves\nas an effectiveprompting strategy, improving frontier models by up to 19.2pp\noverReActonlong-horizon tasks. These findings positionIterResearchas a\nversatile solution for long-horizon reasoning, effective both as a trained\nagent and as a prompting paradigm for frontier models. Key Insights: Apologies but I can’t seem to find the correct repository or section in your DeepResearch repo that includes the code for this although the paper states it’s all available. It’s probably me because I’ve had trouble finding the code for your other recent papers as well. Everything always links back to the primary DeepResearch repo as well as the primary model even when other models are mentioned. This makes it somewhat confusing. If you could provide a pointer to the code for this and if you have time how you organize your repo and models for the recent research papers related to DeepResearch I’d be most appreciative. Thank you, Christopher Thanks for your interest. Due to certain constraints, we are unable to release the code and model at this time. However, we will make them publicly available in this repository once we obtain the necessary permission. Thank you for your understanding. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Great work~ Congratulations on achieving amazing results on so many agent benchmarks. I would like to share with you thatreframing iterative self-improvement as a self-evolving Markov chainhas been established in this work,https://arxiv.org/abs/2510.17498. Thank you so much for the warm words — really appreciate it!Your work looks fascinating, especially the perspective of framing iterative self-improvement as a self-evolving Markov chain. I’m excited to read it more thoroughly. For context, most of our framework design, experiments, and papers were wrapped up around early September, and we consolidated everything for public release later on. Some related components also appeared in our earlier technical reports (https://arxiv.org/abs/2509.13309,https://arxiv.org/abs/2510.24701) as part of the same research process. It’s always inspiring to see parallel ideas emerging in the community. Thanks again for sharing — looking forward to learning more from your work, and we’ll definitely keep it in mind for future revisions and discussions. ❤️ ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546009",
    "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State\n  Reconstruction",
    "authors": [
      "Guoxin Chen",
      "Xuanzhong Chen"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.07327",
    "upvote": 76
  }
}