{
  "context": "VADER, an LLM-driven framework, enhances video anomaly understanding by integrating keyframe object relations and visual cues to provide detailed, causally grounded descriptions and robust question answering. Video anomaly understanding (VAU) aims to provide detailed interpretation and\nsemantic comprehension of anomalous events within videos, addressing\nlimitations of traditional methods that focus solely on detecting and\nlocalizing anomalies. However, existing approaches often neglect the deeper\ncausal relationships and interactions between objects, which are critical for\nunderstanding anomalous behaviors. In this paper, we propose VADER, an\nLLM-driven framework for Video Anomaly unDErstanding, which integrates keyframe\nobject Relation features with visual cues to enhance anomaly comprehension from\nvideo. Specifically, VADER first applies anAnomaly Scorerto assign per-frame\nanomaly scores, followed by aContext-AwarE Sampling(CAES) strategy to capture\nthe causal context of each anomalous event. ARelation Feature Extractorand aCOntrastive Relation Encoder(CORE) jointly model dynamic object interactions,\nproducing compact relational representations for downstream reasoning. These\nvisual and relational cues are integrated withLLMsto generate detailed,\ncausally grounded descriptions and support robust anomaly-related question\nanswering. Experiments on multiple real-world VAU benchmarks demonstrate that\nVADER achieves strong results acrossanomaly description,explanation, andcausal reasoningtasks, advancing the frontier of explainable video anomaly\nanalysis. In this paper, we propose VADER, an LLM-driven framework for Video Anomaly unDErstanding, which integrates keyframe object Relation features with visual cues to enhance anomaly comprehension from video. Specifically, VADER first applies an Anomaly Scorer to assign per-frame anomaly scores, followed by a Context-AwarE Sampling (CAES) strategy to capture the causal context of each anomalous event. A Relation Feature Extractor and a COntrastive Relation Encoder (CORE) jointly model dynamic object interactions, producing compact relational representations for downstream reasoning. These visual and relational cues are integrated with LLMs to generate detailed, causally grounded descriptions and support robust anomaly-related question answering. Experiments on multiple real-world VAU benchmarks demonstrate that VADER achieves strong results across anomaly description, explanation, and causal reasoning tasks, advancing the frontier of explainable video anomaly analysis. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/vader-towards-causal-video-anomaly-understanding-with-relation-aware-large-language-models Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546065",
    "title": "VADER: Towards Causal Video Anomaly Understanding with Relation-Aware\n  Large Language Models",
    "authors": [
      "Min-Hung Chen"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.07299",
    "upvote": 5
  }
}