{
  "context": "A new reasoning data generation framework creates a large-scale vision-centric dataset with over 1M synthetic questions, enhancing performance across various benchmarks and improving cross-modality transfer. Recent progress inmultimodal reasoninghas been driven largely by undisclosed datasets and proprietary data synthesis recipes, leaving open questions about how to systematically build large-scale, vision-centric reasoning datasets, particularly for tasks that go beyond visual math. In this work, we introduce a newreasoning data generation frameworkspanning diverse skills and levels of complexity with over 1M high-qualitysynthetic vision-centric questions. The dataset also includespreference dataandinstruction promptssupporting both offline andonline RL. Our synthesis framework proceeds in two stages: (1) scale; and (2) complexity. Reasoning traces are then synthesized through a two-stage process that leveragesVLMsandreasoning LLMs, producingCoT tracesforVLMsthat capture the richness and diverse cognitive behaviors found in frontier reasoning models. Remarkably, we show thatfinetuningQwen2.5-VL-7Bon our data outperforms all open-data baselines across all evaluated vision-centric benchmarks, and even surpasses strong closed-data models such asMiMo-VL-7B-RLonV* Bench,CV-BenchandMMStar-V. Perhaps most surprising, despite being entirely vision-centric, our data transfers positively to text-only reasoning (MMLU-Pro) and audio reasoning (MMAU), demonstrating its effectiveness. Similarly, despite not containing videos or embodied visual data, we observe notable gains when evaluating on a single-evidence embodied QA benchmark (NiEH). Finally, we use our data to analyze the entire VLM post-training pipeline. Our empirical analysis highlights that (i)SFTon high-quality data with non-linear reasoning traces is essential for effectiveonline RL, (ii)staged offline RLmatchesonline RL's performance while reducing compute demands, and (iii) carefulSFTon high quality data can substantially improveout-of-domain,cross-modality transfer. new reasoning traces data generation solution to obtain visual reasoning state-of-the-art and improve omni perception. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546061",
    "title": "Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale",
    "authors": [
      "Jaehun Jung"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.05705",
    "upvote": 6
  }
}