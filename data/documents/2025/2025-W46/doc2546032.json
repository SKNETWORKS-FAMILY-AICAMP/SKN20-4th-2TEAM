{
  "context": "RedOne 2.0, a social networking service-oriented LLM, uses a progressive, RL-prioritized post-training paradigm to achieve rapid and stable adaptation, delivering improvements over larger baselines with less data. As a key medium for human interaction and information exchange, social\nnetworking services (SNS) pose unique challenges for large language models\n(LLMs): heterogeneous workloads, fast-shifting norms and slang, and\nmultilingual, culturally diverse corpora that induce sharp distribution shift.Supervised fine-tuning(SFT) can specialize models but often triggers a\n``seesaw'' between in-distribution gains and out-of-distribution robustness,\nespecially for smaller models. To address these challenges, we introduce RedOne\n2.0, an SNS-oriented LLM trained with a progressive,RL-prioritizedpost-training paradigm designed for rapid and stable adaptation. The pipeline\nconsist in three stages: (1)Exploratory Learningon curated SNS corpora to\nestablish initial alignment and identify systematic weaknesses; (2) Targeted\nFine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a\nsmall fraction of general data to mitigate forgetting; and (3) Refinement\nLearning that re-applies RL with SNS-centric signals to consolidate\nimprovements and harmonize trade-offs across tasks. Across various tasks\nspanning three categories, our 4B scale model delivers an average improvements\nabout 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves\naverage performance lift about 8.74 from the base model with less than half the\ndata required by SFT-centric method RedOne, evidencing superior data efficiency\nand stability at compact scales. Overall, RedOne 2.0 establishes a competitive,\ncost-effective baseline fordomain-specific LLMsin SNS scenario, advancing\ncapability without sacrificing robustness. An SNS-domain large language model primarily driven by reinforcement learning (RL), trained through three stages—Exploratory Learning (RL), Targeted Fine-Tuning (SFT), and Refinement Learning (RL)—which enhances both domain-specific and general capabilities. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546032",
    "title": "RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social\n  Networking Services",
    "authors": [],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.07070",
    "upvote": 19
  }
}