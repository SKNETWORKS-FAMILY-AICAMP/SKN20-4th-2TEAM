{
  "context": "The study identifies and defends against adversarial attacks in decentralized Group Relative Policy Optimization (GRPO) for Large Language Models (LLMs), demonstrating attack success rates of up to 100% and proposing effective defense mechanisms. Group Relative Policy Optimization(GRPO) has demonstrated great utilization in post-training ofLarge Language Models(LLMs). InGRPO, prompts are answered by the model and, throughreinforcement learning, preferred completions are learnt. Owing to the small communication volume,GRPOis inherently suitable fordecentralised trainingas the prompts can be concurrently answered by multiple nodes and then exchanged in the forms of strings. In this work, we present the first adversarial attack in decentralisedGRPO. We demonstrate that malicious parties can poison such systems by injecting arbitrarymalicious tokensin benign models in both out-of-context andin-context attacks. Using empirical examples of math and coding tasks, we show thatadversarial attackscan easily poison the benign nodes, polluting their local LLM post-training, achievingattack success ratesup to 100% in as few as 50 iterations. We propose two ways to defend against these attacks, depending on whether all users train the same model or different models. We show that these defenses can achieve stop rates of up to 100%, making the attack impossible. \"Hail to the Thief: Exploring Attacks and Defenses in Decentralized GRPO\" is the first systematic study exploring both attack vectors and defense strategies in decentralised reinforcement learning for Large Language Models (LLMs). We demonstrate how adversarial completions can corrupt RL training, causing honest models to produce arbitrary tokens during inference in as few as 20 iterations. We then propose effective, lightweight defenses that make these systems robust and trustworthy. Our work provides the first blueprint for achieving robust decentralised reinforcement learning for LLMs. Reinforcement learning (RL) has become the key to aligning LLMs with human intent, reasoning, and formatting. Due to the low communication required by GRPO (only completions, instead of the large gradients typically needed in training), it is particularly well-suited for decentralised reinforcement learning (dRL). Since dRL involves collaborative learning among participants who may not be known or trusted, attack risks emerge. A malicious participant can compromise others' models, embedding hidden behaviors or spreading subtle biases that others unknowingly learn. Mitigating these risks requires robust dRL mechanisms. This is incredibly important research for the decentralized AI ecosystem!Huge respect to the authors for uncovering how decentralized GRPO can be exploited â€” and more importantly, how it can be defended. As decentralized training scales up, work like this helps the entire community understand real attack surfaces and practical mitigation strategies. The fact that the paper not only demonstrates the vulnerabilities but also provides defenses capable of fully stopping the attacks is a massive contribution. Research like this strengthens trust, improves system robustness, and pushes decentralized LLM training closer to real-world readiness. ðŸ™ŒðŸ”¥ Kudos to the authors and to Gensyn for continuously pushing the boundaries of security in distributed LLM training. Excited to see what comes next! This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Really interesting work. I like how the authors didnâ€™t just point out the problem but actually showed real attacks and then real defenses that stop them completely. Decentralised training is growing fast, so understanding these risks early really matters.Nice to see Gensyn pushing research that actually helps the whole ecosystem. Curious to see what comes next from the team. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2546027",
    "title": "Hail to the Thief: Exploring Attacks and Defenses in Decentralised GRPO",
    "authors": [
      "Nikolay Blagoev",
      "OÄŸuzhan Ersoy"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.09780",
    "upvote": 27
  }
}