{
  "context": "A novel Soft Prompt approach enhances Vision-Language-Action models by using learnable embeddings for diverse robotic data, enabling superior performance across simulations and real-world robots. Successful generalist Vision-Language-Action (VLA) models rely on effective\ntraining across diverse robotic platforms with large-scale,cross-embodiment,\nheterogeneous datasets. To facilitate and leverage the heterogeneity in rich,\ndiverse robotic data sources, we propose a novelSoft Promptapproach with\nminimally added parameters, by infusingprompt learningconcepts intocross-embodimentrobot learning and introducing separate sets of learnable\nembeddings for each distinct data source. These embeddings serve asembodiment-specific prompts, which in unity empower VLA models with effective\nexploitation of varyingcross-embodimentfeatures. Our newX-VLA, a neatflow-matching-basedVLA architecture, relies exclusively on soft-prompted\nstandardTransformer encoders, enjoying both scalability and simplicity.\nEvaluated across 6 simulations as well as 3 real-world robots, our 0.9B\ninstantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep\nof benchmarks, demonstrating superior results on a wide axes of capabilities,\nfromflexible dexteritytoquick adaptationacross embodiments, environments,\nand tasks. Website: https://thu-air-dream.github.io/X-VLA/  This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2542087",
    "title": "X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment\n  Vision-Language-Action Model",
    "authors": [
      "Jinliang Zheng",
      "Dongxiu Liu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/2toinf/X-VLA.git",
    "huggingface_url": "https://huggingface.co/papers/2510.10274",
    "upvote": 15
  }
}