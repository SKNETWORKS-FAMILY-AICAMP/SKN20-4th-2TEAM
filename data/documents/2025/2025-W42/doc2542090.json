{
  "context": "Qwen3Guard introduces multilingual safety guardrail models with fine-grained tri-class judgments and real-time token-level safety monitoring for large language models. Aslarge language models(LLMs) become more capable and widely used, ensuring\nthe safety of their outputs is increasingly critical. Existing guardrail\nmodels, though useful in static evaluation settings, face two major limitations\nin real-world applications: (1) they typically output only binary \"safe/unsafe\"\nlabels, which can be interpreted inconsistently across diversesafety policies,\nrendering them incapable of accommodating varyingsafety tolerancesacross\ndomains; and (2) they require complete model outputs before performing safety\nchecks, making them fundamentally incompatible with streaming LLM inference,\nthereby preventing timely intervention during generation and increasing\nexposure to harmful partial outputs. To address these challenges, we present\nQwen3Guard, a series ofmultilingualsafety guardrail modelswith two\nspecialized variants:Generative Qwen3Guard, which casts safety classification\nas aninstruction-following taskto enable fine-grainedtri-class judgments(safe, controversial, unsafe); andStream Qwen3Guard, which introduces atoken-level classificationhead for real-time safety monitoring during\nincremental text generation. Both variants are available in three sizes (0.6B,\n4B, and 8B parameters) and support up to 119 languages and dialects, providing\ncomprehensive, scalable, and low-latency safety moderation for global LLM\ndeployments. Evaluated across English, Chinese, andmultilingualbenchmarks,\nQwen3Guard achieves state-of-the-art performance in both prompt and response\nsafety classification. All models are released under theApache 2.0 licensefor\npublic use. As large language models (LLMs) become more capable and widely used, ensuring the safety of their outputs is increasingly critical. Existing guardrail models, though useful in static evaluation settings, face two major limitations in real-world applications: (1) they typically output only binary \"safe/unsafe\" labels, which can be interpreted inconsistently across diverse safety policies, rendering them incapable of accommodating varying safety tolerances across domains; and (2) they require complete model outputs before performing safety checks, making them fundamentally incompatible with streaming LLM inference, thereby preventing timely intervention during generation and increasing exposure to harmful partial outputs. To address these challenges, we present Qwen3Guard, a series of multilingual safety guardrail models with two specialized variants: Generative Qwen3Guard, which casts safety classification as an instruction-following task to enable fine-grained tri-class judgments (safe, controversial, unsafe); and Stream Qwen3Guard, which introduces a token-level classification head for real-time safety monitoring during incremental text generation. Both variants are available in three sizes (0.6B, 4B, and 8B parameters) and support up to 119 languages and dialects, providing comprehensive, scalable, and low-latency safety moderation for global LLM deployments. Evaluated across English, Chinese, and multilingual benchmarks, Qwen3Guard achieves state-of-the-art performance in both prompt and response safety classification. All models are released under the Apache 2.0 license for public use. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2542090",
    "title": "Qwen3Guard Technical Report",
    "authors": [
      "Haiquan Zhao",
      "An Yang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/QwenLM/Qwen3Guard",
    "huggingface_url": "https://huggingface.co/papers/2510.14276",
    "upvote": 14
  }
}