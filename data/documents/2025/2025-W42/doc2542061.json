{
  "context": "R-HORIZON, a method using query composition, improves long-horizon reasoning in Large Reasoning Models through a benchmark of complex multi-step tasks, enhancing performance and accuracy. Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1,\nDeepSeek-R1) have led to remarkable improvements through longChain-of-Thought(CoT). However, existing benchmarks mainly focus on immediate, single-horizon\ntasks, failing to adequately evaluate models' ability to understand and respond\nto complex, long-horizon scenarios. To address this incomplete evaluation ofLarge Reasoning Models(LRMs), we propose R-HORIZON, a method designed to\nstimulatelong-horizon reasoningbehaviors inLRMsthroughquery composition.\nBased on R-HORIZON, we construct along-horizon reasoningbenchmark, comprising\ncomplex multi-step reasoning tasks with interdependent problems that span long\nreasoning horizons. Through comprehensive evaluation ofLRMsusing the\nR-HORIZON benchmark, we find that even the most advancedLRMssuffer\nsignificant performance degradation. Our analysis reveals thatLRMsexhibit\nlimited effective reasoning length and struggle to allocate thinking budget\nacross multiple problems appropriately. Recognizing these limitations, we use\nR-HORIZON to constructlong-horizon reasoningdata for reinforcement learning\nwith verified rewards (RLVR). Compared to training with single-horizon data,RLVRwith R-HORIZON not only substantially improves performance on the\nmulti-horizon reasoning tasks, but also promotes accuracy on standard reasoning\ntasks, with an increase of 7.5 onAIME2024. These results position R-HORIZON as\na scalable, controllable, and low-cost paradigm for enhancing and evaluating\nthelong-horizon reasoningcapabilities ofLRMs. Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1, DeepSeek-R1) have led to remarkable improvements through long Chain-of-Thought (CoT). However, existing benchmarks mainly focus on immediate, single-horizon tasks, failing to adequately evaluate models' ability to understand and respond to complex, long-horizon scenarios. To address this incomplete evaluation of Large Reasoning Models (LRMs), we propose R-HORIZON, a method designed to stimulate long-horizon reasoning behaviors in LRMs through query composition. Based on R-HORIZON, we construct a long-horizon reasoning benchmark, comprising complex multi-step reasoning tasks with interdependent problems that span long reasoning horizons. Through comprehensive evaluation of LRMs using the R-HORIZON benchmark, we find that even the most advanced LRMs suffer significant performance degradation. Our analysis reveals that LRMs exhibit limited effective reasoning length and struggle to allocate thinking budget across multiple problems appropriately. Recognizing these limitations, we use R-HORIZON to construct long-horizon reasoning data for reinforcement learning with verified rewards (RLVR). Compared to training with single-horizon data, RLVR with R-HORIZON not only substantially improves performance on the multi-horizon reasoning tasks, but also promotes accuracy on standard reasoning tasks, with an increase of 7.5 on AIME2024. These results position R-HORIZON as a scalable, controllable, and low-cost paradigm for enhancing and evaluating the long-horizon reasoning capabilities of LRMs. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2542061",
    "title": "R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth\n  and Depth?",
    "authors": [
      "Yi Lu",
      "Linsen Guo",
      "Wei He"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/LuLuLuyi/R-HORIZON",
    "huggingface_url": "https://huggingface.co/papers/2510.08189",
    "upvote": 26
  }
}