{
  "context": "A two-stage paradigm adapts pre-trained Text-to-Video models for viewpoint prediction in 4D scenes by integrating an adaptive learning branch and a camera extrinsic diffusion branch. Recent Text-to-Video (T2V) models have demonstrated powerful capability in\nvisual simulation of real-world geometry and physical laws, indicating its\npotential as implicit world models. Inspired by this, we explore the\nfeasibility of leveraging the video generation prior forviewpoint planningfrom given4D scenes, since videos internally accompany dynamic scenes with\nnatural viewpoints. To this end, we propose a two-stage paradigm to adapt\npre-trained T2V models for viewpoint prediction, in a compatible manner. First,\nwe inject the 4D scene representation into the pre-trained T2V model via anadaptive learning branch, where the 4D scene is viewpoint-agnostic and the\nconditional generated video embeds the viewpoints visually. Then, we formulateviewpoint extractionas ahybrid-condition guided camera extrinsic denoisingprocess. Specifically, acamera extrinsic diffusion branchis further\nintroduced onto the pre-trained T2V model, by taking the generated video and 4D\nscene as input. Experimental results show the superiority of our proposed\nmethod over existing competitors, and ablation studies validate the\neffectiveness of our key technical designs. To some extent, this work proves\nthe potential of video generation models toward 4D interaction in real world. TL;DR: We propose AdaViewPlanner, a framework that adapts pre-trained text-to-video models for automatic viewpoint planning in 4D scenes. Given 4D content and text prompts describing the scene context and desired camera motion, our model can generate coordinate-aligned camera pose sequences along with corresponding video visualizations. Leveraging the priors of video generation models, AdaViewPlanner demonstrates strong capability for smooth, diverse, instruction-following, and human-centric viewpoint planning in 4D scenes. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2542076",
    "title": "AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning\n  in 4D Scenes",
    "authors": [],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2510.10670",
    "upvote": 18
  }
}