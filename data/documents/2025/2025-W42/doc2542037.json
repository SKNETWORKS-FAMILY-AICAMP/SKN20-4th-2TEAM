{
  "context": "Diffusion models have recently advanced video restoration, but applying them\nto real-world video super-resolution (VSR) remains challenging due to high\nlatency, prohibitive computation, and poor generalization to ultra-high\nresolutions. Our goal in this work is to make diffusion-based VSR practical by\nachieving efficiency, scalability, and real-time performance. To this end, we\npropose FlashVSR, the first diffusion-based one-step streaming framework\ntowards real-time VSR. FlashVSR runs at approximately 17 FPS for 768x1408\nvideos on a single A100 GPU by combining three complementary innovations: (i) a\ntrain-friendly three-stage distillation pipeline that enables streaming\nsuper-resolution, (ii) locality-constrained sparse attention that cuts\nredundant computation while bridging the train-test resolution gap, and (iii) a\ntiny conditional decoder that accelerates reconstruction without sacrificing\nquality. To support large-scale training, we also construct VSR-120K, a new\ndataset with 120k videos and 180k images. Extensive experiments show that\nFlashVSR scales reliably to ultra-high resolutions and achieves\nstate-of-the-art performance with up to 12x speedup over prior one-step\ndiffusion VSR models. We will release the code, pretrained models, and dataset\nto foster future research in efficient diffusion-based VSR. TL;DR — FlashVSR is a streaming, one-step diffusion-based video super-resolution framework with block-sparse attention and a Tiny Conditional Decoder. It reaches ~17 FPS at 768×1408 on a single A100 GPU. A Locality-Constrained Attention design further improves generalization and perceptual quality on ultra-high-resolution videos. FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-ResolutionPage:https://zhuang2002.github.io/FlashVSR/Paper:https://arxiv.org/abs/2510.12747Code:https://github.com/OpenImagingLab/FlashVSR⭐ If you like our work, please give it a star! This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2542037",
    "title": "FlashVSR: Towards Real-Time Diffusion-Based Streaming Video\n  Super-Resolution",
    "authors": [
      "Junhao Zhuang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/OpenImagingLab/FlashVSR",
    "huggingface_url": "https://huggingface.co/papers/2510.12747",
    "upvote": 37
  }
}