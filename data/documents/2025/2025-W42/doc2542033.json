{
  "context": "State-of-the-art Visual-Language-Action models show high benchmark scores but are brittle to various perturbations, particularly in camera viewpoints and robot initial states, and often ignore language instructions. Visual-Language-Action (VLA) models report impressive success rates on\nrobotic manipulation benchmarks, yet these results may mask fundamental\nweaknesses in robustness. We perform a systematicvulnerability analysisby\nintroducing controlledperturbationsacross seven dimensions:objects layout,camera viewpoints,robot initial states,language instructions, light\nconditions,background texturesandsensor noise. We comprehensively analyzed\nmultiple state-of-the-art models and revealed consistentbrittlenessbeneath\napparent competence. Our analysis exposes critical weaknesses: models exhibit\nextreme sensitivity to perturbation factors, includingcamera viewpointsandrobot initial states, with performance dropping from 95% to below 30% under\nmodestperturbations. Surprisingly, models are largely insensitive to language\nvariations, with further experiments revealing that models tend to ignorelanguage instructionscompletely. Our findings challenge the assumption that\nhigh benchmark scores equate to true competency and highlight the need for\nevaluation practices that assessreliabilityunder realistic variation. üöÄ Introducing LIBERO-Plus: A Comprehensive Benchmark for Vision-Language-Action Models We are excited to unveil LIBERO-Plus, an advanced robustness evaluation tool for Vision-Language-Action (VLA) models. LIBERO-Plus allows researchers to understand how these models perform under various environmental perturbations, shedding light on their vulnerabilities in real-world settings. üîç Novel Findings: Uncovering Hidden Vulnerabilities Models exhibit extreme sensitivity to perturbation factors, including camera viewpoints and robot initial states, with performance dropping from 95% to below 30% under modest perturbations. Models are largely insensitive to language variations, with further experiments revealing that models tend to ignore language instructions completely. Models exhibit a reliance on superficial visual cues, such as positional bias, rather than a genuine semantic understanding of task-relevant objects. Compositional Generalization is intrinsically non-decomposable. Training Data Diversity Significantly Improves Robustness. ... For more detailed information, please check out our paper. ‚öôÔ∏è Easy to Use: Seamless Transition to LIBERO-Plus LIBERO-Plus makes it incredibly easy for users to evaluate the robustness of their existing models. With just a few simple steps, you can seamlessly switch from LIBERO to LIBERO-Plus, unlocking powerful tools for automatic and fine-grained evaluation. üìä Comprehensive, Automatic, and Fine-Grained Benchmark LIBERO-Plus offers a robust benchmarking framework with 7 perturbation dimensions and 21 sub-dimensions. It provides a fine-grained difficulty scale from L1 to L5, allowing users to systematically assess model performance across various challenges. The construction is automated, including both training and testing datasets, making it easier than ever to conduct comprehensive assessments. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ¬∑Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2542033",
    "title": "LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action\n  Models",
    "authors": [
      "Siyin Wang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/sylvestf/LIBERO-plus",
    "huggingface_url": "https://huggingface.co/papers/2510.13626",
    "upvote": 45
  }
}