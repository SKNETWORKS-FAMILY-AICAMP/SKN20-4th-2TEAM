{
  "context": "FinAuditing is a benchmark for evaluating LLMs on structured financial auditing tasks, revealing their limitations in handling taxonomy-driven, hierarchical financial documents. The complexity of the Generally Accepted Accounting Principles (GAAP) and the\nhierarchical structure of eXtensible Business Reporting Language (XBRL) filings\nmake financial auditing increasingly difficult to automate and verify. While\nlarge language models (LLMs) have demonstrated strong capabilities in\nunstructured text understanding, their ability to reason over structured,\ninterdependent, and taxonomy-driven financial documents remains largely\nunexplored. To fill this gap, we introduceFinAuditing, the firsttaxonomy-aligned,structure-aware,multi-document benchmarkfor evaluatingLLMson financial auditing tasks. Built from realUS-GAAP-compliantXBRL filings,FinAuditingdefines three complementary subtasks,FinSMfor semantic\nconsistency,FinREforrelational consistency, andFinMRfor numerical\nconsistency, each targeting a distinct aspect of structured auditing reasoning.\nWe further propose a unified evaluation framework integratingretrieval,classification, andreasoning metricsacross these subtasks. Extensivezero-shot experimentson 13 state-of-the-artLLMsreveal that current models\nperform inconsistently across semantic, relational, and mathematical\ndimensions, with accuracy drops of up to 60-90% when reasoning over\nhierarchical multi-document structures. Our findings expose the systematic\nlimitations of modernLLMsin taxonomy-grounded financial reasoning and\nestablishFinAuditingas a foundation for developing trustworthy,structure-aware, and regulation-aligned financial intelligence systems. The\nbenchmark dataset is available at Hugging Face. FinAuditing is a taxonomy aligned and structure aware benchmark designed to evaluate large language models (LLMs) on financial auditing reasoning. It is built from real US GAAP compliant XBRL filings and defines three complementary subtasks: FinSM for semantic consistency, FinRE for relational consistency, and FinMR for numerical consistency. These tasks jointly assess models’ ability to reason over hierarchical and interdependent financial documents. Experiments on 13 state of the art LLMs reveal substantial performance gaps, highlighting the challenges of structured and taxonomy grounded financial reasoning and underscoring the need for more trustworthy and regulation aligned financial intelligence systems. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2542073",
    "title": "FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark\n  for Evaluating LLMs",
    "authors": [
      "Yan Wang",
      "Jimin Huang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/The-FinAI/FinAuditing.git",
    "huggingface_url": "https://huggingface.co/papers/2510.08886",
    "upvote": 19
  }
}