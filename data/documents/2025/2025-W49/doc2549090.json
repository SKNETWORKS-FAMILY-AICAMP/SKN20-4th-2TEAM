{
  "context": "MagicQuill V2 introduces a layered composition paradigm for generative image editing, combining diffusion models with granular control, enabling clear separation and manipulation of user intentions for content, position, shape, and color. We propose MagicQuill V2, a novel system that introduces alayered compositionparadigm togenerative image editing, bridging the gap between thesemantic powerofdiffusion modelsand thegranular controlof traditional graphics software. Whilediffusion transformersexcel at holistic generation, their use of singular, monolithic prompts fails to disentangle distinct user intentions for content, position, and appearance. To overcome this, our method deconstructscreative intentinto a stack of controllable visual cues: acontent layerfor what to create, aspatial layerfor where to place it, astructural layerfor how it is shaped, and acolor layerfor its palette. Our technical contributions include a specialized data generation pipeline forcontext-aware content integration, aunified control moduleto process all visual cues, and afine-tuned spatial branchfor precise local editing, includingobject removal. Extensive experiments validate that this layered approach effectively resolves the user intention gap, granting creators direct, intuitive control over the generative process.  • Project Page:https://magicquill.art/v2• Code:https://github.com/zliucz/MagicQuillV2• HuggingFace Space:https://huggingface.co/spaces/AI4Editing/MagicQuillV2 This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2549090",
    "title": "MagicQuillV2: Precise and Interactive Image Editing with Layered Visual Cues",
    "authors": [
      "Zichen Liu",
      "Yue Yu",
      "Qiuyu Wang",
      "Wen Wang",
      "Yanhong Zeng"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/zliucz/MagicQuillV2",
    "huggingface_url": "https://huggingface.co/papers/2512.03046",
    "upvote": 11
  }
}