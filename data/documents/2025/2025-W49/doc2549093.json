{
  "context": "RULER-Bench evaluates video generation models' reasoning abilities through 40 tasks across six categories, revealing gaps in their rule coherence and providing a benchmark for future improvements. Recent advances invideo generationhave enabled the synthesis of videos with strongtemporal consistencyand impressivevisual quality, marking a crucial step towardvision foundation models. To evaluate thesevideo generationmodels, existing benchmarks primarily focus on factors related to visual perception and understanding, likevisual aesthetics,instruction adherence, andtemporal coherence. However, the rule-basedreasoning capabilitiesofvideo generationmodels remain largely unexplored. Although recent studies have carried out preliminary explorations into whether video models can serve aszero-shot learners, they still lack a fine-grained decomposition ofreasoning capabilitiesand a comprehensive evaluation protocol. To address this gap, we introduceRULER-Bench, a benchmark designed to evaluate the reasoning ability ofvideo generationmodels from the perspective ofcognitive rules. Built upon two fundamental paradigms:text-to-videoandimage-to-video,RULER-Benchcovers 40 representative tasks spanning six rule categories with 622 high-qualityannotated instances. For the evaluation of each generated video, we construct achecklistcovering four metrics and leverageGPT-o3to assign scores to each question, achieving 85% alignment with human judgements. Extensive experiments show that the state-of-the-art model achieves only 48.87% on therule coherencemetric, highlighting significant room for improvement in the reasoning capability of next-level video models. We expect that the insight obtained fromRULER-Benchwill facilitate further development ofreasoning-aware video generation, advancingvideo generationmodels towardvision foundation intelligence. Recent advances in video generation have enabled the synthesis of videos with strong temporal consistency and impressive visual quality, marking a crucial step toward vision foundation models. To evaluate these video generation models, existing benchmarks primarily focus on factors related to visual perception and understanding, like visual aesthetics, instruction adherence, and temporal coherence. However, the rule-based reasoning capabilities of video generation models remain largely unexplored. Although recent studies have carried out preliminary explorations into whether video models can serve as zero-shot learners, they still lack a fine-grained decomposition of reasoning capabilities and a comprehensive evaluation protocol. To address this gap, we introduce RULER-Bench, a benchmark designed to evaluate the reasoning ability of video generation models from the perspective of cognitive rules. Built upon two fundamental paradigms: text-to-video and image-to-video, RULER-Bench covers 40 representative tasks spanning six rule categories with 622 high-quality annotated instances.  For the evaluation of each generated video, we construct a checklist covering four metrics and leverage GPT-o3 to assign scores to each question, achieving 85% alignment with human judgements. Extensive experiments show that the state-of-the-art model achieves only 48.87% on the rule coherence metric, highlighting significant room for improvement in the reasoning capability of next-level video models. We expect that the insight obtained from RULER-Bench will facilitate further development of reasoning-aware video generation, advancing video generation models toward vision foundation intelligence. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2549093",
    "title": "RULER-Bench: Probing Rule-based Reasoning Abilities of Next-level Video Generation Models for Vision Foundation Intelligence",
    "authors": [
      "Xuming He"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/hexmSeeU/RULER-Bench",
    "huggingface_url": "https://huggingface.co/papers/2512.02622",
    "upvote": 9
  }
}