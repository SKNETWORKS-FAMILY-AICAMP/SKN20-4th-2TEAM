{
  "context": "A new VLN agent framework, SeeNav-Agent, improves navigation performance by reducing visual hallucinations and enhancing planning through dual-view visual prompts and step-level reinforcement fine-tuning with SRGPO. Existing Vision-Language Navigation (VLN) agents based onLarge Vision-Language Models (LVLMs)often suffer from perception errors, reasoning errors, and planning errors, which significantly hinder their navigation performance. To address these limitations, a novelVLN agentframework, named SeeNav-Agent, is proposed in this work. First, to reduceperception hallucinationsof the visual module of theVLN agent, adual-view Visual Prompt (VP)technique is introduced in the input space, which can also improve the agent's understanding of current spatial states. Subsequently, a novelstep-level Reinforcement Fine-Tuning (RFT)method,Step Reward Group Policy Optimization (SRGPO), is designed for the post-training ofVLN agents. In SRGPO, we first define verifiable process rewards for the navigation task, and then perform efficient step-level advantage estimation by randomly grouping different navigation steps. SRGPO provides dense reward signals for the reinforcement learning process of theVLN agentand enhances its planning capability. Experimental results on theEmbodiedBench Navigation benchmarkindicate that by introducing the zero-shot VP module, theGPT-4.1achieves anavigation success rateof 86.7%, surpassing the current best LVLM by approximately 20 percentage points (pp). Through post-training based on SRGPO, theQwen2.5-VL-3Bmodel reaches anavigation success rateof 72.3%, outperforming the best existing LVLM model by 5.6 pp. Moreover, compared to RFT algorithms such asGRPOandGiGPO, the proposed SRGPO demonstrates significant improvements in training stability, convergence efficiency, and generalization capability. ðŸŽ¯ Code:https://github.com/WzcTHU/SeeNav-AgentðŸ¤— Model:https://huggingface.co/wangzc9865/SeeNav-Agent This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2549102",
    "title": "SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization",
    "authors": [
      "Zichuan Lin"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/WzcTHU/SeeNav-Agent",
    "huggingface_url": "https://huggingface.co/papers/2512.02631",
    "upvote": 8
  }
}