{
  "context": "Live Avatar uses a 14-billion-parameter diffusion model with Timestep-forcing Pipeline Parallelism and Rolling Sink Frame Mechanism to achieve real-time, high-fidelity avatar generation. Existingdiffusion-based video generationmethods are fundamentally constrained bysequential computationandlong-horizon inconsistency, limiting their practical adoption inreal-time,streaming audio-driven avatar synthesis. We present Live Avatar, an algorithm-system co-designed framework that enables efficient, high-fidelity, and infinite-length avatar generation using a 14-billion-parameter diffusion model. Our approach introducesTimestep-forcing Pipeline Parallelism(TPP), adistributed inference paradigmthat pipelinesdenoising stepsacross multiple GPUs, effectively breaking theautoregressive bottleneckand ensuring stable,low-latency real-time streaming. To further enhance temporal consistency and mitigate identity drift and color artifacts, we propose theRolling Sink Frame Mechanism(RSFM), which maintainssequence fidelityby dynamically recalibrating appearance using a cached reference image. Additionally, we leverageSelf-Forcing Distribution Matching Distillationto facilitatecausal,streamable adaptationof large-scale models without sacrificingvisual quality. Live Avatar demonstrates state-of-the-art performance, reaching 20 FPSend-to-end generationon 5H800 GPUs, and, to the best of our knowledge, is the first to achieve practical,real-time, high-fidelity avatar generation at this scale. Our work establishes a new paradigm for deploying advanced diffusion models in industrial long-form video synthesis applications.  Interactive video demo:https://liveavatar.github.io/ Github repo:https://github.com/Alibaba-Quark/LiveAvatarThe model is coming in a couple of days. Stay tuned! This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/live-avatar-streaming-real-time-audio-driven-avatar-generation-with-infinite-length-9586-061c9a5d arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/live-avatar-streaming-real-time-audio-driven-avatar-generation-with-infinite-length Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2549005",
    "title": "Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length",
    "authors": [
      "Yubo Huang",
      "Enhong Chen",
      "Jiaming Liu",
      "Steven Hoi"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Alibaba-Quark/LiveAvatar",
    "huggingface_url": "https://huggingface.co/papers/2512.04677",
    "upvote": 167
  }
}