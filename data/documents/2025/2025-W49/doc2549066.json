{
  "context": "A Transformer-based framework, 4DLangVGGT, enhances 4D scene understanding by integrating geometric perception and language alignment, achieving scalability and generalization across dynamic scenes. Constructing4D language fieldsis crucial forembodied AI,augmented/virtual reality, and4D scene understanding, as they provide enrichedsemantic representationsof dynamic environments and enable open-vocabulary querying in complex scenarios. However, existing approaches to 4D semantic field construction primarily rely on scene-specificGaussian splatting, which requires per-scene optimization, exhibits limited generalization, and is difficult to scale to real-world applications. To address these limitations, we propose 4DLangVGGT, the firstTransformer-basedfeed-forward unified frameworkfor 4D language grounding, that jointly integrates geometric perception and language alignment within a single architecture. 4DLangVGGT has two key components: the4D Visual Geometry Transformer,StreamVGGT, which capturesspatio-temporal geometric representationsof dynamic scenes; and theSemantic Bridging Decoder(SBD), which projectsgeometry-aware featuresinto alanguage-aligned semantic space, thereby enhancing semantic interpretability while preserving structural fidelity. Unlike prior methods that depend on costly per-scene optimization, 4DLangVGGT can be jointly trained across multiple dynamic scenes and directly applied during inference, achieving both deployment efficiency and strong generalization. This design significantly improves the practicality of large-scale deployment and establishes a new paradigm for open-vocabulary4D scene understanding. Experiments onHyperNeRFandNeu3D datasetsdemonstrate that our approach not only generalizes effectively but also achieves state-of-the-art performance, achieving up to 2% gains under per-scene training and 1% improvements under multi-scene training. Our code released in https://github.com/hustvl/4DLangVGGT code:https://github.com/hustvl/4DLangVGGTwebpage:https://hustvl.github.io/4DLangVGGT/ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2549066",
    "title": "4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer",
    "authors": [
      "Xianzu Wu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/hustvl/4DLangVGGT",
    "huggingface_url": "https://huggingface.co/papers/2512.05060",
    "upvote": 18
  }
}