{
  "context": "A comprehensive investigation into generating and editing structured visuals using a unified model integrating a VLM with FLUX Kontext, achieving strong performance and introducing a new benchmark and evaluation metric. While modern visual generation models excel at creating aesthetically\npleasing natural images, they struggle with producing or editing structured\nvisuals like charts, diagrams, and mathematical figures, which demand\ncomposition planning, text rendering, and multimodal reasoning for factual\nfidelity. To address this, we present the first comprehensive, systematic\ninvestigation of this domain, encompassing data construction, model training,\nand an evaluation benchmark. First, we construct a large-scale dataset of 1.3\nmillion high-quality structured image pairs derived from executable drawing\nprograms and augmented withchain-of-thought reasoningannotations. Building on\nit, we train a unified model that integrates aVLMwith FLUX.1 Kontext via a\nlightweight connector for enhancedmultimodal understanding. A three-stage\ntraining curriculum enables progressivefeature alignment,knowledge infusion,\nandreasoning-augmented generation, further boosted by an external reasoner at\ninference time. Finally, we introduceStructBench, a novel benchmark for\ngeneration and editing with over 1,700 challenging instances, and an\naccompanying evaluation metric,StructScore, which employs a multi-round Q\\&A\nprotocol to assess fine-grained factual accuracy. Evaluations of 15 models\nreveal that even leading closed-source systems remain far from satisfactory.\nOur model attains strong editing performance, and inference-time reasoning\nyields consistent gains across diverse architectures. By releasing the dataset,\nmodel, and benchmark, we aim to advance unified multimodal foundations for\nstructured visuals. Project Page:https://structvisuals.github.io/ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541066",
    "title": "Factuality Matters: When Image Generation and Editing Meet Structured\n  Visuals",
    "authors": [
      "Le Zhuo",
      "Songhao Han",
      "Yuandong Pu",
      "Boxiang Qiu",
      "Sayak Paul",
      "Xi Chen"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/zhuole1025/Structured-Visuals",
    "huggingface_url": "https://huggingface.co/papers/2510.05091",
    "upvote": 19
  }
}