{
  "context": "MeDiM, a medical discrete diffusion model, integrates multimodal biomedical data by learning shared distributions across images, text, and clinical notes, achieving high-fidelity generation and enhanced downstream performance. Recent advances in generative medical models are constrained by\nmodality-specific scenarios that hinder the integration of complementary\nevidence from imaging, pathology, and clinical notes. This fragmentation limits\ntheir evolution into foundation models that can learn and reason across the\nfull spectrum of biomedical data. We propose MeDiM, the first medical discrete\ndiffusion model that learns shared distributions across modalities without\nmodality-specific components. MeDiM unifies multiple generative tasks:\ntranslating between images and text, and jointly producing image-report pairs\nacross domains in response to prompts. Built on a discrete diffusion framework,\nMeDiM bridges vision and language representations through a shared\nprobabilistic space. To enable unified and flexible medical generation, we\nemploy amultimodal large language model(MLLM) as the diffusion backbone,\nleveraging its prior knowledge and cross-modal reasoning. Two key designs are\nintroduced: (1) removing the causal attention mask forbidirectional context,\nand (2) injectingcontinuous timestep embeddingsfor diffusion awareness.\nExperiments demonstrate high-fidelity medical generation (FID16.60 on\nMIMIC-CXR andFID24.19 on PathGen) and accurate report generation (METEOR0.2650 and 0.2580). Jointly generated image-report pairs further enhance\ndownstream performance (plus6.43 percentBLEU-1, plus18.57 percentBLEU-2,\nplus31.58 percentBLEU-3, plus4.80 percentMETEOR), showing that MeDiM supports\ncoherent and clinically grounded multimodal outputs. project page:https://jwmao1.github.io/MeDiM_web/code:https://github.com/UCSC-VLAA/MeDiM This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541096",
    "title": "Discrete Diffusion Models with MLLMs for Unified Medical Multimodal\n  Generation",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/UCSC-VLAA/MeDiM",
    "huggingface_url": "https://huggingface.co/papers/2510.06131",
    "upvote": 10
  }
}