{
  "context": "Markovian Thinking, implemented in Delethink, enables efficient and scalable reinforcement learning for long-chain-of-thought reasoning in LLMs by decoupling thinking length from context size, resulting in linear compute and constant memory usage. Reinforcement learning(RL) has recently become a strong recipe for trainingreasoning LLMsthat produce long chains of thought (LongCoT). Yet the standard\nRL \"thinking environment\", where the state is the prompt plus all prior\nreasoning tokens, makes the state unbounded and forcesattention-based policiesto pay quadratic compute as thoughts lengthen. We revisit the environment\nitself. We proposeMarkovian Thinking, a paradigm in which the policy advances\nreasoning while conditioning on a constant-size state, decoupling thinking\nlength from context size. As an immediate consequence this yields linear\ncompute with constant memory. We instantiate this idea withDelethink, an RL\nenvironment that structures reasoning intofixed-size chunks. Within each\nchunk, the model thinks as usual; at the boundary, the environment resets the\ncontext and reinitializes the prompt with a short carryover. Through RL, the\npolicy learns to write a textual state near the end of each chunk sufficient\nfor seamless continuation of reasoning after reset. Trained in this\nenvironment, anR1-Distill1.5B model reasons in 8K-token chunks yet thinks up\nto 24K tokens, matching or surpassingLongCoT-RL trained with a 24K budget.\nWithtest-time scaling,Delethinkcontinues to improve whereLongCoTplateaus.\nThe effect of linear compute is substantial: we empirically estimate at 96K\naverage thinking lengthLongCoT-RL costs 27 H100-months vs. 7 forDelethink.\nAnalysis atRL initializationshows off-the-shelfreasoning models(1.5B-120B)\noften sample Markovian traces zero-shot across diverse benchmarks, providing\npositive samples that make RL effective at scale. Our results show that\nredesigning the thinking environment is a powerful lever: it enables very long\nreasoning without quadratic overhead and opens a path toward efficient,\nscalablereasoning LLMs. Takeaways This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541039",
    "title": "The Markovian Thinker",
    "authors": [
      "Milad Aghajohari",
      "Kamran Chitsaz",
      "Amirhossein Kazemnejad"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/McGill-NLP/the-markovian-thinker",
    "huggingface_url": "https://huggingface.co/papers/2510.06557",
    "upvote": 30
  }
}