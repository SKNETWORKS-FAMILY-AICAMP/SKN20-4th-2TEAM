{
  "context": "General Policy Composition (GPC) enhances robotic control performance by combining pre-trained diffusion-based policies without additional training, leading to superior results across various benchmarks. Diffusion-based modelsfor robotic control, includingvision-language-action(VLA) andvision-action(VA) policies, have demonstrated significant\ncapabilities. Yet their advancement is constrained by the high cost of\nacquiring large-scale interaction datasets. This work introduces an alternative\nparadigm for enhancing policy performance without additional model training.\nPerhaps surprisingly, we demonstrate that the composed policies can exceed the\nperformance of either parent policy. Our contribution is threefold. First, we\nestablish a theoretical foundation showing that theconvex compositionofdistributional scoresfrom multiple diffusion models can yield a superior\none-step functional objective compared to any individual score. AGr\\\"onwall-type boundis then used to show that this single-step improvement\npropagates through entire generation trajectories, leading to systemic\nperformance gains. Second, motivated by these results, we propose General\nPolicy Composition (GPC), a training-free method that enhances performance by\ncombining thedistributional scoresof multiplepre-trained policiesvia a\nconvex combination and test-time search.GPCis versatile, allowing for the\nplug-and-play composition of heterogeneous policies, including VA and VLA\nmodels, as well as those based on diffusion or flow-matching, irrespective of\ntheir input visual modalities. Third, we provide extensive empirical\nvalidation. Experiments onRobomimic,PushT, andRoboTwinbenchmarks, alongsidereal-world robotic evaluations, confirm thatGPCconsistently improves\nperformance and adaptability across a diverse set of tasks. Further analysis of\nalternative composition operators and weighting strategies offers insights into\nthe mechanisms underlying the success ofGPC. These results establishGPCas a\nsimple yet effective method for improving control performance by leveraging\nexisting policies. Diffusion-based models for robotic control, including vision-language-action (VLA) and vision-action (VA) policies, have demonstrated significant capabilities. Yet their advancement is constrained by the high cost of acquiring large-scale interaction datasets. This work introduces an alternative paradigm for enhancing policy performance without additional model training. Perhaps surprisingly, we demonstrate that the composed policies can exceed the performance of either parent policy. Our contribution is threefold. First, we establish a theoretical foundation showing that the convex composition of distributional scores from multiple diffusion models can yield a superior one-step functional objective compared to any individual score. A Grönwall-type bound is then used to show that this single-step improvement propagates through entire generation trajectories, leading to systemic performance gains. Second, motivated by these results, we propose General Policy Composition (GPC), a training-free method that enhances performance by combining the distributional scores of multiple pre-trained policies via a convex combination and test-time search. GPC is versatile, allowing for the plug-and-play composition of heterogeneous policies, including VA and VLA models, as well as those based on diffusion or flow-matching, irrespective of their input visual modalities. Third, we provide extensive empirical validation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside real-world robotic evaluations, confirm that GPC consistently improves performance and adaptability across a diverse set of tasks. Further analysis of alternative composition operators and weighting strategies offers insights into the mechanisms underlying the success of GPC. These results establish GPC as a simple yet effective method for improving control performance by leveraging existing policies. Our Project Page is athttps://sagecao1125.github.io/GPC-Site/. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541067",
    "title": "Compose Your Policies! Improving Diffusion-based or Flow-based Robot\n  Policies via Test-time Distribution-level Composition",
    "authors": [
      "Jiahang Cao",
      "Andrew F. Luo"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/SageCao1125/GPC",
    "huggingface_url": "https://huggingface.co/papers/2510.01068",
    "upvote": 19
  }
}