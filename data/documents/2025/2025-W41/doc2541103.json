{
  "context": "SRGen, a lightweight test-time framework, improves LLM reasoning by dynamically identifying and correcting high-uncertainty tokens during generation, leading to better single-pass quality and self-consistency. Large language models (LLMs) increasingly solve complex reasoning tasks via\nlong chain-of-thought, but their forward-only autoregressive generation process\nis fragile; early token errors can cascade, which creates a clear need for\nself-reflection mechanisms. However, existing self-reflection either performs\nrevisions over full drafts or learns self-correction via expensive training,\nboth fundamentally reactive and inefficient. To address this, we proposeSelf-Reflective Generationat Test Time (SRGen), a lightweight test-time\nframework that reflects before generating at uncertain points. During token\ngeneration,SRGenutilizesdynamic entropy thresholdingto identify\nhigh-uncertainty tokens. For each identified token, it trains a specificcorrective vector, which fully exploits the already generated context for aself-reflective generationto correct thetoken probability distribution. By\nretrospectively analyzing the partial output, this self-reflection enables more\ntrustworthy decisions, thereby significantly reducing the probability of errors\nat highly uncertain points. Evaluated on challenging mathematical reasoning\nbenchmarks and a diverse set of LLMs,SRGencan consistently strengthen model\nreasoning: improvements in single-pass quality also translate into strongerself-consistency voting. Especially, onAIME2024withDeepSeek-R1-Distill-Qwen-7B,SRGenyields absolute improvements of +12.0% onPass@1and +13.3% onCons@5. Moreover, our findings positionSRGenas a\nplug-and-play method that integrates reflection into the generation process for\nreliable LLM reasoning, achieving consistent gains with bounded overhead and\nbroad composability with other training-time (e.g.,RLHF) and test-time (e.g.,SLOT) techniques. SRGen brings reflection into generation at test time by detecting high-uncertainty tokens, learning tiny per-token corrective vectors from the partial output, and continuing with a corrected distribution, which reduces error cascades and strengthens single-pass as well as self-consistency reasoning; on AIME2024 with DeepSeek-R1-Distill-Qwen-7B it delivers +12.0% Pass@1 and +13.3% Cons@5, with bounded overhead and clean compatibility with training-time and test-time techniques. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541103",
    "title": "Self-Reflective Generation at Test Time",
    "authors": [
      "Jian Mu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/2020-qqtcg/SRGen",
    "huggingface_url": "https://huggingface.co/papers/2510.02919",
    "upvote": 9
  }
}