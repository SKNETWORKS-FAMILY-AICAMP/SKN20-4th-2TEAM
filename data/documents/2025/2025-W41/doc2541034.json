{
  "context": "ARTDECO combines feed-forward models and SLAM pipelines for efficient and accurate 3D reconstruction from monocular images. On-the-fly3D reconstructionfrommonocular image sequencesis a\nlong-standing challenge in computer vision, critical for applications such asreal-to-sim,AR/VR, androbotics. Existing methods face a major tradeoff:per-scene optimizationyields high fidelity but is computationally expensive,\nwhereasfeed-forward foundation modelsenable real-time inference but struggle\nwith accuracy and robustness. In this work, we propose ARTDECO, a unified\nframework that combines the efficiency of feed-forward models with the\nreliability ofSLAM-based pipelines. ARTDECO uses3D foundation modelsfor pose\nestimation andpoint prediction, coupled with aGaussian decoderthat\ntransformsmulti-scale featuresintostructured 3D Gaussians. To sustain both\nfidelity and efficiency at scale, we design a hierarchical Gaussian\nrepresentation with aLoD-aware rendering strategy, which improves rendering\nfidelity while reducingredundancy. Experiments on eight diverse indoor and\noutdoor benchmarks show that ARTDECO deliversinteractive performancecomparable to SLAM, robustness similar to feed-forward systems, andreconstruction qualityclose toper-scene optimization, providing a practical\npath toward on-the-fly digitization of real-world environments with both\naccurate geometry and high visual fidelity. Explore more demos on our project\npage: https://city-super.github.io/artdeco/. On-the-fly 3D reconstruction from monocular image sequences is a long-standing challenge in computer vision, critical for applications such as real-to-sim, AR/VR, and robotics. Existing methods face a major tradeoff: per-scene optimization yields high fidelity but is computationally expensive, whereas feed-forward foundation models enable real-time inference but struggle with accuracy and robustness. In this work, we propose ARTDECO, a unified framework that combines the efficiency of feed-forward models with the reliability of SLAM-based pipelines. ARTDECO uses 3D foundation models for pose estimation and point prediction, coupled with a Gaussian decoder that transforms multi-scale features into structured 3D Gaussians. To sustain both fidelity and efficiency at scale, we design a hierarchical Gaussian representation with a LoD-aware rendering strategy, which improves rendering fidelity while reducing redundancy. Experiments on eight diverse indoor and outdoor benchmarks show that ARTDECO delivers interactive performance comparable to SLAM, robustness similar to feed-forward systems, and reconstruction quality close to per-scene optimization, providing a practical path toward on-the-fly digitization of real-world environments with both accurate geometry and high visual fidelity. Explore more demos on our project page:https://city-super.github.io/artdeco/. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541034",
    "title": "ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D\n  Reconstruction with Structured Scene Representation",
    "authors": [
      "Kerui Ren"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/InternRobotics/ARTDECO",
    "huggingface_url": "https://huggingface.co/papers/2510.08551",
    "upvote": 33
  }
}