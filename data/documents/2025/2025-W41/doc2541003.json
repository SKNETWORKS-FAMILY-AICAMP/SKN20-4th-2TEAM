{
  "context": "ACE, a framework for adaptive context engineering, enhances LLM applications by preserving detailed knowledge through structured updates, outperforming baselines in agent and domain-specific tasks with reduced adaptation costs. Large language model(LLM) applications such as agents and domain-specific\nreasoning increasingly rely oncontext adaptation-- modifying inputs with\ninstructions, strategies, or evidence, rather than weight updates. Prior\napproaches improve usability but often suffer from brevity bias, which drops\ndomain insights for concise summaries, and fromcontext collapse, where\niterative rewriting erodes details over time. Building on the adaptive memory\nintroduced byDynamic Cheatsheet, we introduceACE(Agentic Context\nEngineering), a framework that treats contexts as evolving playbooks that\naccumulate, refine, and organize strategies through a modular process ofgeneration,reflection, andcuration.ACEprevents collapse with structured,\nincremental updates that preserve detailed knowledge and scale with\nlong-context models. Across agent and domain-specific benchmarks,ACEoptimizes\ncontexts both offline (e.g., system prompts) and online (e.g., agent memory),\nconsistently outperforming strong baselines: +10.6% on agents and +8.6% on\nfinance, while significantly reducingadaptation latencyandrollout cost.\nNotably,ACEcould adapt effectively without labeled supervision and instead by\nleveragingnatural execution feedback. On theAppWorld leaderboard,ACEmatches\nthe top-ranked production-level agent on the overall average and surpasses it\non the harder test-challenge split, despite using a smaller open-source model.\nThese results show that comprehensive, evolving contexts enable scalable,\nefficient, and self-improving LLM systems with low overhead. Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on context adaptation -- modifying inputs with instructions, strategies, or evidence, rather than weight updates. Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for concise summaries, and from context collapse, where iterative rewriting erodes details over time. Building on the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context Engineering), a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies through a modular process of generation, reflection, and curation. ACE prevents collapse with structured, incremental updates that preserve detailed knowledge and scale with long-context models. Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost. Notably, ACE could adapt effectively without labeled supervision and instead by leveraging natural execution feedback. On the AppWorld leaderboard, ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder test-challenge split, despite using a smaller open-source model. These results show that comprehensive, evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Thanks for including the prompts for the Generator and Reflector code. I can see how breaking up the refinement into separate steps is super helpful. I'm thinking that this could easily be modified to look at evals from MCP servers as well. arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/agentic-context-engineering-evolving-contexts-for-self-improving-language-models This is the first author of the paper. Thanks a lot for everyone's interest. The ACE code is available here:https://github.com/ace-agent/ace. Use this if you want to develop your own application with ACE, or if you want to reproduce the Finance experiment results in the paper. The ACE + AppWorld code is available here:https://github.com/ace-agent/ace-appworld. Use this if you want to reproduce the AppWorld agent experiment results in the paper. We will update the arxiv version soon to include the code links and more experiment details. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541003",
    "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving\n  Language Models",
    "authors": [
      "Qizheng Zhang",
      "Fenglu Hong",
      "Mengmeng Ji"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/ace-agent/ace",
    "huggingface_url": "https://huggingface.co/papers/2510.04618",
    "upvote": 127
  }
}