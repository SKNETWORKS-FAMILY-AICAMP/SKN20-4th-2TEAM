{
  "context": "The Game-Time Benchmark evaluates the temporal dynamics and real-time interaction capabilities of conversational spoken language models, highlighting performance gaps in instruction-following and synchronized responses. Conversational Spoken Language Models(SLMs) are emerging as a promising\nparadigm for real-time speech interaction. However, their capacity oftemporal\ndynamics, including the ability to managetiming,tempoand simultaneous\nspeaking, remains a critical and unevaluated challenge for conversational\nfluency. To address this gap, we introduce theGame-Time Benchmark, a framework\nto systematically assess thesetemporal capabilities. Inspired by how humans\nlearn a language through language activities, Game-Time consists of basicinstruction-following tasksand advanced tasks withtemporal constraints, such\nastempo adherenceandsynchronized responses. Our evaluation of diverse SLM\narchitectures reveals a clear performance disparity: while state-of-the-art\nmodels handle basic tasks well, many contemporary systems still struggle with\nfundamental instruction-following. More critically, nearly all models degrade\nsubstantially undertemporal constraints, exposing persistent weaknesses intime awarenessandfull-duplex interaction. TheGame-Time Benchmarkprovides a\nfoundation for guiding future research toward moretemporally-aware\nconversational AI. Demos and datasets are available on our project website\nhttps://ga642381.github.io/Game-Time. Conversational Spoken Language Models (SLMs) are emerging as a promising paradigm for real-time speech interaction. However, their capacity of temporal dynamics, including the ability to manage timing, tempo and simultaneous speaking, remains a critical and unevaluated challenge for conversational fluency. To address this gap, we introduce the Game-Time Benchmark, a framework to systematically assess these temporal capabilities. Inspired by how humans learn a language through language activities, Game-Time consists of basic instruction-following tasks and advanced tasks with temporal constraints, such as tempo adherence and synchronized responses. Our evaluation of diverse SLM architectures reveals a clear performance disparity: while state-of-the-art models handle basic tasks well, many contemporary systems still struggle with fundamental instruction-following. More critically, nearly all models degrade substantially under temporal constraints, exposing persistent weaknesses in time awareness and full-duplex interaction. The Game-Time Benchmark provides a foundation for guiding future research toward more temporally-aware conversational AI. Demos and datasets are available on our project websitehttps://ga642381.github.io/Game-Time. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541047",
    "title": "Game-Time: Evaluating Temporal Dynamics in Spoken Language Models",
    "authors": [
      "Kai-Wei Chang",
      "En-Pei Hu",
      "Wei-Chih Chen"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2509.26388",
    "upvote": 26
  }
}