{
  "context": "OBS-Diff is a novel one-shot pruning framework that compresses large-scale text-to-image diffusion models with minimal quality loss and significant inference acceleration. Large-scale text-to-imagediffusion models, while powerful, suffer from\nprohibitive computational cost. Existing one-shot network pruning methods can\nhardly be directly applied to them due to the iterative denoising nature ofdiffusion models. To bridge the gap, this paper presentsOBS-Diff, a novelone-shot pruningframework that enables accurate and training-free compression\nof large-scale text-to-imagediffusion models. Specifically, (i)OBS-Diffrevitalizes the classicOptimal Brain Surgeon(OBS), adapting it to the complex\narchitectures of moderndiffusion modelsand supporting diverse pruning\ngranularity, includingunstructured,N:M semi-structured, andstructured(MHA\nheads andFFN neurons) sparsity; (ii) To align the pruning criteria with the\niterative dynamics of the diffusion process, by examining the problem from an\nerror-accumulation perspective, we propose a noveltimestep-aware Hessianconstruction that incorporates alogarithmic-decrease weighting scheme,\nassigning greater importance to earlier timesteps to mitigate potential error\naccumulation; (iii) Furthermore, a computationally efficient group-wise\nsequential pruning strategy is proposed to amortize the expensive calibration\nprocess. Extensive experiments show thatOBS-Diffachieves state-of-the-artone-shot pruningfordiffusion models, delivering inference acceleration with\nminimal degradation in visual quality. Large-scale text-to-image diffusion models, while powerful, suffer from prohibitive computational cost. Existing one-shot network pruning methods can hardly be directly applied to them due to the iterative denoising nature of diffusion models. To bridge the gap, this paper presents OBS-Diff, a novel one-shot pruning framework that enables accurate and training-free compression of large-scale text-to-image diffusion models. Specifically, (i) OBS-Diff revitalizes the classic Optimal Brain Surgeon (OBS), adapting it to the complex architectures of modern diffusion models and supporting diverse pruning granularity, including unstructured, N:M semi-structured, and structured (MHA heads and FFN neurons) sparsity; (ii) To align the pruning criteria with the iterative dynamics of the diffusion process, by examining the problem from an error-accumulation perspective, we propose a novel timestep-aware Hessian construction that incorporates a logarithmic-decrease weighting scheme, assigning greater importance to earlier timesteps to mitigate potential error accumulation; (iii) Furthermore, a computationally efficient group-wise sequential pruning strategy is proposed to amortize the expensive calibration process. Extensive experiments show that OBS-Diff achieves state-of-the-art one-shot pruning for diffusion models, delivering inference acceleration with minimal degradation in visual quality. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2541058",
    "title": "OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot",
    "authors": [
      "Junhan Zhu",
      "Huan Wang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Alrightlone/OBS-Diff",
    "huggingface_url": "https://huggingface.co/papers/2510.06751",
    "upvote": 21
  }
}