{
  "context": "FaraGen creates synthetic datasets for computer use agents, enabling the training of efficient and high-performing models like Fara-7B on diverse web tasks, outperforming larger models on benchmarks. Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists forCUA trajectories. To address these gaps, we introduceFaraGen, a novelsynthetic data generationsystem formulti-step web tasks.FaraGencan propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multipleverifiers. It achieves high throughput, yield, and diversity formulti-step web tasks, producing verified trajectories at approximately $1 each. We use this data to trainFara-7B, anative CUA modelthat perceives the computer using onlyscreenshots, executes actions viapredicted coordinates, and is small enough to run on-device. We find thatFara-7Boutperforms other CUA models of comparable size on benchmarks likeWebVoyager,Online-Mind2Web, andWebTailBench-- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore,Fara-7Bis competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are makingFara-7Bopen-weight on Microsoft Foundry and HuggingFace, and we are releasingWebTailBench. Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548053",
    "title": "Fara-7B: An Efficient Agentic Model for Computer Use",
    "authors": [
      "Hussein Mozannar",
      "Akshay Nambi"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/microsoft/fara",
    "huggingface_url": "https://huggingface.co/papers/2511.19663",
    "upvote": 13
  }
}