{
  "context": "HunyuanVideo 1.5 is a lightweight video generation model with state-of-the-art visual quality and motion coherence, using a DiT architecture with SSTA and an efficient video super-resolution network. We present HunyuanVideo 1.5, a lightweight yet powerful open-source video generation model that achieves state-of-the-art visual quality and motion coherence with only 8.3 billion parameters, enabling efficient inference on consumer-grade GPUs. This achievement is built upon several key components, including meticulous data curation, an advancedDiT architecturefeaturingselective and sliding tile attention(SSTA), enhanced bilingual understanding throughglyph-aware text encoding,progressive pre-trainingandpost-training, and an efficientvideo super-resolution network. Leveraging these designs, we developed a unified framework capable of high-qualitytext-to-videoandimage-to-videogeneration across multiple durations and resolutions.Extensive experiments demonstrate that this compact and proficient model establishes a new state-of-the-art among open-source video generation models. By releasing the code and model weights, we provide the community with a high-performance foundation that lowers the barrier to video creation and research, making advanced video generation accessible to a broader audience. All open-source assets are publicly available at https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5. We present HunyuanVideo 1.5, a lightweight yet powerful open-source video generation model that achieves state-of-the-art visual quality and motion coherence with only 8.3 billion parameters, enabling efficient inference on consumer-grade GPUs. This achievement is built upon several key components, including meticulous data curation, an advanced DiT architecture featuring selective and sliding tile attention (SSTA), enhanced bilingual understanding through glyph-aware text encoding, progressive pre-training and post-training, and an efficient video super-resolution network. Leveraging these designs, we developed a unified framework capable of high-quality text-to-video and image-to-video generation across multiple durations and resolutions.Extensive experiments demonstrate that this compact and proficient model establishes a new state-of-the-art among open-source video generation models. By releasing the code and model weights, we provide the community with a high-performance foundation that lowers the barrier to video creation and research, making advanced video generation accessible to a broader audience. All open-source assets are publicly available athttps://github.com/Tencent-Hunyuan/HunyuanVideo-1.5. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548033",
    "title": "HunyuanVideo 1.5 Technical Report",
    "authors": [
      "Jiangfeng Xiong",
      "Peizhen Zhang",
      "Weijie Kong"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5",
    "huggingface_url": "https://huggingface.co/papers/2511.18870",
    "upvote": 24
  }
}