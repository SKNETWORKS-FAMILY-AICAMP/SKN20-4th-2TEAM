{
  "context": "OpenMMReasoner, a two-stage training approach combining supervised fine-tuning and reinforcement learning, enhances multimodal reasoning performance through rigorous data curation and improved training strategies. Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe formultimodal reasoningspanningsupervised fine-tuning(SFT) andreinforcement learning(RL). In the SFT stage, we construct an 874K-samplecold-start datasetwith rigorousstep-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shapingmultimodal reasoningperformance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across ninemultimodal reasoning benchmarks, establishing a solid empirical foundation for futurelarge-scale multimodal reasoningresearch. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner. Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduceOpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. Models :https://huggingface.co/OpenMMReasoner/OpenMMReasoner-RLCollection :https://huggingface.co/collections/lmms-lab/openmmreasonerPaper :https://arxiv.org/abs/2511.16334Project Page :https://evolvinglmms-lab.github.io/OpenMMReasoner/Github :https://github.com/EvolvingLMMs-Lab/OpenMMReasonerBlog :https://www.lmms-lab.com/posts/openmmreasoner/ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv explained breakdown of this paper ðŸ‘‰https://arxivexplained.com/papers/openmmreasoner-pushing-the-frontiers-for-multimodal-reasoning-with-an-open-and-general-recipe Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548006",
    "title": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe",
    "authors": [
      "Kaichen Zhang",
      "Keming Wu",
      "Zuhao Yang",
      "Lidong Bing"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/EvolvingLMMs-Lab/OpenMMReasoner",
    "huggingface_url": "https://huggingface.co/papers/2511.16334",
    "upvote": 92
  }
}