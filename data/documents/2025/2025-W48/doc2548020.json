{
  "context": "UltraFlux, a Flux-based DiT trained on a 4K dataset, addresses failures in diffusion transformers at 4K resolution through enhanced positional encoding, improved VAE compression, gradient rebalancing, and aesthetic curriculum learning, achieving superior performance compared to existing models. Diffusion transformershave recently delivered strongtext-to-image generationaround 1K resolution, but we show that extending them to native 4K across diverse aspect ratios exposes a tightly coupled failure mode spanningpositional encoding,VAE compression, and optimization. Tackling any of these factors in isolation leaves substantial quality on the table. We therefore take a data-model co-design view and introduce UltraFlux, a Flux-based DiT trained natively at 4K on MultiAspect-4K-1M, a 1M-image 4K corpus with controlled multi-AR coverage, bilingual captions, and rich VLM/IQA metadata for resolution- and AR-aware sampling. On the model side, UltraFlux couples (i)Resonance 2D RoPEwithYaRNfor training-window-, frequency-, and AR-awarepositional encodingat 4K; (ii) a simple, non-adversarialVAE post-trainingscheme that improves 4K reconstruction fidelity; (iii) anSNR-Aware Huber Waveletobjective that rebalances gradients across timesteps and frequency bands; and (iv) aStage-wise Aesthetic Curriculum Learningstrategy that concentrates high-aesthetic supervision on high-noise steps governed by the model prior. Together, these components yield a stable, detail-preserving 4K DiT that generalizes across wide, square, and tall ARs. On theAesthetic-Evalat 4096 benchmark and multi-AR 4K settings, UltraFlux consistently outperforms strong open-source baselines across fidelity, aesthetic, and alignment metrics, and-with a LLM prompt refiner-matches or surpasses the proprietarySeedream 4.0. TL;DR: UltraFlux couples a rigorously curated 1M 4K Image dataset with a native 4K generative model, delivering sharper detail and stronger text–image consistency than existing open alternatives.  UltraFlux is our latest effort toward high-fidelity, native 4K image synthesis. Rather than scaling resolution in isolation, we approach 4K generation as acoupled system problem, where data quality, spatial representation, reconstruction fidelity, and optimization dynamics must be designed together. Current high-resolution pipelines often improve one component at the expense of another — sharper details but unstable layouts, or stronger global structure but loss of fine texture. UltraFlux avoids this trade-off by jointly engineering the data distribution and the generative process, enabling stable behavior across wide, square, and tall aspect ratios while preserving delicate structures that typically vanish at 4K. At the data level, we construct a large, clean, and distribution-balanced 4K corpus with broad aspect-ratio coverage, stronger aesthetic supervision, and bilingual captions. This gives the model direct exposure to the patterns that matter most for 4K realism: rich textures and consistent human-centric scenes—categories underrepresented in existing public sources. On the model side, UltraFlux reinforces stable spatial reasoning at large scales, improves reconstruction of high-frequency regions without sacrificing efficiency, and rebalances the training objective so that fine-detail preservation and global composition are learned in a coordinated way. A structured two-stage training schedule further sharpens aesthetic and semantic consistency where the generative prior matters most. Together, these components produce a system that offers: UltraFlux represents a step toward principled, practical native 4K generation — not by adding more compute, but by treating high-resolution synthesis as an integrated design problem. Project:https://w2genai-lab.github.io/UltraFlux/HF Model:https://huggingface.co/Owen777/UltraFlux-v1Inf Code and Dataset (coming soon):https://github.com/W2GenAI-Lab/UltraFlux This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548020",
    "title": "UltraFlux: Data-Model Co-Design for High-quality Native 4K Text-to-Image Generation across Diverse Aspect Ratios",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/W2GenAI-Lab/UltraFlux",
    "huggingface_url": "https://huggingface.co/papers/2511.18050",
    "upvote": 37
  }
}