{
  "context": "GigaWorld-0 is a unified world model framework that integrates video generation and 3D modeling to produce high-quality, diverse, and physically plausible VLA data, enabling strong real-world performance in embodied AI without real-world training. World models are emerging as a foundational paradigm for scalable, data-efficient embodied AI. In this work, we presentGigaWorld-0, a unified world model framework designed explicitly as a data engine for Vision-Language-Action (VLA) learning.GigaWorld-0integrates two synergistic components:GigaWorld-0-Video, which leverages large-scale video generation to produce diverse, texture-rich, and temporally coherent embodied sequences under fine-grained control of appearance, camera viewpoint, and action semantics; andGigaWorld-0-3D, which combines3D generative modeling,3D Gaussian Splattingreconstruction,physically differentiable system identification, andexecutable motion planningto ensure geometric consistency and physical realism. Their joint optimization enables the scalable synthesis ofembodied interaction datathat is visually compelling, spatially coherent, physically plausible, and instruction-aligned. Training at scale is made feasible through our efficientGigaTrainframework, which exploitsFP8-precisionandsparse attentionto drastically reduce memory and compute requirements. We conduct comprehensive evaluations showing thatGigaWorld-0generates high-quality, diverse, and controllable data across multiple dimensions. Critically,VLA model(e.g.,GigaBrain-0) trained onGigaWorld-0-generated data achieve strongreal-world performance, significantly improving generalization andtask successon physical robots without any real-world interaction during training. World models are emerging as a foundational paradigm for scalable, data-efficient embodied AI. In this work, we present GigaWorld-0, a unified world model framework designed explicitly as a data engine for Vision-Language-Action (VLA) learning. GigaWorld-0 integrates two synergistic components: GigaWorld-0-Video, which leverages large-scale video generation to produce diverse, texture-rich, and temporally coherent embodied sequences under fine-grained control of appearance, camera viewpoint, and action semantics; and GigaWorld-0-3D, which combines 3D generative modeling, 3D Gaussian Splatting reconstruction, physically differentiable system identification, and executable motion planning to ensure geometric consistency and physical realism. Their joint optimization enables the scalable synthesis of embodied interaction data that is visually compelling, spatially coherent, physically plausible, and instruction-aligned. Training at scale is made feasible through our efficient GigaTrain framework, which exploits FP8-precision and sparse attention to drastically reduce memory and compute requirements. We conduct comprehensive evaluations showing that GigaWorld-0 generates high-quality, diverse, and controllable data across multiple dimensions. Critically, VLA model (e.g., GigaBrain-0) trained on GigaWorld-0-generated data achieve strong real-world performance, significantly improving generalization and task success on physical robots without any real-world interaction during training. project page:https://giga-world-0.github.io/ This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend project page 404 https://giga-world-0.github.io/ Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548026",
    "title": "GigaWorld-0: World Models as Data Engine to Empower Embodied AI",
    "authors": [
      "Xiaofeng Wang",
      "Yang Wang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/open-gigaai/giga-world-0",
    "huggingface_url": "https://huggingface.co/papers/2511.19861",
    "upvote": 30
  }
}