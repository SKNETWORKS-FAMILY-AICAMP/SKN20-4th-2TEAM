{
  "context": "One4D is a unified framework for 4D generation and reconstruction that uses a novel decoupled approach to produce high-quality RGB frames and pointmaps from varying sparsities of input frames. We present One4D, a unified framework for 4D generation and reconstruction that produces dynamic 4D content as synchronized RGB frames and pointmaps. By consistently handling varying sparsities of conditioning frames through aUnified Masked Conditioning (UMC)mechanism, One4D can seamlessly transition between 4D generation from a single image, 4D reconstruction from a full video, and mixed generation and reconstruction from sparse frames. Our framework adapts a powerfulvideo generation modelforjoint RGB and pointmap generation, with carefully designed network architectures. The commonly useddiffusion finetuningstrategies for depthmap or pointmap reconstruction often fail onjoint RGB and pointmap generation, quickly degrading the base video model. To address this challenge, we introduceDecoupled LoRA Control (DLC), which employs two modality-specificLoRA adaptersto form decoupled computation branches for RGB frames and pointmaps, connected by lightweight, zero-initialized control links that gradually learn mutualpixel-level consistency. Trained on a mixture of synthetic and real4D datasetsunder modest computational budgets, One4D produces high-quality RGB frames and accurate pointmaps across both generation and reconstruction tasks. This work represents a step toward general, high-quality geometry-based 4D world modeling using video diffusion models. Project page: https://mizhenxing.github.io/One4D We present One4D, a unified framework for 4D generation and reconstruction that produces dynamic 4D content as synchronized RGB frames and pointmaps. By consistently handling varying sparsities of conditioning frames through a Unified Masked Conditioning (UMC) mechanism, One4D can seamlessly transition between 4D generation from a single image, 4D reconstruction from a full video, and mixed generation and reconstruction from sparse frames. Our framework adapts a powerful video generation model for joint RGB and pointmap generation, with carefully designed network architectures. The commonly used diffusion finetuning strategies for depthmap or pointmap reconstruction often fail on joint RGB and pointmap generation, quickly degrading the base video model. To address this challenge, we introduce Decoupled LoRA Control (DLC), which employs two modality-specific LoRA adapters to form decoupled computation branches for RGB frames and pointmaps, connected by lightweight, zero-initialized control links that gradually learn mutual pixel-level consistency. Trained on a mixture of synthetic and real 4D datasets under modest computational budgets, One4D produces high-quality RGB frames and accurate pointmaps across both generation and reconstruction tasks. This work represents a step toward general, high-quality geometry-based 4D world modeling using video diffusion models. Project page:https://mizhenxing.github.io/One4D This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548060",
    "title": "One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control",
    "authors": [
      "Zhenxing Mi",
      "Yuxin Wang",
      "Dan Xu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/MiZhenxing/One4D",
    "huggingface_url": "https://huggingface.co/papers/2511.18922",
    "upvote": 11
  }
}