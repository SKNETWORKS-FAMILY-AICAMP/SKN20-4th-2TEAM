{
  "context": "AutoEnv and AutoEnv-36 provide a standardized framework and dataset for evaluating cross-environment learning in agents, highlighting the challenges and limitations of existing learning methods. Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable,heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we proposeAutoEnv, an automated framework that treats environments asfactorizable distributionsover transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. UsingAutoEnv, we constructAutoEnv-36, a dataset of 36 environments with 358 validated levels, on which sevenlanguage modelsachieve 12-49%normalized reward, demonstrating the challenge ofAutoEnv-36. Second, we formalize agent learning as acomponent-centric processdriven by three stages ofSelection,Optimization, andEvaluationapplied to an improvable agent component. Using this formulation, we design eightlearning methodsand evaluate them onAutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixedlearning methodsdo not scale acrossheterogeneous environments.Environment-adaptive selectionoflearning methodssubstantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and positionAutoEnvandAutoEnv-36as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv. AUTOENV: Automated Environments for Measuring Cross-Environment Agent LearningThis paper tackles a gap in current agentic learning work: most ‚Äúself-improving‚Äù agents are evaluated in a single domain, so we don‚Äôt really know how well they learn across environments with very different dynamics, observations, and rewards. The authors introduce AUTOENV, a framework that uses LLM-driven code generation plus self-repair to automatically build RL-style environments in three abstraction layers (BaseEnv / ObsEnv / SkinEnv). From 100 themes they obtain AUTOENV-36, a curated set of 36 heterogeneous environments (binary vs accumulative reward, full vs partial observation, aligned vs inverse semantics) where strong LLM agents still only reach 12‚Äì49% normalized reward, making it a challenging and discriminative benchmark. On top of this, they propose a component-centric formulation of agent learning as Selection‚ÄìOptimization‚ÄìEvaluation over improvable components like prompts and agent code, instantiate 8 concrete learning methods, and define a ‚Äúlearning upper bound‚Äù that picks the best method per environment. Experiments show that any single fixed learning strategy quickly breaks down as environment diversity grows, while simple environment-adaptive selection recovers part of the upper bound but still leaves a sizeable gap. The work argues that future progress in agentic learning will require automated design and selection of learning strategies themselves, not just better prompts or models. arXiv explained breakdown of this paper üëâhttps://arxivexplained.com/papers/autoenv-automated-environments-for-measuring-cross-environment-agent-learning This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ¬∑Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548007",
    "title": "AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning",
    "authors": [
      "Jiayi Zhang",
      "Fanqi Kong",
      "Yang Cheng",
      "Jinyu Xiang",
      "Jianhao Ruan",
      "HongZhang Liu"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/FoundationAgents/AutoEnv",
    "huggingface_url": "https://huggingface.co/papers/2511.19304",
    "upvote": 90
  }
}