{
  "context": "Block Cascading parallelizes video block generation, achieving significant speed improvements without compromising quality. Block-causal video generationfaces a stark speed-quality trade-off: small 1.3B models manage only 16 FPS while large 14B models crawl at 4.5 FPS, forcing users to choose between responsiveness and quality. Block Cascading significantly mitigates this trade-off through training-freeparallelization. Our key insight: future video blocks do not need fullydenoised current blocksto begin generation. By starting block generation with partially denoised context from predecessors, we transformsequential pipelinesintoparallel cascadeswhere multiple blocks denoise simultaneously. With 5 GPUs exploitingtemporal parallelism, we achieve ~2x acceleration across all model scales: 1.3B models accelerate from 16 to 30 FPS, 14B models from 4.5 to 12.5 FPS. Beyond inference speed, Block Cascading eliminates overhead fromKV-recaching(of ~200ms) duringcontext switchesforinteractive generation. Extensive evaluations validated against multiple block-causal pipelines demonstrate no significant loss in generation quality when switching from block-causal to Block Cascading pipelines for inference. Project Page: https://hmrishavbandy.github.io/block_cascading_page/ Block-causal video generation faces a stark speed-quality trade-off: small 1.3B models manage only 16 FPS while large 14B models crawl at 4.5 FPS, forcing users to choose between responsiveness and quality. Block Cascading significantly mitigates this trade-off through training-free parallelization. Our key insight: future video blocks do not need fully denoised current blocks to begin generation. By starting block generation with partially denoised context from predecessors, we transform sequential pipelines into parallel cascades where multiple blocks denoise simultaneously. With 5 GPUs exploiting temporal parallelism, we achieve ~2x acceleration across all model scales: 1.3B models accelerate from 16 to 30 FPS, 14B models from 4.5 to 12.5 FPS. Beyond inference speed, Block Cascading eliminates overhead from KV-recaching (of ~200ms) during context switches for interactive generation. Extensive evaluations validated against multiple block-causal pipelines demonstrate no significant loss in generation quality when switching from block-causal to Block Cascading pipelines for inference. Project page:https://hmrishavbandy.github.io/block_cascading_page/ In this work, you achieved a 2× speedup using 5 GPUs. What about Unified Sequence Parallelism? It usually yields near-linear speedup with the number of GPUs in non-causal scenarios. Have you tried its effect in the causal case? This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2548066",
    "title": "Block Cascading: Training Free Acceleration of Block-Causal Video Models",
    "authors": [
      "Hmrishav Bandyopadhyay"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.20426",
    "upvote": 9
  }
}