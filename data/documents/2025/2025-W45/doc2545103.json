{
  "context": "A discriminative approach to depth and ego-motion estimation leverages geometric constraints to improve performance and robustness in 3D perception tasks. Unsupervised learningofdepthandego-motion, two fundamental3D perceptiontasks, has made significant strides in recent years. However, most methods\ntreatego-motionas an auxiliary task, either mixing all motion types or\nexcludingdepth-independent rotational motions in supervision. Such designs\nlimit the incorporation of stronggeometric constraints, reducing reliability\nand robustness under diverse conditions. This study introduces a discriminative\ntreatment of motion components, leveraging the geometric regularities of their\nrespective rigid flows to benefit bothdepthandego-motionestimation. Given\nconsecutive video frames, network outputs first align theoptical axesandimaging planesof the source and target cameras.Optical flowsbetween frames\nare transformed through these alignments, and deviations are quantified to\nimposegeometric constraintsindividually on eachego-motioncomponent,\nenabling more targeted refinement. These alignments further reformulate the\njoint learning process intocoaxialandcoplanarforms, wheredepthand each\ntranslation component can be mutually derived through closed-form geometric\nrelationships, introducing complementary constraints that improvedepthrobustness.DiMoDE, a generaldepthandego-motionjoint learning framework\nincorporating these designs, achieves state-of-the-art performance on multiple\npublic datasets and a newly collected diverse real-world dataset, particularly\nunder challenging conditions. Our source code will be publicly available at\nmias.group/DiMoDEupon publication. Based on the core idea of discriminately treating motion components, we introduce optical axis and imaging plane alignment processes to the joint depth and ego-motion learning. This design establishes strong geometric constraints from motion components that enhance the robustness of both depth and ego-motion learning across diverse and adverse conditions. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545103",
    "title": "Discriminately Treating Motion Components Evolves Joint Depth and\n  Ego-Motion Learning",
    "authors": [],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.01502",
    "upvote": 1
  }
}