{
  "context": "Vote-in-Context (ViC) is a training-free framework that leverages Vision-Language Models (VLMs) for zero-shot reranking and fusion in cross-modal video retrieval, achieving state-of-the-art performance. In the retrieval domain, candidates'fusionfrom heterogeneous retrievers is\na long-standing challenge, particularly for complex, multi-modal data such as\nvideos. While typicalfusiontechniques are training-free, they rely solely on\nrank or score signals, disregarding candidates' representations. This work\nintroducesVote-in-Context(ViC), a generalized, training-free framework that\nre-thinkslist-wise rerankingandfusionas azero-shot reasoningtask for aVision-Language Model(VLM). The core insight is to serialize both content\nevidence and retriever metadata directly within theVLM's prompt, allowing the\nmodel to adaptively weigh retriever consensus against visual-linguistic\ncontent. We demonstrate the generality of this framework by applying it to the\nchallenging domain of cross-modal video retrieval. To this end, we introduce\ntheS-Grid, a compact serialization map that represents each video as an image\ngrid, optionally paired withsubtitlesto enablelist-wise reasoningover video\ncandidates.ViCis evaluated both as a single-list reranker, where it\ndramatically improves the precision of individual retrievers, and as anensemble fuser, where it consistently outperforms strong baselines likeCombSUM. Across video retrieval benchmarks includingActivityNetandVATEX, the\nframework establishes new state-of-the-artzero-shot retrievalperformance,\ndemonstrating its effectiveness in handling complex visual and temporal signals\nalongside text. In zero-shot settings,ViCachievesRecall@1scores of 87.1%\n(t2v) / 89.0% (v2t) on MSR-VTT and 99.6% (v2t) onVATEX, representing massive\ngains of up to +40Recall@1over previous state-of-the-art baselines. We\npresentViCas a simple, reproducible, and highly effective recipe for turning\nmodernVLMs into powerful zero-shot rerankers and fusers. Code and resources\nare publicly available at: https://github.com/mohammad2012191/ViC ðŸ¤” What we explored: ðŸ”¥ Answers: ViC is simple, effective, and general. It utilizes candidates' ranks, consensus and content to rerank the candidates. We believe it unlocks a new way to think about reranking and fusion across modalities and retrieval pipelines. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545097",
    "title": "Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers",
    "authors": [
      "Mohamed Eltahir"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/mohammad2012191/ViC",
    "huggingface_url": "https://huggingface.co/papers/2511.01617",
    "upvote": 2
  }
}