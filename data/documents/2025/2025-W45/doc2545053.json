{
  "context": "LiveTradeBench evaluates LLMs in dynamic trading environments to assess decision-making under real-time uncertainty and market volatility. Large language models(LLMs) achieve strong performance across\nbenchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but\nthese tests occur in static settings, lacking real dynamics and uncertainty.\nConsequently, they evaluate isolated reasoning or problem-solving rather than\ndecision-making under uncertainty. To address this, we introduce\nLiveTradeBench, alive trading environmentfor evaluating LLM agents in\nrealistic and evolving markets. LiveTradeBench follows three design principles:\n(i) Live data streaming ofmarket pricesandnews, eliminating dependence on\noffline backtesting and preventing information leakage while capturing\nreal-time uncertainty; (ii) a portfolio-management abstraction that extends\ncontrol from single-asset actions tomulti-asset allocation, integrating risk\nmanagement andcross-asset reasoning; and (iii)multi-market evaluationacross\nstructurally distinct environments--U.S. stocksand Polymarket prediction\nmarkets--differing involatility,liquidity, andinformation flow. At each\nstep, an agent observes prices,news, and its portfolio, then outputs\npercentage allocations that balance risk and return. Using LiveTradeBench, we\nrun 50-day live evaluations of 21LLMsacross families. Results show that (1)\nhigh LMArena scores do not imply superior trading outcomes; (2) models display\ndistinct portfolio styles reflecting risk appetite and reasoning dynamics; and\n(3) someLLMseffectively leverage live signals to adapt decisions. These\nfindings expose a gap between static evaluation and real-world competence,\nmotivating benchmarks that testsequential decision makingand consistency\nunder live uncertainty. Large language models (LLMs) achieve strong performance across benchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but these tests occur in static settings, lacking real dynamics and uncertainty. Consequently, they evaluate isolated reasoning or problem-solving rather than decision-making under uncertainty. To address this, we introduce LiveTradeBench, a live trading environment for evaluating LLM agents in realistic and evolving markets. LiveTradeBench follows three design principles: (i) Live data streaming of market prices and news, eliminating dependence on offline backtesting and preventing information leakage while capturing real-time uncertainty; (ii) a portfolio-management abstraction that extends control from single-asset actions to multi-asset allocation, integrating risk management and cross-asset reasoning; and (iii) multi-market evaluation across structurally distinct environments--U.S. stocks and Polymarket prediction markets--differing in volatility, liquidity, and information flow. At each step, an agent observes prices, news, and its portfolio, then outputs percentage allocations that balance risk and return. Using LiveTradeBench, we run 50-day live evaluations of 21 LLMs across families. Results show that (1) high LMArena scores do not imply superior trading outcomes; (2) models display distinct portfolio styles reflecting risk appetite and reasoning dynamics; and (3) some LLMs effectively leverage live signals to adapt decisions. These findings expose a gap between static evaluation and real-world competence, motivating benchmarks that test sequential decision making and consistency under live uncertainty. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545053",
    "title": "LiveTradeBench: Seeking Real-World Alpha with Large Language Models",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/ulab-uiuc/live-trade-bench",
    "huggingface_url": "https://huggingface.co/papers/2511.03628",
    "upvote": 12
  }
}