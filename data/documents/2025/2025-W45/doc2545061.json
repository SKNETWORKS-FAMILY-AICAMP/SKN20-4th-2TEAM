{
  "context": "TWIST2, a portable mocap-free system, enables efficient data collection and hierarchical visuomotor policy control for humanoid robots. Large-scale data has driven breakthroughs in robotics, from language models\nto vision-language-action models in bimanual manipulation. However, humanoid\nrobotics lacks equally effective data collection frameworks. Existing humanoid\nteleoperation systems either use decoupled control or depend on expensive\nmotion capture setups. We introduce TWIST2, a portable, mocap-free humanoid\nteleoperation and data collection system that preserves fullwhole-body controlwhile advancing scalability. Our system leveragesPICO4U VRfor obtaining\nreal-time whole-body human motions, with a custom 2-DoF robot neck (cost around\n$250) foregocentric vision, enabling holistic human-to-humanoid control. We\ndemonstrate long-horizon dexterous and mobile humanoid skills and we can\ncollect 100 demonstrations in 15 minutes with an almost 100% success rate.\nBuilding on this pipeline, we propose ahierarchical visuomotor policyframework that autonomously controls the full humanoid body based on egocentric\nvision. Our visuomotor policy successfully demonstrates whole-body dexterous\nmanipulation anddynamic kicking tasks. The entire system is fully reproducible\nand open-sourced at https://yanjieze.com/TWIST2 . Our collected dataset is also\nopen-sourced at https://twist-data.github.io . Large-scale data has driven breakthroughs in robotics, from language models to vision-language-action models in bimanual manipulation. However, humanoid robotics lacks equally effective data collection frameworks. Existing humanoid teleoperation systems either use decoupled control or depend on expensive motion capture setups. We introduce TWIST2, a portable, mocap-free humanoid teleoperation and data collection system that preserves full whole-body control while advancing scalability. Our system leverages PICO4U VR for obtaining real-time whole-body human motions, with a custom 2-DoF robot neck (cost around $250) for egocentric vision, enabling holistic human-to-humanoid control. We demonstrate long-horizon dexterous and mobile humanoid skills and we can collect 100 demonstrations in 15 minutes with an almost 100% success rate. Building on this pipeline, we propose a hierarchical visuomotor policy framework that autonomously controls the full humanoid body based on egocentric vision. Our visuomotor policy successfully demonstrates whole-body dexterous manipulation and dynamic kicking tasks. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545061",
    "title": "TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System",
    "authors": [
      "Yanjie Ze"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/amazon-far/TWIST2",
    "huggingface_url": "https://huggingface.co/papers/2511.02832",
    "upvote": 9
  }
}