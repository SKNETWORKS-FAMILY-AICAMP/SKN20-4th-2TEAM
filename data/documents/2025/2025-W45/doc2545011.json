{
  "context": "Continuous Autoregressive Language Models (CALM) improve language model efficiency by predicting continuous vectors instead of discrete tokens, reducing computational cost while maintaining performance. The efficiency of large language models (LLMs) is fundamentally limited by\ntheir sequential, token-by-token generation process. We argue that overcoming\nthis bottleneck requires a new design axis for LLM scaling: increasing the\nsemantic bandwidth of each generative step. To this end, we introduceContinuous Autoregressive Language Models(CALM), a paradigm shift fromdiscrete next-token predictiontocontinuous next-vector prediction.CALMuses\nahigh-fidelity autoencoderto compress a chunk of K tokens into a single\ncontinuous vector, from which the original tokens can be reconstructed with\nover 99.9\\% accuracy. This allows us to model language as a sequence of\ncontinuous vectors instead of discrete tokens, which reduces the number of\ngenerative steps by a factor of K. The paradigm shift necessitates a new\nmodeling toolkit; therefore, we develop a comprehensive likelihood-free\nframework that enables robust training, evaluation, and controllable sampling\nin the continuous domain. Experiments show thatCALMsignificantly improves the\nperformance-compute trade-off, achieving the performance of strong discrete\nbaselines at a significantly lower computational cost. More importantly, these\nfindings establish next-vector prediction as a powerful and scalable pathway\ntowardsultra-efficient language models. Code:\nhttps://github.com/shaochenze/calm. Project:\nhttps://shaochenze.github.io/blog/2025/CALM. From discrete next-token prediction to continuous next-vector predictionCode:https://github.com/shaochenze/calmBlog:https://shaochenze.github.io/blog/2025/CALM this is like a large concept model - it performs well because tokens are often chunked through its vicinity. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545011",
    "title": "Continuous Autoregressive Language Models",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/shaochenze/calm",
    "huggingface_url": "https://huggingface.co/papers/2510.27688",
    "upvote": 70
  }
}