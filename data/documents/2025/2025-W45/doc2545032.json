{
  "context": "Evaluation of agent-based systems reveals a collaboration gap where solo-performing models degrade in pairings, suggesting the need for collaboration-aware evaluation and training strategies. The trajectory of AI development suggests that we will increasingly rely onagent-based systemscomposed of independently developed agents with different\ninformation, privileges, and tools. The success of these systems will\ncritically depend on effective collaboration among these heterogeneous agents,\neven under partial observability. Despite intense interest, few empirical\nstudies have evaluated such agent-agent collaboration at scale. We propose acollaborative maze-solving benchmarkthat (i) isolates collaborative\ncapabilities, (ii) modulates problem complexity, (iii) enables scalable\nautomated grading, and (iv) imposes no output-format constraints, preserving\necological plausibility. Using this framework, we evaluate 32 leading open- and\nclosed-source models in solo, homogeneous, and heterogeneous pairings. Our\nresults reveal a \"collaboration gap\": models that perform well solo often\ndegrade substantially when required to collaborate. Collaboration can break\ndown dramatically; for instance, small distilled models that solve mazes well\nalone may fail almost completely in certain pairings. We find that starting\nwith the stronger agent often improves outcomes, motivating a \"relay inference\"\napproach where the stronger agent leads before handing off to the weaker one,\nclosing much of the gap. Our findings argue for (1) collaboration-aware\nevaluation, (2)training strategiesdeveloped to enhance collaborative\ncapabilities, and (3)interaction designthat reliably elicits agents' latent\nskills, guidance that applies to AI-AI and human-AI collaboration. We’ve identified a “Collaboration Gap” in today’s top AI models. Testing 32 leading LMs on our novel maze-solving benchmark, we found that models that excel solo can see their performancecollapsewhen required to collaborate – even with an identical copy of themselves! Why does this matter? The future of AI is unlikely to be one giant model; it's systems of multiple, independent AI agents with different information and skills. Current attempts at multi-agent systems rely onpre-definedcommunication protocols or central orchestration. In contrast, open-world integration likely requires flexible, on-the-fly communication to adapt to the diversity of the real world. We provide insights into homogeneous and heterogeneous collaboration and explore a \"relay\" inference approach for effective heterogeneous deployment. Our findings argue that collaboration is a distinct capability that current training strategies fail to capture. We shouldn’t just hope for it to emerge – we mustdesignfor it. This means new evals, training strategies, and interaction designs. Evaluating the sort of behavior is one of the first things I did with gpt 3.5. for my particular use case at the time, it was actually easier to use the DaVinci model to get what I needed. ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545032",
    "title": "The Collaboration Gap",
    "authors": [],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2511.02687",
    "upvote": 22
  }
}