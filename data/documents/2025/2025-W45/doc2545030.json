{
  "context": "Nemotron Nano V2 VL, a hybrid Mamba-Transformer LLM, improves document and video understanding through enhanced architecture and token reduction techniques. We introduce Nemotron Nano V2 VL, the latest model of the Nemotron\nvision-language series designed for strong real-world document understanding,\nlong video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers\nsignificant improvements over our previous model,\nLlama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major\nenhancements in model architecture, datasets, and training recipes. Nemotron\nNano V2 VL builds on Nemotron Nano V2, a hybridMamba-TransformerLLM, and\ninnovativetoken reduction techniquesto achieve higher inference throughput in\nlong document and video scenarios. We are releasing model checkpoints inBF16,FP8, andFP4formats and sharing large parts of our datasets, recipes and\ntraining code. NVIDIA Nemotron Nano V2 VL This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545030",
    "title": "NVIDIA Nemotron Nano V2 VL",
    "authors": [
      "Amala Sanjay Deshmukh",
      "Kateryna Chumachenko"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/NVIDIA-NeMo/Curator",
    "huggingface_url": "https://huggingface.co/papers/2511.03929",
    "upvote": 27
  }
}