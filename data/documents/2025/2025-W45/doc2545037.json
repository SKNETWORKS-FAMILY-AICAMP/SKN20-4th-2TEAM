{
  "context": "OpenSIR is a self-play framework that enables large language models to improve their reasoning abilities through open-ended problem generation and solving without external supervision. Recent advances inlarge language model(LLM) reasoning through reinforcement\nlearning rely onannotated datasetsfor verifiable rewards, which may limit\nmodels' ability to surpass human-level performance. Whileself-playoffers a\npromising alternative, existing approaches depend on external verifiers or\ncannot learn open-endedly. We presentOpen-Ended Self-Improving Reasoner(OpenSIR), aself-playframework where an LLM learns to generate and solve\nnovel problems by alternating teacher and student roles without external\nsupervision. To generate novel problems,OpenSIRoptimises for both difficulty\nand diversity, rewarding problems that challenge appropriately while exploring\ndistinct concepts, enabling open-endedmathematical discovery. Starting from a\nsingle trivial seed problem,OpenSIRsubstantially improves instruction models:Llama-3.2-3B-Instructadvances from 73.9 to 78.3 onGSM8K, and from 28.8 to\n34.4 onCollege Math, whileGemma-2-2B-Instructrises from 38.5 to 58.7 onGSM8K. Our analyses reveal thatOpenSIRachievesopen-ended learningthrough\nco-evolvingteacher-student rolesthat adaptively calibrate difficulty and\ndrive diverse exploration, progressing autonomously from basic to advanced\nmathematics. OpenSIR is a self-play framework in which a large language model alternates between “teacher” and “student” roles, generating and solving novel problems optimised for difficulty and diversity without external supervision. ·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545037",
    "title": "OpenSIR: Open-Ended Self-Improving Reasoner",
    "authors": [
      "Pasquale Minervini"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/EdinburghNLP/OpenSIR",
    "huggingface_url": "https://huggingface.co/papers/2511.00602",
    "upvote": 20
  }
}