{
  "context": "A benchmark and framework improve Vision-Language Models' performance on Rebus Puzzles through structured reasoning and example selection. UnderstandingRebus Puzzles(Rebus Puzzlesuse pictures, symbols, and letters\nto represent words or phrases creatively) requires a variety of skills such as\nimage recognition, cognitive skills, commonsense reasoning, multi-step\nreasoning, image-based wordplay, etc., making this a challenging task for even\ncurrentVision-Language Models. In this paper, we present\nleft|,circlearrowright,text{BUS},right|, a large and diverse\nbenchmark of 1,333 EnglishRebus Puzzlescontaining different artistic styles\nand levels of difficulty, spread across 18 categories such as food, idioms,\nsports, finance, entertainment, etc. We also proposeRebusDescProgICE, a\nmodel-agnostic framework which uses a combination of an unstructured\ndescription and code-based, structured reasoning, along with better,\nreasoning-basedin-context example selection, improving the performance ofVision-Language Modelson\nleft|,circlearrowright,text{BUS},right| by 2.1-4.1% and\n20-30% using closed-source and open-source models respectively compared toChain-of-Thought Reasoning. Understanding Rebus Puzzles (Rebus Puzzles use pictures, symbols, and letters to represent words or phrases creatively) requires a variety of skills such as image recognition, cognitive skills, common-sense reasoning, multi-step reasoning, image-based wordplay, etc., making this a challenging task for even current Vision-Language Models. In this paper, we present ‚ôªÔ∏èüöç (Rebus Puzzle for the Word ‚ÄúRebus‚Äù, consisting of the ‚ÄúRe‚Äù - ‚ôªÔ∏è and ‚ÄúBus‚Äù - üöç symbols), a large and diverse benchmark of 1,333 English Rebus Puzzles containing different artistic styles and levels of difficulty, spread across 18 categories such as food, idioms, sports, finance, entertainment, etc. We also propose RebusDescProgICE, a model-agnostic framework which uses a combination of an unstructured description and code-based, structured reasoning, along with better, reasoning-based in-context example selection, improving the performance of Vision-Language Models on ‚ôªÔ∏èüöç by 2.1 ‚Äì 4.1% and 20 ‚Äì 30% using closed-source and open-source models respectively compared to Chain-of-Thought Reasoning. ¬∑Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545054",
    "title": "left|,circlearrowright,text{BUS},right|: A Large and\n  Diverse Multimodal Benchmark for evaluating the ability of Vision-Language\n  Models to understand Rebus Puzzles",
    "authors": [],
    "publication_year": 2025,
    "github_url": "https://github.com/abhi1nandy2/Re-Bus",
    "huggingface_url": "https://huggingface.co/papers/2511.01340",
    "upvote": 12
  }
}