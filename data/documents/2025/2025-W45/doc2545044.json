{
  "context": "TIR-Bench evaluates advanced visual reasoning capabilities in multimodal models through diverse tasks requiring tool use and chain-of-thought, demonstrating the need for genuine thinking-with-images. The frontier of visual reasoning is shifting toward models likeOpenAI o3,\nwhich can intelligently create and operate tools to transform images for\nproblem-solving, also known asthinking-with-imagesinchain-of-thought. Yet existing benchmarks fail to fully capture this advanced\ncapability. Even Visual Search, the most common benchmark for currentthinking-with-imagesmethods, tests only basic operations such as\nlocalization and cropping, offering little insight into more complex, dynamic,\nand tool-dependent reasoning. We introduceTIR-Bench, a comprehensive\nbenchmark for evaluating agenticthinking-with-imagesacross 13 diverse tasks,\neach requiring novel tool use for image processing and manipulation inchain-of-thought. We evaluate 22multimodal large language models(MLLMs), from\nleading open-sourced and proprietary models to those with explicit tool-use\naugmentation. Results show thatTIR-Benchis universally challenging, and\nstrong performance requires genuinethinking-with-imagescapabilities. Finally,\nwe present a pilot study comparing direct versusagentic fine-tuning. The frontier of visual reasoning is shifting toward models like OpenAI o3, which can intelligently create and operate tools to transform images for problem-solving, also known as thinking-\\textit{with}-images in chain-of-thought. Yet existing benchmarks fail to fully capture this advanced capability. Even Visual Search, the most common benchmark for current thinking-\\textit{with}-images methods, tests only basic operations such as localization and cropping, offering little insight into more complex, dynamic, and tool-dependent reasoning. We introduce \\textbf{TIR-Bench}, a comprehensive benchmark for evaluating agentic thinking-with-images across 13 diverse tasks, each requiring novel tool use for image processing and manipulation in chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from leading open-sourced and proprietary models to those with explicit tool-use augmentation. Results show that TIR-Bench is universally challenging, and strong performance requires genuine thinking-with-images capabilities. Finally, we present a pilot study comparing direct versus agentic fine-tuning. Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545044",
    "title": "TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images\n  Reasoning",
    "authors": [
      "Shitian Zhao",
      "Haoquan Zhang"
    ],
    "publication_year": 2025,
    "github_url": "https://github.com/agents-x-project/TIR-Bench",
    "huggingface_url": "https://huggingface.co/papers/2511.01833",
    "upvote": 15
  }
}