{
  "context": "EBT-Policy, an energy-based architecture, outperforms diffusion-based policies in robotic tasks by offering improved robustness, reduced computational cost, and emergent zero-shot recovery capabilities. Implicit policies parameterized by generative models, such as Diffusion\nPolicy, have become the standard for policy learning and Vision-Language-Action\n(VLA) models in robotics. However, these approaches often suffer from high\ncomputational cost, exposure bias, and unstable inference dynamics, which lead\nto divergence underdistribution shifts.Energy-Based Models(EBMs) address\nthese issues by learningenergy landscapesend-to-end and modeling equilibrium\ndynamics, offering improved robustness and reduced exposure bias. Yet, policies\nparameterized byEBMshave historically struggled to scale effectively. Recent\nwork onEnergy-Based Transformers(EBTs) demonstrates the scalability ofEBMsto high-dimensional spaces, but their potential for solving core challenges in\nphysically embodied models remains underexplored. We introduce a new\nenergy-based architecture,EBT-Policy, that solves core issues in robotic and\nreal-world settings. Across simulated and real-world tasks,EBT-Policyconsistently outperforms diffusion-based policies, while requiring less\ntraining and inference computation. Remarkably, on some tasks it converges\nwithin just two inference steps, a 50x reduction compared toDiffusion Policy's\n100. Moreover,EBT-Policyexhibits emergent capabilities not seen in prior\nmodels, such aszero-shot recoveryfrom failed action sequences using onlybehavior cloningand without explicit retry training. By leveraging its scalar\nenergy foruncertainty-aware inferenceanddynamic compute allocation,EBT-Policyoffers a promising path toward robust, generalizable robot behavior\nunderdistribution shifts. Implicit policies parameterized by generative models, such as Diffusion Policy, have become the standard for policy learning and Vision-Language-Action (VLA) models in robotics. However, these approaches often suffer from high computational cost, exposure bias, and unstable inference dynamics, which lead to divergence under distribution shifts. Energy-Based Models (EBMs) address these issues by learning energy landscapes end-to-end and modeling equilibrium dynamics, offering improved robustness and reduced exposure bias. Yet, policies parameterized by EBMs have historically struggled to scale effectively. Recent work on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs to high-dimensional spaces, but their potential for solving core challenges in physically embodied models remains underexplored. We introduce a new energy-based architecture, EBT-Policy, that solves core issues in robotic and real-world settings. Across simulated and real-world tasks, EBT-Policy consistently outperforms diffusion-based policies, while requiring less training and inference computation. Remarkably, on some tasks it converges within just two inference steps, a 50x reduction compared to Diffusion Policy's 100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior models, such as zero-shot recovery from failed action sequences using only behavior cloning and without explicit retry training. By leveraging its scalar energy for uncertainty-aware inference and dynamic compute allocation, EBT-Policy offers a promising path toward robust, generalizable robot behavior under distribution shifts. nice paper! Great work for world models! Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2545015",
    "title": "EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities",
    "authors": [
      "Travis Davies",
      "Huxian Liu"
    ],
    "publication_year": 2025,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2510.27545",
    "upvote": 48
  }
}