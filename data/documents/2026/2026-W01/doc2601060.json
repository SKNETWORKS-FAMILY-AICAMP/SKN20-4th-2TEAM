{
  "context": "Recent video-language models have shown great potential for video understanding, but still struggle with accurate temporal grounding for event-level perception. We observe that two main factors in video understanding (i.e., temporal grounding and textual response) form a logical hierarchy: accurate temporal evidence grounding lays the foundation for reliable textual response. However, existing works typically handle these two tasks in a coupled manner without a clear logical structure, leading to sub-optimal objectives. We address this from a factorized learning perspective. We first propose D^2VLM, a framework that decouples the learning of these two tasks while also emphasizing their inherent dependency. We adopt a \"grounding then answering with evidence referencing\" paradigm and introduce evidence tokens for evidence grounding, which emphasize event-level visual semantic capture beyond the focus on timestamp representation in existing works. To further facilitate the learning of these two tasks, we introduce a novel factorized preference optimization (FPO) algorithm. Unlike standard preference optimization, FPO explicitly incorporates probabilistic temporal grounding modeling into the optimization objective, enabling preference learning for both temporal grounding and textual response. We also construct a synthetic dataset to address the lack of suitable datasets for factorized preference learning with explicit temporal grounding. Experiments on various tasks demonstrate the clear advantage of our approach. Our source code is available at https://github.com/nusnlp/d2vlm. We tackle temporally grounded video-language understanding from a factorized perspective. Some key takeaways: [1] We emphasize the distinct yet causally dependent nature of temporal grounding and textual response. [2] Our study highlights the importance of explicit event-level visual semantic capture in enhancing both grounding and textual response quality. [3] We also propose a new Factorized Preference Optimization (FPO) scheme that jointly optimizes temporal and textual factors. A factorized data synthesis approach is also proposed to support FPO. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/factorized-learning-for-temporally-grounded-video-language-models-2136-9a51f180 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2601060",
    "title": "Factorized Learning for Temporally Grounded Video-Language Models",
    "authors": [],
    "publication_year": 2026,
    "github_url": "https://github.com/nusnlp/d2vlm",
    "huggingface_url": "https://huggingface.co/papers/2512.24097",
    "upvote": 6
  }
}