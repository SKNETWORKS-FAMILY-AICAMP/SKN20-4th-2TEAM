{
  "context": "UniMAGE is a unified director model that combines script drafting and key-shot design using a Mixture-of-Transformers architecture with interleaved concept learning and disentangled expert learning to create coherent video scripts and consistent keyframe images. Existing AI-driven video creation systems typically treat script drafting and key-shot design as two disjoint tasks: the former relies on large language models, while the latter depends on image generation models. We argue that these two tasks should be unified within a single framework, as logical reasoning and imaginative thinking are both fundamental qualities of a film director. In this work, we propose UniMAGE, a unified director model that bridges user prompts with well-structured scripts, thereby empowering non-experts to produce long-context, multi-shot films by leveraging existing audio-video generation models. To achieve this, we employ theMixture-of-Transformersarchitecture that unifies text and image generation. To further enhancenarrative logicand keyframe consistency, we introduce a ``first interleaving, then disentangling'' training paradigm. Specifically, we first performInterleaved Concept Learning, which utilizesinterleaved text-image datato foster the model's deeper understanding and imaginative interpretation of scripts. We then conductDisentangled Expert Learning, which decouplesscript writingfromkeyframe generation, enabling greater flexibility and creativity in storytelling. Extensive experiments demonstrate that UniMAGE achieves state-of-the-art performance among open-source models, generating logically coherent video scripts and visually consistent keyframe images. UniMAGE unifies script writing and keyframe generation for long-context video creation using Mixture-of-Transformers and a two-stage interleaving/disentangling training paradigm. This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/bridging-your-imagination-with-audio-video-generation-via-a-unified-director-5756-3936d858 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2601065",
    "title": "Bridging Your Imagination with Audio-Video Generation via a Unified Director",
    "authors": [],
    "publication_year": 2026,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.23222",
    "upvote": 5
  }
}