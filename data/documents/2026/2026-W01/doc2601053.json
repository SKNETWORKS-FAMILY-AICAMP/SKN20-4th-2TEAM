{
  "context": "A new benchmark for dialog-enabled navigation tasks introduces interactive learning to resolve ambiguous instructions through active dialog, enhancing real-world applicability of embodied agents. In most existing embodied navigation tasks, instructions are well-defined and unambiguous, such as instruction following and object searching. Under this idealized setting, agents are required solely to produce effective navigation outputs conditioned on vision and language inputs. However, real-world navigation instructions are often vague and ambiguous, requiring the agent to resolve uncertainty and infer user intent through active dialog. To address this gap, we proposeInteractive Instance Object Navigation (IION), a task that requires agents not only to generate navigation actions but also to produce language outputs via active dialog, thereby aligning more closely with practical settings. IION extendsInstance Object Navigation (ION)by allowing agents to freely consult anoraclein natural language while navigating. Building on this task, we present theVision Language-Language Navigation (VL-LN)benchmark, which provides a large-scale, automatically generated dataset and a comprehensive evaluation protocol for training and assessingdialog-enabled navigation models. VL-LN comprises over 41k long-horizondialog-augmented trajectoriesfor training and an automatic evaluation protocol with anoraclecapable of responding to agent queries. Using this benchmark, we train a navigation model equipped with dialog capabilities and show that it achieves significant improvements over the baselines. Extensive experiments and analyses further demonstrate the effectiveness and reliability of VL-LN for advancing research on dialog-enabled embodied navigation. Code and dataset: https://0309hws.github.io/VL-LN.github.io/ VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/vl-ln-bench-towards-long-horizon-goal-oriented-navigation-with-active-dialogs-1973-e5132f3f Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2601053",
    "title": "VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs",
    "authors": [],
    "publication_year": 2026,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.22342",
    "upvote": 8
  }
}