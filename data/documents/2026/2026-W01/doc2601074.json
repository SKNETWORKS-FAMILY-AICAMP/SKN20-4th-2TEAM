{
  "context": "Making deep learning recommendation model (DLRM) training and inference fast and efficient is important. However, this presents three key system challenges - model architecture diversity, kernel primitive diversity, and hardware generation and architecture heterogeneity. This paper presents KernelEvolve-an agentic kernel coding framework-to tackle heterogeneity at-scale for DLRM. KernelEvolve is designed to take kernel specifications as input and automate the process of kernel generation and optimization for recommendation model across heterogeneous hardware architectures. KernelEvolve does so by operating at multiple programming abstractions, from Triton and CuTe DSL to low-level hardware agnostic languages, spanning the full hardware-software optimization stack. The kernel optimization process is described as graph-based search with selection policy, universal operator, fitness function, and termination rule, dynamically adapts to runtime execution context through retrieval-augmented prompt synthesis. We designed, implemented, and deployed KernelEvolve to optimize a wide variety of production recommendation models across generations of NVIDIA and AMD GPUs, as well as Meta's AI accelerators. We validate KernelEvolve on the publicly-available KernelBench suite, achieving 100% pass rate on all 250 problems across three difficulty levels, and 160 PyTorch ATen operators across three heterogeneous hardware platforms, demonstrating 100% correctness. KernelEvolve reduces development time from weeks to hours and achieves substantial performance improvements over PyTorch baselines across diverse production use cases and for heterogeneous AI systems at-scale. Beyond performance efficiency improvements, KernelEvolve significantly mitigates the programmability barrier for new AI hardware by enabling automated kernel generation for in-house developed AI hardware. Excited to share our recent work onKernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta. We designed, implemented, and deployed KernelEvolve to optimize a wide variety of production recommendation models acrossgenerations of NVIDIA and AMD GPUs, as well as Metaâ€™s latest-generation AI accelerators (MTIA v3). Writing high-performance GPU kernels is a complex challenge that typically demands years of deep expertise and remains a major focus of industry and academic research. Itâ€™s truly impressive to see KernelEvolve not only achieve state-of-the-art results on open benchmarks, but alsodeliver 1.25â€“17x speedups across Meta production use cases. This milestone was made possible by outstanding collaboration across Metaâ€”including teams fromMonetization Infra and Ranking, FAIR, Compiler, MTIA, Serverless Compute, and more. Thank you to everyone for your dedication and teamwork in making this breakthrough happen! You can read the full paper here:ðŸ‘‰https://lnkd.in/gdPb43EZ This is only ~1% of the journey. There is much more ahead in 2026 as we continue pushing the boundaries. If your background aligns (Agentic, LLM, RL, AI compiler, Kernels, Inference/training optimization etc.) and youâ€™re interested in joining us on this journey, feel free to DM me. Weâ€™re hiring. (gangliao@meta.com) This is an automated message from theLibrarian Bot. I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkoutthisSpace You can directly ask Librarian Bot for paper recommendations by tagging it in a comment:@librarian-botrecommend arXiv lens breakdown of this paper ðŸ‘‰https://arxivlens.com/PaperView/Details/kernelevolve-scaling-agentic-kernel-coding-for-heterogeneous-ai-accelerators-at-meta-4947-164c1026 Â·Sign uporlog into comment",
  "metadata": {
    "doc_id": "doc2601074",
    "title": "KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta",
    "authors": [
      "Gang Liao"
    ],
    "publication_year": 2026,
    "github_url": "",
    "huggingface_url": "https://huggingface.co/papers/2512.23236",
    "upvote": 2
  }
}